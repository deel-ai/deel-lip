{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: HKR classifier on MNIST dataset\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deel-ai/deel-lip/blob/master/docs/notebooks/demo3.ipynb)\n",
    "\n",
    "This notebook will demonstrate learning a binary task on the MNIST0-8 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/deel-ai/deel-lip.git@keras3 -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:46:57.908038: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 16:46:57.919347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 16:46:57.922845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 16:46:57.931333: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 16:46:59.216961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.ops as K\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.models import Sequential\n",
    "\n",
    "from deel.lip.layers import SpectralDense, FrobeniusDense\n",
    "from deel.lip.activations import GroupSort, GroupSort2\n",
    "from deel.lip.losses import HKR, KR, HingeMargin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "For this task we will select two classes: 0 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 11774 samples, classes proportions: 50.306 percent\n",
      "test set size: 1954 samples, classes proportions: 50.154 percent\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# first we select the two classes\n",
    "selected_classes = [0, 8]  # must be two classes as we perform binary classification\n",
    "\n",
    "\n",
    "def prepare_data(x, y, class_a=0, class_b=8):\n",
    "    \"\"\"\n",
    "    This function convert the MNIST data to make it suitable for our binary classification\n",
    "    setup.\n",
    "    \"\"\"\n",
    "    # select items from the two selected classes\n",
    "    mask = (y == class_a) + (\n",
    "        y == class_b\n",
    "    )  # mask to select only items from class_a or class_b\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    x = x.astype(\"float32\")\n",
    "    y = y.astype(\"float32\")\n",
    "    # convert from range int[0,255] to float32[-1,1]\n",
    "    x /= 255\n",
    "    x = x.reshape((-1, 28, 28, 1))\n",
    "    # change label to binary classification {-1,1}\n",
    "    y[y == class_a] = 1.0\n",
    "    y[y == class_b] = 0.0\n",
    "    return x, y.reshape((-1, 1))\n",
    "\n",
    "\n",
    "# now we load the dataset\n",
    "(x_train, y_train_ord), (x_test, y_test_ord) = mnist.load_data()\n",
    "\n",
    "# prepare the data\n",
    "x_train, y_train = prepare_data(\n",
    "    x_train, y_train_ord, selected_classes[0], selected_classes[1]\n",
    ")\n",
    "x_test, y_test = prepare_data(\n",
    "    x_test, y_test_ord, selected_classes[0], selected_classes[1]\n",
    ")\n",
    "\n",
    "# display infos about dataset\n",
    "print(\n",
    "    \"train set size: %i samples, classes proportions: %.3f percent\"\n",
    "    % (y_train.shape[0], 100 * y_train[y_train == 1].sum() / y_train.shape[0])\n",
    ")\n",
    "print(\n",
    "    \"test set size: %i samples, classes proportions: %.3f percent\"\n",
    "    % (y_test.shape[0], 100 * y_test[y_test == 1].sum() / y_test.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1-Lipschitz Model\n",
    "\n",
    "Let's first explicit the paremeters of this experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# network parameters\n",
    "activation = GroupSort  # ReLU, MaxMin, GroupSort2\n",
    "\n",
    "# loss parameters\n",
    "min_margin = 1.0\n",
    "alpha = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the network. Here the experiment is done with a MLP. But `deel-lip`\n",
    "also provide state of the art 1-Lipschitz convolutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725893221.465840 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.485439 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.485575 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.486425 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.486529 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.486613 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.579691 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.579806 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725893221.579895 1172384 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-09 16:47:01.579967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6818 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lipModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lipModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpectralDense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,241</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,057</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpectralDense</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ frobenius_dense                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FrobeniusDense</span>)                │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense (\u001b[38;5;33mSpectralDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m50,241\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,057\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpectralDense\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ frobenius_dense                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mFrobeniusDense\u001b[0m)                │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,330</span> (200.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,330\u001b[0m (200.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,664</span> (100.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,664\u001b[0m (100.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,666</span> (100.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,666\u001b[0m (100.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras.utils.clear_session()\n",
    "# helper function to build the 1-lipschitz MLP\n",
    "model = Sequential(\n",
    "    layers=[\n",
    "        Input((28, 28, 1)),\n",
    "        Flatten(),\n",
    "        SpectralDense(32, GroupSort2(), use_bias=True),\n",
    "        SpectralDense(16, GroupSort2(), use_bias=True),\n",
    "        FrobeniusDense(1, activation=None, use_bias=False),\n",
    "    ],\n",
    "    name=\"lipModel\",\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=HKR(\n",
    "        alpha=alpha, min_margin=min_margin\n",
    "    ),  # HKR stands for the hinge regularized KR loss\n",
    "    metrics=[\n",
    "        KR,  # shows the KR term of the loss\n",
    "        HingeMargin(min_margin=min_margin),  # shows the hinge term of the loss\n",
    "        BinaryAccuracy(threshold=0),  # shows the classification accuracy\n",
    "    ],\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn classification on MNIST\n",
    "\n",
    "Now the model is build, we can learn the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725893224.205872 1172438 service.cc:146] XLA service 0x7fe044006190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1725893224.205889 1172438 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
      "2024-09-09 16:47:04.238892: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-09 16:47:04.372884: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/92\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - HingeMargin: 0.1326 - KR: 2.4768 - binary_accuracy: 0.8870 - loss: -1.1513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725893226.312877 1172438 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - HingeMargin: 0.0941 - KR: 3.4458 - binary_accuracy: 0.9218 - loss: -2.5046 - val_HingeMargin: 0.0264 - val_KR: 5.5877 - val_binary_accuracy: 0.9800 - val_loss: -5.3403\n",
      "Epoch 2/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - HingeMargin: 0.0392 - KR: 5.4768 - binary_accuracy: 0.9725 - loss: -5.0849 - val_HingeMargin: 0.0350 - val_KR: 5.6396 - val_binary_accuracy: 0.9754 - val_loss: -5.3006\n",
      "Epoch 3/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - HingeMargin: 0.0354 - KR: 5.5531 - binary_accuracy: 0.9742 - loss: -5.1991 - val_HingeMargin: 0.0258 - val_KR: 5.5907 - val_binary_accuracy: 0.9811 - val_loss: -5.3503\n",
      "Epoch 4/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - HingeMargin: 0.0353 - KR: 5.4961 - binary_accuracy: 0.9722 - loss: -5.1434 - val_HingeMargin: 0.0324 - val_KR: 5.6472 - val_binary_accuracy: 0.9754 - val_loss: -5.3337\n",
      "Epoch 5/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - HingeMargin: 0.0300 - KR: 5.6041 - binary_accuracy: 0.9791 - loss: -5.3042 - val_HingeMargin: 0.0255 - val_KR: 5.8793 - val_binary_accuracy: 0.9806 - val_loss: -5.6417\n",
      "Epoch 6/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - HingeMargin: 0.0237 - KR: 5.8564 - binary_accuracy: 0.9830 - loss: -5.6191 - val_HingeMargin: 0.0222 - val_KR: 5.9550 - val_binary_accuracy: 0.9821 - val_loss: -5.7550\n",
      "Epoch 7/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - HingeMargin: 0.0216 - KR: 5.9770 - binary_accuracy: 0.9847 - loss: -5.7610 - val_HingeMargin: 0.0206 - val_KR: 5.9949 - val_binary_accuracy: 0.9836 - val_loss: -5.8124\n",
      "Epoch 8/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - HingeMargin: 0.0198 - KR: 6.0514 - binary_accuracy: 0.9844 - loss: -5.8534 - val_HingeMargin: 0.0221 - val_KR: 6.0710 - val_binary_accuracy: 0.9826 - val_loss: -5.8722\n",
      "Epoch 9/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - HingeMargin: 0.0219 - KR: 6.0584 - binary_accuracy: 0.9833 - loss: -5.8395 - val_HingeMargin: 0.0200 - val_KR: 6.0795 - val_binary_accuracy: 0.9836 - val_loss: -5.9015\n",
      "Epoch 10/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - HingeMargin: 0.0219 - KR: 6.0507 - binary_accuracy: 0.9841 - loss: -5.8315 - val_HingeMargin: 0.0201 - val_KR: 6.1044 - val_binary_accuracy: 0.9826 - val_loss: -5.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe1140219c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model reaches a very decent accuracy on this task.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e585d72a124540032141457729caea4129d351be49f1f69f41c00c4f8476abb5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
