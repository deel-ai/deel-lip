{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Explore DEEL-LIP docs \u00bb"},{"location":"#welcome-to-deel-lip-documentation","title":"\ud83d\udc4b Welcome to deel-lip documentation!","text":"<p>Controlling the Lipschitz constant of a layer or a whole neural network has many applications ranging from adversarial robustness to Wasserstein distance estimation.</p> <p>This library provides an efficient implementation of k-Lispchitz layers for keras.</p>"},{"location":"#table-of-contents","title":"\ud83d\udcda Table of contents","text":"<ul> <li>\ud83d\udcda Table of contents</li> <li>\ud83d\udd25 Tutorials</li> <li>\ud83d\ude80 Quick Start</li> <li>\ud83d\udce6 What's Included</li> <li>\ud83d\udc4d Contributing</li> <li>\ud83d\udc40 See Also</li> <li>\ud83d\ude4f Acknowledgments</li> <li>\ud83d\uddde\ufe0f Citation</li> <li>\ud83d\udcdd License</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>You can install <code>deel-lip</code> directly from pypi:</p> <pre><code>pip install deel-lip\n</code></pre> <p>In order to use <code>deel-lip</code>, you also need a valid tensorflow installation. <code>deel-lip</code> supports tensorflow versions 2.x.</p>"},{"location":"#tutorials","title":"\ud83d\udd25 Tutorials","text":"Tutorial Name Notebook Getting started 1 - Creating a 1-Lipschitz neural network Wasserstein distance estimation on toy example HKR Classifier on toy dataset HKR classifier on MNIST dataset HKR multiclass and fooling"},{"location":"#whats-included","title":"\ud83d\udce6 What's Included","text":"<ul> <li>k-Lipschitz variant of keras layers such as <code>Dense</code>, <code>Conv2D</code> and    <code>Pooling</code>,</li> <li>activation functions compatible with <code>keras</code>,</li> <li>kernel initializers and kernel constraints for <code>keras</code>,</li> <li>loss functions that make use of Lipschitz constrained networks (see    our paper for more    information),</li> <li>tools to monitor the singular values of kernels during training,</li> <li>tools to convert k-Lipschitz network to regular network for faster    inference.</li> </ul>"},{"location":"#contributing","title":"\ud83d\udc4d Contributing","text":"<p>To contribute, you can open an issue, or fork this repository and then submit changes through a pull-request. We use black to format the code and follow PEP-8 convention. To check that your code will pass the lint-checks, you can run:</p> <pre><code>tox -e py36-lint\n</code></pre> <p>You need <code>tox</code> in order to run this. You can install it via <code>pip</code>:</p> <pre><code>pip install tox\n</code></pre>"},{"location":"#see-also","title":"\ud83d\udc40 See Also","text":"<p>More from the DEEL project:</p> <ul> <li>Xplique a Python library exclusively dedicated to explaining neural networks.</li> <li>Influenciae Python toolkit dedicated to computing influence values for the discovery of potentially problematic samples in a dataset.</li> <li>deel-torchlip a Python library for training k-Lipschitz neural networks on PyTorch.</li> <li>DEEL White paper a summary of the DEEL team on the challenges of certifiable AI and the role of data quality, representativity and explainability for this purpose.</li> </ul>"},{"location":"#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<p>  This project received funding from the French \u201dInvesting for the Future \u2013 PIA3\u201d program within the Artificial and Natural Intelligence Toulouse Institute (ANITI). The authors gratefully acknowledge the support of the  DEEL  project.</p>"},{"location":"#citation","title":"\ud83d\uddde\ufe0f Citation","text":"<p>This library has been built to support the work presented in the paper Achieving robustness in classification using optimaltransport with Hinge regularization which aim provable and efficient robustness by design.</p> <p>This work can be cited as:</p> <pre><code>@misc{2006.06520,\n    Author = {Mathieu Serrurier and Franck Mamalet and Alberto Gonz\u00e1lez-Sanz and Thibaut Boissin and Jean-Michel Loubes and Eustasio del Barrio},\n    Title = {Achieving robustness in classification using optimal transport with hinge regularization},\n    Year = {2020},\n    Eprint = {arXiv:2006.06520},\n}\n</code></pre>"},{"location":"#license","title":"\ud83d\udcdd License","text":"<p>The package is released under  MIT license.</p>"},{"location":"api/activations/","title":"deel.lip.activations","text":"<p>Warning</p> <p><code>deel.lip.activations</code> module is deprecated. All activation layers and functions are now available directly in <code>deel.lip.layers</code> module, e.g. <code>deel.lip.layers.GroupSort2</code>.</p> <p><code>deel.lip.activations</code> module is still available for retro-compatibility but will be definitely removed in deel-lip 1.6.0.</p>"},{"location":"api/callbacks/","title":"deel.lip.callbacks","text":"<p>This module contains callbacks that can be added to keras training process.</p>"},{"location":"api/callbacks/#deel.lip.callbacks.CondenseCallback","title":"CondenseCallback","text":"<pre><code>CondenseCallback(on_epoch=True, on_batch=False)\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Automatically condense layers of a model on batches/epochs. Condensing a layer consists in overwriting the kernel with the constrained weights. This prevents the explosion/vanishing of values inside the original kernel.</p> Warning <p>Overwriting the kernel may disturb the optimizer, especially if it has a non-zero momentum.</p> PARAMETER  DESCRIPTION <code>on_epoch</code> <p>if True apply the constraint between epochs</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>on_batch</code> <p>if True apply constraints between batches</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(self, on_epoch: bool = True, on_batch: bool = False):\n    \"\"\"\n    Automatically condense layers of a model on batches/epochs. Condensing a layer\n    consists in overwriting the kernel with the constrained weights. This prevents\n    the explosion/vanishing of values inside the original kernel.\n\n    Warning:\n        Overwriting the kernel may disturb the optimizer, especially if it has a\n        non-zero momentum.\n\n    Args:\n        on_epoch: if True apply the constraint between epochs\n        on_batch: if True apply constraints between batches\n    \"\"\"\n    super().__init__()\n    self.on_epoch = on_epoch\n    self.on_batch = on_batch\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.LossParamLog","title":"LossParamLog","text":"<pre><code>LossParamLog(param_name, rate=1)\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Logger to print values of a loss parameter at each epoch.</p> PARAMETER  DESCRIPTION <code>param_name</code> <p>name of the parameter of the loss to log.</p> <p> TYPE: <code>str</code> </p> <code>rate</code> <p>logging rate (in epochs)</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(self, param_name, rate=1):\n    \"\"\"\n    Logger to print values of a loss parameter at each epoch.\n\n    Args:\n        param_name (str): name of the parameter of the loss to log.\n        rate (int): logging rate (in epochs)\n    \"\"\"\n    self.param_name = param_name\n    self.rate = rate\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.LossParamScheduler","title":"LossParamScheduler","text":"<pre><code>LossParamScheduler(param_name, fp, xp, step=0)\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Scheduler to modify a loss parameter during training. It uses a linear interpolation (defined by fp and xp) depending on the optimization step.</p> PARAMETER  DESCRIPTION <code>param_name</code> <p>name of the parameter of the loss to tune. Must be a tf.Variable.</p> <p> TYPE: <code>str</code> </p> <code>fp</code> <p>values of the loss parameter as steps given by the xp.</p> <p> TYPE: <code>list</code> </p> <code>xp</code> <p>step where the parameter equals fp.</p> <p> TYPE: <code>list</code> </p> <code>step</code> <p>step value, for serialization/deserialization purposes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(self, param_name, fp, xp, step=0):\n    \"\"\"\n    Scheduler to modify a loss parameter during training. It uses a linear\n    interpolation (defined by fp and xp) depending on the optimization step.\n\n    Args:\n        param_name (str): name of the parameter of the loss to tune. Must be a\n            tf.Variable.\n        fp (list): values of the loss parameter as steps given by the xp.\n        xp (list): step where the parameter equals fp.\n        step (int): step value, for serialization/deserialization purposes.\n    \"\"\"\n    self.xp = xp\n    self.fp = fp\n    self.step = step\n    self.param_name = param_name\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.MonitorCallback","title":"MonitorCallback","text":"<pre><code>MonitorCallback(\n    monitored_layers,\n    logdir,\n    target=\"kernel\",\n    what=\"max\",\n    on_epoch=True,\n    on_batch=False,\n)\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Allow to monitor the singular values of specified layers during training. This analyze the singular values of the original kernel (before reparametrization). Two modes can be chosen: \"max\" plots the largest singular value over training, while \"all\" plots the distribution of the singular values over training (series of distribution).</p> PARAMETER  DESCRIPTION <code>monitored_layers</code> <p>list of layer name to monitor.</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>logdir</code> <p>path to the logging directory.</p> <p> TYPE: <code>str</code> </p> <code>target</code> <p>describe what to monitor, can either \"kernel\" or \"wbar\". Setting to \"kernel\" check values of the unconstrained weights while setting to \"wbar\" check values of the constrained weights (allowing to check if the parameters are correct to ensure lipschitz constraint)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'kernel'</code> </p> <code>what</code> <p>either \"max\", which display the largest singular value over the training process, or \"all\", which plot the distribution of all singular values.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'max'</code> </p> <code>on_epoch</code> <p>if True apply the constraint between epochs.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>on_batch</code> <p>if True apply constraints between batches.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(\n    self,\n    monitored_layers: Iterable[str],\n    logdir: str,\n    target: str = \"kernel\",\n    what: str = \"max\",\n    on_epoch: bool = True,\n    on_batch: bool = False,\n):\n    \"\"\"\n    Allow to monitor the singular values of specified layers during training. This\n    analyze the singular values of the original kernel (before reparametrization).\n    Two modes can be chosen: \"max\" plots the largest singular value over training,\n    while \"all\" plots the distribution of the singular values over training (series\n    of distribution).\n\n    Args:\n        monitored_layers: list of layer name to monitor.\n        logdir: path to the logging directory.\n        target: describe what to monitor, can either \"kernel\" or \"wbar\". Setting\n            to \"kernel\" check values of the unconstrained weights while setting to\n            \"wbar\" check values of the constrained weights (allowing to check if\n            the parameters are correct to ensure lipschitz constraint)\n        what: either \"max\", which display the largest singular value over the\n            training process, or \"all\", which plot the distribution of all singular\n            values.\n        on_epoch: if True apply the constraint between epochs.\n        on_batch: if True apply constraints between batches.\n    \"\"\"\n    self.on_epoch = on_epoch\n    self.on_batch = on_batch\n    assert target in {\"kernel\", \"wbar\"}\n    self.target = target\n    assert what in {\"max\", \"all\"}\n    self.what = what\n    self.logdir = logdir\n    self.file_writer = tf.summary.create_file_writer(\n        os.path.join(logdir, \"metrics\")\n    )\n    self.monitored_layers = monitored_layers\n    if on_batch and on_epoch:\n        self.on_epoch = False  # avoid display bug (inconsistent steps)\n    self.epochs = 0\n    super().__init__()\n</code></pre>"},{"location":"api/compute_layer_sv/","title":"Compute layer sv","text":"<p>Compute the largest and lowest singular values of a layer or network.</p> <p>The singular values are computed using the SVD decomposition of the weight matrix. For convolutional layers, the equivalent matrix is computed and the SVD is applied on it.</p> <p>The <code>compute_layer_sv()</code> function is the main function to compute the singular values of a given layer. It supports by default several kinds of layers (Conv2D, Dense, Add, BatchNormalization, ReLU, Activation, and deel-lip layers). For other layers, the user can provide a supplementary_type2sv dictionary linking a new layer type with a user-defined function to compute the singular values.</p> <p>The function <code>compute_model_sv()</code> computes the singular values of all layers in a model. It returns a dictionary indicating for each layer name a tuple (min sv, max sv).</p>"},{"location":"api/compute_layer_sv/#deel.lip.compute_layer_sv.compute_layer_sv","title":"compute_layer_sv","text":"<pre><code>compute_layer_sv(layer, supplementary_type2sv={})\n</code></pre> <p>Compute the largest and lowest singular values (or upper and lower bounds) of a given layer.</p> <p>In case of Condensable layers, a vanilla_export is applied to the layer to get the weights. Support by default several kind of layers (Conv2D,Dense,Add, BatchNormalization, ReLU, Activation, and deel-lip layers)</p> PARAMETER  DESCRIPTION <code>layer</code> <p>a single tf.keras.layer</p> <p> TYPE: <code>Layer</code> </p> <code>supplementary_type2sv</code> <p>a dictionary linking new layer type with user-defined function to compute the singular values. Defaults to {}.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <p>Returns:     tuple: a 2-tuple with lowest and largest singular values.</p> Source code in <code>deel/lip/compute_layer_sv.py</code> <pre><code>def compute_layer_sv(layer, supplementary_type2sv={}):\n    \"\"\"\n    Compute the largest and lowest singular values (or upper and lower bounds)\n    of a given layer.\n\n    In case of Condensable layers, a vanilla_export is applied to the layer\n    to get the weights.\n    Support by default several kind of layers (Conv2D,Dense,Add, BatchNormalization,\n    ReLU, Activation, and deel-lip layers)\n\n    Args:\n        layer (tf.keras.layers.Layer): a single tf.keras.layer\n        supplementary_type2sv (dict, optional): a dictionary linking new layer type with\n            user-defined function to compute the singular values. Defaults to {}.\n    Returns:\n        tuple: a 2-tuple with lowest and largest singular values.\n    \"\"\"\n    default_type2sv = {\n        tf.keras.layers.Conv2D: _compute_sv_conv2d_layer,\n        tf.keras.layers.Conv2DTranspose: _compute_sv_conv2d_layer,\n        PadConv2D: _compute_sv_conv2d_layer,\n        tf.keras.layers.Dense: _compute_sv_dense,\n        tf.keras.layers.ReLU: _compute_sv_activation,\n        tf.keras.layers.Activation: _compute_sv_activation,\n        GroupSort: _compute_sv_activation,\n        MaxMin: _compute_sv_activation,\n        tf.keras.layers.Add: _compute_sv_add,\n        tf.keras.layers.BatchNormalization: _compute_sv_bn,\n    }\n    input_shape = layer.input_shape\n    if isinstance(layer, Condensable):\n        layer.condense()\n        layer = layer.vanilla_export()\n    if type(layer) in default_type2sv.keys():\n        return default_type2sv[type(layer)](layer, input_shape)\n    elif type(layer) in supplementary_type2sv.keys():\n        return supplementary_type2sv[type(layer)](layer, input_shape)\n    else:\n        return (None, None)\n</code></pre>"},{"location":"api/compute_layer_sv/#deel.lip.compute_layer_sv.compute_model_sv","title":"compute_model_sv","text":"<pre><code>compute_model_sv(model, supplementary_type2sv={})\n</code></pre> <p>Compute the largest and lowest singular values of all layers in a model.</p> PARAMETER  DESCRIPTION <code>model</code> <p>a tf.keras Model or Sequential.</p> <p> TYPE: <code>Model</code> </p> <code>supplementary_type2sv</code> <p>a dictionary linking new layer type with user defined function to compute the min and max singular values.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>A dictionary indicating for each layer name a tuple (min sv, max sv)</p> Source code in <code>deel/lip/compute_layer_sv.py</code> <pre><code>def compute_model_sv(model, supplementary_type2sv={}):\n    \"\"\"Compute the largest and lowest singular values of all layers in a model.\n\n    Args:\n        model (tf.keras.Model): a tf.keras Model or Sequential.\n        supplementary_type2sv (dict, optional): a dictionary linking new layer type\n            with user defined function to compute the min and max singular values.\n\n    Returns:\n        dict: A dictionary indicating for each layer name a tuple (min sv, max sv)\n    \"\"\"\n    list_sv = []\n    for layer in model.layers:\n        if isinstance(layer, tf.keras.Model):\n            list_sv.append((layer.name, (None, None)))\n            list_sv += compute_model_sv(layer, supplementary_type2sv)\n        else:\n            list_sv.append((layer.name, compute_layer_sv(layer, supplementary_type2sv)))\n    return list_sv\n</code></pre>"},{"location":"api/constraints/","title":"deel.lip.constraints","text":"<p>This module contains extra constraint objects. These object can be added as params to regular layers.</p>"},{"location":"api/constraints/#deel.lip.constraints.AutoWeightClipConstraint","title":"AutoWeightClipConstraint","text":"<pre><code>AutoWeightClipConstraint(scale=1)\n</code></pre> <p>             Bases: <code>Constraint</code></p> <p>Clips the weights incident to each hidden unit to be inside the range <code>[-c,+c]</code>. With c = 1/sqrt(size(kernel)).</p> PARAMETER  DESCRIPTION <code>scale</code> <p>scaling factor to increase/decrease clipping value.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1</code> </p> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(self, scale=1):\n    \"\"\"\n    Clips the weights incident to each hidden unit to be inside the range `[-c,+c]`.\n    With c = 1/sqrt(size(kernel)).\n\n    Args:\n        scale (float): scaling factor to increase/decrease clipping value.\n    \"\"\"\n    self.scale = scale\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.FrobeniusConstraint","title":"FrobeniusConstraint","text":"<pre><code>FrobeniusConstraint(eps=1e-07)\n</code></pre> <p>             Bases: <code>Constraint</code></p> <p>Constrain the weights by dividing the weight matrix by it's L2 norm.</p> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(self, eps=1e-7):\n    \"\"\"\n    Constrain the weights by dividing the weight matrix by it's L2 norm.\n    \"\"\"\n    self.eps = eps\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.SpectralConstraint","title":"SpectralConstraint","text":"<pre><code>SpectralConstraint(\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    u=None,\n)\n</code></pre> <p>             Bases: <code>Constraint</code></p> <p>Ensure that all singular values of the weight matrix equals to 1. Computation based on Bjorck algorithm. The computation is done in two steps:</p> <ol> <li>reduce the larget singular value to k_coef_lip, using iterate power method.</li> <li>increase other singular values to k_coef_lip, using bjorck algorithm.</li> </ol> PARAMETER  DESCRIPTION <code>k_coef_lip</code> <p>lipschitz coefficient of the weight matrix</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>eps_bjorck</code> <p>stopping criterion Bjorck algorithm.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta_bjorck</code> <p>beta parameter in bjorck algorithm.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>u</code> <p>vector used for iterated power method, can be set to None (used for serialization/deserialization purposes).</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(\n    self,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    u=None,\n) -&gt; None:\n    \"\"\"\n    Ensure that *all* singular values of the weight matrix equals to 1. Computation\n    based on Bjorck algorithm. The computation is done in two steps:\n\n    1. reduce the larget singular value to k_coef_lip, using iterate power method.\n    2. increase other singular values to k_coef_lip, using bjorck algorithm.\n\n    Args:\n        k_coef_lip (float): lipschitz coefficient of the weight matrix\n        eps_spectral (float): stopping criterion for the iterative power algorithm.\n        eps_bjorck (float): stopping criterion Bjorck algorithm.\n        beta_bjorck (float): beta parameter in bjorck algorithm.\n        u (tf.Tensor): vector used for iterated power method, can be set to None\n            (used for serialization/deserialization purposes).\n    \"\"\"\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.k_coef_lip = k_coef_lip\n    if not (isinstance(u, tf.Tensor) or (u is None)):\n        u = tf.convert_to_tensor(u)\n    self.u = u\n    super(SpectralConstraint, self).__init__()\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.WeightClipConstraint","title":"WeightClipConstraint","text":"<pre><code>WeightClipConstraint(c=2)\n</code></pre> <p>             Bases: <code>Constraint</code></p> <p>Clips the weights incident to each hidden unit to be inside the range <code>[-c,+c]</code>.</p> PARAMETER  DESCRIPTION <code>c</code> <p>clipping parameter.</p> <p> TYPE: <code>float</code> DEFAULT: <code>2</code> </p> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(self, c=2):\n    \"\"\"\n    Clips the weights incident to each hidden unit to be inside the range `[-c,+c]`.\n\n    Args:\n        c (float): clipping parameter.\n    \"\"\"\n    self.c = c\n</code></pre>"},{"location":"api/initializers/","title":"deel.lip.initializers","text":"<p>This module contains extra Keras initializers, e.g. SpectralInitializer for 1-Lipschitz matrix initialization. They can be used as kernel initializers in any Keras layer.</p>"},{"location":"api/initializers/#deel.lip.initializers.SpectralInitializer","title":"SpectralInitializer","text":"<pre><code>SpectralInitializer(\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    k_coef_lip=1.0,\n    base_initializer=\"orthogonal\",\n)\n</code></pre> <p>             Bases: <code>Initializer</code></p> <p>Initialize a kernel to be 1-lipschitz orthogonal using bjorck normalization.</p> PARAMETER  DESCRIPTION <code>eps_spectral</code> <p>stopping criterion of iterative power method</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>eps_bjorck</code> <p>float greater than 0, stopping criterion of bjorck algorithm, setting it to None disable orthogonalization</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta_bjorck</code> <p>beta parameter of bjorck algorithm</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>base_initializer</code> <p>method used to generate weights before applying the orthonormalization</p> <p> TYPE: <code>str</code> DEFAULT: <code>'orthogonal'</code> </p> Source code in <code>deel/lip/initializers.py</code> <pre><code>def __init__(\n    self,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    k_coef_lip=1.0,\n    base_initializer=\"orthogonal\",\n) -&gt; None:\n    \"\"\"\n    Initialize a kernel to be 1-lipschitz orthogonal using bjorck\n    normalization.\n\n    Args:\n        eps_spectral (float): stopping criterion of iterative power method\n        eps_bjorck (float): float greater than 0, stopping criterion of\n            bjorck algorithm, setting it to None disable orthogonalization\n        beta_bjorck (float): beta parameter of bjorck algorithm\n        base_initializer (str): method used to generate weights before applying the\n            orthonormalization\n    \"\"\"\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.k_coef_lip = k_coef_lip\n    self.base_initializer = initializers.get(base_initializer)\n    super(SpectralInitializer, self).__init__()\n</code></pre>"},{"location":"api/layers/","title":"deel.lip.layers","text":"<p>The submodule <code>deel.lip.layers</code> contains all custom Keras layers to build Lipschitz-constrained neural networks. They all inherit from <code>keras.layers.Layer</code> from Keras API.</p>"},{"location":"api/layers/#deel.lip.layers.activations","title":"activations","text":"<p>This module contains extra activation functions which respect the Lipschitz constant. It can be added as a layer, or it can be used in the \"activation\" params for other layers.</p>"},{"location":"api/layers/#deel.lip.layers.activations.FullSort","title":"FullSort","text":"<pre><code>FullSort(**kwargs)\n</code></pre> <p>             Bases: <code>GroupSort</code></p> <p>FullSort activation. Special case of GroupSort where the entire input is sorted.</p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    FullSort activation. Special case of GroupSort where the entire input is sorted.\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    kwargs[\"n\"] = None\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.GroupSort","title":"GroupSort","text":"<pre><code>GroupSort(\n    n=None,\n    data_format=\"channels_last\",\n    k_coef_lip=1.0,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Layer</code>, <code>LipschitzLayer</code></p> <p>GroupSort activation</p> PARAMETER  DESCRIPTION <code>n</code> <p>group size used when sorting. When None group size is set to input size (fullSort behavior)</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>data_format</code> <p>either channels_first or channels_last</p> <p> TYPE: <code>str</code> DEFAULT: <code>'channels_last'</code> </p> <code>k_coef_lip</code> <p>the lipschitz coefficient to be enforced</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>**kwargs</code> <p>params passed to layers (named fashion)</p> <p> DEFAULT: <code>{}</code> </p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, n=None, data_format=\"channels_last\", k_coef_lip=1.0, **kwargs):\n    \"\"\"\n    GroupSort activation\n\n    Args:\n        n (int): group size used when sorting. When None group size is set to input\n            size (fullSort behavior)\n        data_format (str): either channels_first or channels_last\n        k_coef_lip (float): the lipschitz coefficient to be enforced\n        **kwargs: params passed to layers (named fashion)\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    self.set_klip_factor(k_coef_lip)\n    super(GroupSort, self).__init__(**kwargs)\n    if data_format == \"channels_last\":\n        self.channel_axis = -1\n    elif data_format == \"channels_first\":\n        raise RuntimeError(\n            \"channels_first not implemented for GroupSort activation\"\n        )\n    else:\n        raise RuntimeError(\"data format not understood\")\n    self.n = n\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.GroupSort2","title":"GroupSort2","text":"<pre><code>GroupSort2(**kwargs)\n</code></pre> <p>             Bases: <code>GroupSort</code></p> <p>GroupSort2 activation. Special case of GroupSort with group of size 2.</p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    GroupSort2 activation. Special case of GroupSort with group of size 2.\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    kwargs[\"n\"] = 2\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.Householder","title":"Householder","text":"<pre><code>Householder(\n    data_format=\"channels_last\",\n    k_coef_lip=1.0,\n    theta_initializer=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Layer</code>, <code>LipschitzLayer</code></p> <p>Householder activation: this review From this repository</p> PARAMETER  DESCRIPTION <code>data_format</code> <p>either channels_first or channels_last. Only channels_last is supported.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'channels_last'</code> </p> <code>k_coef_lip</code> <p>The lipschitz coefficient to be enforced.</p> <p> TYPE: <code>str</code> DEFAULT: <code>1.0</code> </p> <code>theta_initializer</code> <p>initializer for the angle theta of reflection. Defaults to pi/2, which corresponds to GroupSort2.</p> <p> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>parameters passed to the <code>tf.keras.layers.Layer</code>.</p> <p> DEFAULT: <code>{}</code> </p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(\n    self,\n    data_format=\"channels_last\",\n    k_coef_lip=1.0,\n    theta_initializer=None,\n    **kwargs,\n):\n    \"\"\"\n    Householder activation:\n    [this review](https://openreview.net/pdf?id=tD7eCtaSkR)\n    From [this repository](https://github.com/singlasahil14/SOC)\n\n    Args:\n        data_format (str): either channels_first or channels_last. Only\n            channels_last is supported.\n        k_coef_lip (str): The lipschitz coefficient to be enforced.\n        theta_initializer: initializer for the angle theta of reflection. Defaults\n            to pi/2, which corresponds to GroupSort2.\n        **kwargs: parameters passed to the `tf.keras.layers.Layer`.\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    if data_format != \"channels_last\":\n        raise RuntimeError(\"Only 'channels_last' data format is supported\")\n\n    self.data_format = data_format\n    self.set_klip_factor(k_coef_lip)\n    self.theta_initializer = theta_initializer\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.MaxMin","title":"MaxMin","text":"<pre><code>MaxMin(\n    data_format=\"channels_last\", k_coef_lip=1.0, **kwargs\n)\n</code></pre> <p>             Bases: <code>Layer</code>, <code>LipschitzLayer</code></p> <p>MaxMin activation [Relu(x),reLU(-x)]</p> PARAMETER  DESCRIPTION <code>data_format</code> <p>either channels_first or channels_last</p> <p> TYPE: <code>str</code> DEFAULT: <code>'channels_last'</code> </p> <code>k_coef_lip</code> <p>the lipschitz coefficient to be enforced</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>**kwargs</code> <p>params passed to layers (named fashion)</p> <p> DEFAULT: <code>{}</code> </p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Double channel size as input.</p> References <p>([M. Blot, M. Cord, et N. Thome, \u00ab\u00a0Max-min convolutional neural networks for image classification\u00a0\u00bb, in 2016 IEEE International Conference on Image Processing (ICIP), Phoenix, AZ, USA, 2016, p. 3678\u20113682.)</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, data_format=\"channels_last\", k_coef_lip=1.0, **kwargs):\n    \"\"\"\n    MaxMin activation [Relu(x),reLU(-x)]\n\n    Args:\n        data_format (str): either channels_first or channels_last\n        k_coef_lip (float): the lipschitz coefficient to be enforced\n        **kwargs: params passed to layers (named fashion)\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Double channel size as input.\n\n    References:\n        ([M. Blot, M. Cord, et N. Thome, \u00ab\u00a0Max-min convolutional neural networks\n        for image classification\u00a0\u00bb, in 2016 IEEE International Conference on Image\n        Processing (ICIP), Phoenix, AZ, USA, 2016, p. 3678\u20113682.)\n\n    \"\"\"\n    self.set_klip_factor(k_coef_lip)\n    super(MaxMin, self).__init__(**kwargs)\n    if data_format == \"channels_last\":\n        self.channel_axis = -1\n    elif data_format == \"channels_first\":\n        self.channel_axis = 1\n    else:\n        raise RuntimeError(\"data format not understood\")\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.PReLUlip","title":"PReLUlip","text":"<pre><code>PReLUlip(k_coef_lip=1.0)\n</code></pre> <p>PreLu activation, with Lipschitz constraint.</p> PARAMETER  DESCRIPTION <code>k_coef_lip</code> <p>lipschitz coefficient to be enforced</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"PReLUlip\")\ndef PReLUlip(k_coef_lip=1.0):\n    \"\"\"\n    PreLu activation, with Lipschitz constraint.\n\n    Args:\n        k_coef_lip (float): lipschitz coefficient to be enforced\n    \"\"\"\n    return PReLU(\n        alpha_constraint=MinMaxNorm(min_value=-k_coef_lip, max_value=k_coef_lip)\n    )\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer","title":"base_layer","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.Condensable","title":"Condensable","text":"<p>             Bases: <code>ABC</code></p> <p>Some Layers don't optimize directly the kernel, this means that the kernel stored in the layer is not the kernel used to make predictions (called W_bar), To address this, these layers can implement the condense() function that make self.kernel equal to W_bar. This operation also allows to turn the Lipschitz layer to its keras equivalent e.g. The Dense layer that have the same predictions as the trained SpectralDense.</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.Condensable.condense","title":"condense  <code>abstractmethod</code>","text":"<pre><code>condense()\n</code></pre> <p>The condense operation allows to overwrite the kernel and ensure that other variables are still consistent. Returns:     None</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>@abc.abstractmethod\ndef condense(self):\n    \"\"\"\n    The condense operation allows to overwrite the kernel and ensure that other\n    variables are still consistent.\n    Returns:\n        None\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer.Condensable.vanilla_export","title":"vanilla_export  <code>abstractmethod</code>","text":"<pre><code>vanilla_export()\n</code></pre> <p>This operation allows to turn this Layer to its super type, easing storage and serving. Returns:      self as super type</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>@abc.abstractmethod\ndef vanilla_export(self):\n    \"\"\"\n    This operation allows to turn this Layer to its super type, easing storage and\n    serving.\n    Returns:\n         self as super type\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer","title":"LipschitzLayer","text":"<p>             Bases: <code>ABC</code></p> <p>This class allows to set Lipschitz factor of a layer. Lipschitz layer must inherit this class to allow user to set the Lipschitz factor. Warning:      This class only regroups useful functions when developing new Lipschitz layers.      But it does not ensure any property about the layer. This means that      inheriting from this class won't ensure anything about the Lipschitz constant.</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer.coef_lip","title":"coef_lip  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>coef_lip = None\n</code></pre> <p>define correction coefficient (ie. Lipschitz bound ) of the layer ( multiply the output of the layer by this constant )</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer.k_coef_lip","title":"k_coef_lip  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>k_coef_lip = 1.0\n</code></pre> <p>variable used to store the lipschitz factor</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer.set_klip_factor","title":"set_klip_factor","text":"<pre><code>set_klip_factor(klip_factor)\n</code></pre> <p>Allow to set the Lipschitz factor of a layer. Args:     klip_factor (float): the Lipschitz factor the user want to ensure. Returns:     None</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>def set_klip_factor(self, klip_factor):\n    \"\"\"\n    Allow to set the Lipschitz factor of a layer.\n    Args:\n        klip_factor (float): the Lipschitz factor the user want to ensure.\n    Returns:\n        None\n    \"\"\"\n    self.k_coef_lip = klip_factor\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional","title":"convolutional","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.convolutional.FrobeniusConv2D","title":"FrobeniusConv2D","text":"<pre><code>FrobeniusConv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Conv2D</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>Same as SpectralConv2D but in the case of a single output.</p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    **kwargs,\n):\n    if strides not in ((1, 1), [1, 1], 1):\n        raise RuntimeError(\"FrobeniusConv2D does not support strides\")\n    if dilation_rate not in ((1, 1), [1, 1], 1):\n        raise RuntimeError(\"FrobeniusConv2D does not support dilation rate\")\n    if padding != \"same\":\n        raise RuntimeError(\"FrobeniusConv2D only supports padding='same'\")\n    if not (\n        (kernel_constraint is None)\n        or isinstance(kernel_constraint, SpectralConstraint)\n    ):\n        raise RuntimeError(\n            \"only deellip constraints are allowed as other constraints could break\"\n            \" 1 lipschitz condition\"\n        )\n    super(FrobeniusConv2D, self).__init__(\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs,\n    )\n    self.set_klip_factor(k_coef_lip)\n    self.wbar = None\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional.SpectralConv2D","title":"SpectralConv2D","text":"<pre><code>SpectralConv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Conv2D</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>This class is a Conv2D Layer constrained such that all singular of it's kernel are 1. The computation based on Bjorck algorithm. As this is not enough to ensure 1 Lipschitzity a coertive coefficient is applied on the output. The computation is done in three steps:</p> <ol> <li>reduce the largest singular value to 1, using iterated power method.</li> <li>increase other singular values to 1, using Bjorck algorithm.</li> <li>divide the output by the Lipschitz bound to ensure k Lipschitzity.</li> </ol> PARAMETER  DESCRIPTION <code>filters</code> <p>Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).</p> <p> </p> <code>kernel_size</code> <p>An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.</p> <p> </p> <code>strides</code> <p>An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p> <p> DEFAULT: <code>(1, 1)</code> </p> <code>padding</code> <p>one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</p> <p> DEFAULT: <code>'same'</code> </p> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <p> DEFAULT: <code>None</code> </p> <code>dilation_rate</code> <p>an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride value != 1.</p> <p> DEFAULT: <code>(1, 1)</code> </p> <code>activation</code> <p>Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: <code>a(x) = x</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>use_bias</code> <p>Boolean, whether the layer uses a bias vector.</p> <p> DEFAULT: <code>True</code> </p> <code>kernel_initializer</code> <p>Initializer for the <code>kernel</code> weights matrix.</p> <p> DEFAULT: <code>SpectralInitializer()</code> </p> <code>bias_initializer</code> <p>Initializer for the bias vector.</p> <p> DEFAULT: <code>'zeros'</code> </p> <code>kernel_regularizer</code> <p>Regularizer function applied to the <code>kernel</code> weights matrix.</p> <p> DEFAULT: <code>None</code> </p> <code>bias_regularizer</code> <p>Regularizer function applied to the bias vector.</p> <p> DEFAULT: <code>None</code> </p> <code>activity_regularizer</code> <p>Regularizer function applied to the output of the layer (its \"activation\")..</p> <p> DEFAULT: <code>None</code> </p> <code>kernel_constraint</code> <p>Constraint function applied to the kernel matrix.</p> <p> DEFAULT: <code>None</code> </p> <code>bias_constraint</code> <p>Constraint function applied to the bias vector.</p> <p> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>lipschitz constant to ensure</p> <p> DEFAULT: <code>1.0</code> </p> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <p> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>eps_bjorck</code> <p>stopping criterion Bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta_bjorck</code> <p>beta parameter in bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration.</p> <p> DEFAULT: <code>DEFAULT_MAXITER_SPECTRAL</code> </p> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_MAXITER_BJORCK</code> </p> <p>This documentation reuse the body of the original keras.layers.Conv2D doc.</p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs,\n):\n    \"\"\"\n    This class is a Conv2D Layer constrained such that all singular of it's kernel\n    are 1. The computation based on Bjorck algorithm. As this is not\n    enough to ensure 1 Lipschitzity a coertive coefficient is applied on the\n    output.\n    The computation is done in three steps:\n\n    1. reduce the largest singular value to 1, using iterated power method.\n    2. increase other singular values to 1, using Bjorck algorithm.\n    3. divide the output by the Lipschitz bound to ensure k Lipschitzity.\n\n    Args:\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        dilation_rate: an integer or tuple/list of 2 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use.\n            If you don't specify anything, no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix.\n        bias_initializer: Initializer for the bias vector.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix.\n        bias_regularizer: Regularizer function applied to the bias vector.\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \"activation\")..\n        kernel_constraint: Constraint function applied to the kernel matrix.\n        bias_constraint: Constraint function applied to the bias vector.\n        k_coef_lip: lipschitz constant to ensure\n        eps_spectral: stopping criterion for the iterative power algorithm.\n        eps_bjorck: stopping criterion Bjorck algorithm.\n        beta_bjorck: beta parameter in bjorck algorithm.\n        maxiter_spectral: maximum number of iterations for the power iteration.\n        maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n\n    This documentation reuse the body of the original keras.layers.Conv2D doc.\n    \"\"\"\n    if dilation_rate not in ((1, 1), [1, 1], 1):\n        raise RuntimeError(\"SpectralConv2D does not support dilation rate\")\n    if padding != \"same\":\n        raise RuntimeError(\"SpectralConv2D only supports padding='same'\")\n    super(SpectralConv2D, self).__init__(\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs,\n    )\n    self._kwargs = kwargs\n    self.set_klip_factor(k_coef_lip)\n    self.u = None\n    self.sig = None\n    self.wbar = None\n    _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.maxiter_bjorck = maxiter_bjorck\n    self.maxiter_spectral = maxiter_spectral\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional.SpectralConv2DTranspose","title":"SpectralConv2DTranspose","text":"<pre><code>SpectralConv2DTranspose(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    output_padding=None,\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Conv2DTranspose</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>This class is a Conv2DTranspose layer constrained such that all singular values of its kernel are 1. The computation is based on Bj\u00f6rck orthogonalization algorithm.</p> <p>The computation is done in three steps: 1. reduce the largest singular value to 1, using iterated power method. 2. increase other singular values to 1, using Bj\u00f6rck algorithm. 3. divide the output by the Lipschitz target K to ensure K-Lipschitzity.</p> <p>This documentation reuses the body of the original <code>tf.keras.layers.Conv2DTranspose</code> doc.</p> PARAMETER  DESCRIPTION <code>filters</code> <p>Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).</p> <p> </p> <code>kernel_size</code> <p>An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.</p> <p> </p> <code>strides</code> <p>An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions.</p> <p> DEFAULT: <code>(1, 1)</code> </p> <code>padding</code> <p>only <code>\"same\"</code> padding is supported in this Lipschitz layer (case-insensitive).</p> <p> DEFAULT: <code>'same'</code> </p> <code>output_padding</code> <p>if set to <code>None</code> (default), the output shape is inferred. Only <code>None</code> value is supported in this Lipschitz layer.</p> <p> DEFAULT: <code>None</code> </p> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <p> DEFAULT: <code>None</code> </p> <code>dilation_rate</code> <p>an integer, specifying the dilation rate for all spatial dimensions for dilated convolution. This Lipschitz layer does not support dilation rate != 1.</p> <p> DEFAULT: <code>(1, 1)</code> </p> <code>activation</code> <p>Activation function to use. If you don't specify anything, no activation is applied (see <code>keras.activations</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>use_bias</code> <p>Boolean, whether the layer uses a bias vector.</p> <p> DEFAULT: <code>True</code> </p> <code>kernel_initializer</code> <p>Initializer for the <code>kernel</code> weights matrix (see <code>keras.initializers</code>). Defaults to <code>SpectralInitializer</code>.</p> <p> DEFAULT: <code>SpectralInitializer()</code> </p> <code>bias_initializer</code> <p>Initializer for the bias vector (see <code>keras.initializers</code>). Defaults to 'zeros'.</p> <p> DEFAULT: <code>'zeros'</code> </p> <code>kernel_regularizer</code> <p>Regularizer function applied to the <code>kernel</code> weights matrix (see <code>keras.regularizers</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>bias_regularizer</code> <p>Regularizer function applied to the bias vector (see <code>keras.regularizers</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>activity_regularizer</code> <p>Regularizer function applied to the output of the layer (its \"activation\") (see <code>keras.regularizers</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>kernel_constraint</code> <p>Constraint function applied to the kernel matrix (see <code>keras.constraints</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>bias_constraint</code> <p>Constraint function applied to the bias vector (see <code>keras.constraints</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>Lipschitz constant to ensure</p> <p> DEFAULT: <code>1.0</code> </p> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <p> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>eps_bjorck</code> <p>stopping criterion Bj\u00f6rck algorithm.</p> <p> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta_bjorck</code> <p>beta parameter in Bj\u00f6rck algorithm.</p> <p> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration.</p> <p> DEFAULT: <code>DEFAULT_MAXITER_SPECTRAL</code> </p> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_MAXITER_BJORCK</code> </p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    output_padding=None,\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs,\n):\n    \"\"\"\n    This class is a Conv2DTranspose layer constrained such that all singular values\n    of its kernel are 1. The computation is based on Bj\u00f6rck orthogonalization\n    algorithm.\n\n    The computation is done in three steps:\n    1. reduce the largest singular value to 1, using iterated power method.\n    2. increase other singular values to 1, using Bj\u00f6rck algorithm.\n    3. divide the output by the Lipschitz target K to ensure K-Lipschitzity.\n\n    This documentation reuses the body of the original\n    `tf.keras.layers.Conv2DTranspose` doc.\n\n    Args:\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        padding: only `\"same\"` padding is supported in this Lipschitz layer\n            (case-insensitive).\n        output_padding: if set to `None` (default), the output shape is inferred.\n            Only `None` value is supported in this Lipschitz layer.\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        dilation_rate: an integer, specifying the dilation rate for all spatial\n            dimensions for dilated convolution. This Lipschitz layer does not\n            support dilation rate != 1.\n        activation: Activation function to use.\n            If you don't specify anything, no activation is applied\n            (see `keras.activations`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see `keras.initializers`). Defaults to `SpectralInitializer`.\n        bias_initializer: Initializer for the bias vector\n            (see `keras.initializers`). Defaults to 'zeros'.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix (see `keras.regularizers`).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see `keras.regularizers`).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \"activation\") (see `keras.regularizers`).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see `keras.constraints`).\n        bias_constraint: Constraint function applied to the bias vector\n            (see `keras.constraints`).\n        k_coef_lip: Lipschitz constant to ensure\n        eps_spectral: stopping criterion for the iterative power algorithm.\n        eps_bjorck: stopping criterion Bj\u00f6rck algorithm.\n        beta_bjorck: beta parameter in Bj\u00f6rck algorithm.\n        maxiter_spectral: maximum number of iterations for the power iteration.\n        maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n    \"\"\"\n    super().__init__(\n        filters,\n        kernel_size,\n        strides,\n        padding,\n        output_padding,\n        data_format,\n        dilation_rate,\n        activation,\n        use_bias,\n        kernel_initializer,\n        bias_initializer,\n        kernel_regularizer,\n        bias_regularizer,\n        activity_regularizer,\n        kernel_constraint,\n        bias_constraint,\n        **kwargs,\n    )\n\n    if self.dilation_rate != (1, 1):\n        raise ValueError(\"SpectralConv2DTranspose does not support dilation rate\")\n    if self.padding != \"same\":\n        raise ValueError(\"SpectralConv2DTranspose only supports padding='same'\")\n    if self.output_padding is not None:\n        raise ValueError(\n            \"SpectralConv2DTranspose only supports output_padding=None\"\n        )\n    self.set_klip_factor(k_coef_lip)\n    self.u = None\n    self.sig = None\n    self.wbar = None\n    _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.maxiter_bjorck = maxiter_bjorck\n    self.maxiter_spectral = maxiter_spectral\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.dense","title":"dense","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.dense.FrobeniusDense","title":"FrobeniusDense","text":"<pre><code>FrobeniusDense(\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    disjoint_neurons=True,\n    k_coef_lip=1.0,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Dense</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>Identical and faster than a SpectralDense in the case of a single output. In the multi-neurons setting, this layer can be used: - as a classical Frobenius Dense normalization (disjoint_neurons=False) - as a stacking of 1 lipschitz independent neurons (each output is 1-lipschitz, but the no orthogonality is enforced between outputs )  (disjoint_neurons=True).</p> Warning <p>default is disjoint_neurons = True</p> Source code in <code>deel/lip/layers/dense.py</code> <pre><code>def __init__(\n    self,\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    disjoint_neurons=True,\n    k_coef_lip=1.0,\n    **kwargs\n):\n    super().__init__(\n        units=units,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self.disjoint_neurons = disjoint_neurons\n    self.axis_norm = None\n    self.wbar = None\n    if self.disjoint_neurons:\n        self.axis_norm = 0\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.dense.SpectralDense","title":"SpectralDense","text":"<pre><code>SpectralDense(\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Dense</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>This class is a Dense Layer constrained such that all singular of it's kernel are 1. The computation based on Bjorck algorithm. The computation is done in two steps:</p> <ol> <li>reduce the larget singular value to 1, using iterated power method.</li> <li>increase other singular values to 1, using Bjorck algorithm.</li> </ol> PARAMETER  DESCRIPTION <code>units</code> <p>Positive integer, dimensionality of the output space.</p> <p> </p> <code>activation</code> <p>Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: <code>a(x) = x</code>).</p> <p> DEFAULT: <code>None</code> </p> <code>use_bias</code> <p>Boolean, whether the layer uses a bias vector.</p> <p> DEFAULT: <code>True</code> </p> <code>kernel_initializer</code> <p>Initializer for the <code>kernel</code> weights matrix.</p> <p> DEFAULT: <code>SpectralInitializer()</code> </p> <code>bias_initializer</code> <p>Initializer for the bias vector.</p> <p> DEFAULT: <code>'zeros'</code> </p> <code>kernel_regularizer</code> <p>Regularizer function applied to the <code>kernel</code> weights matrix.</p> <p> DEFAULT: <code>None</code> </p> <code>bias_regularizer</code> <p>Regularizer function applied to the bias vector.</p> <p> DEFAULT: <code>None</code> </p> <code>activity_regularizer</code> <p>Regularizer function applied to the output of the layer (its \"activation\")..</p> <p> DEFAULT: <code>None</code> </p> <code>kernel_constraint</code> <p>Constraint function applied to the <code>kernel</code> weights matrix.</p> <p> DEFAULT: <code>None</code> </p> <code>bias_constraint</code> <p>Constraint function applied to the bias vector.</p> <p> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>lipschitz constant to ensure</p> <p> DEFAULT: <code>1.0</code> </p> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <p> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>eps_bjorck</code> <p>stopping criterion Bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta_bjorck</code> <p>beta parameter in bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration.</p> <p> DEFAULT: <code>DEFAULT_MAXITER_SPECTRAL</code> </p> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm.</p> <p> DEFAULT: <code>DEFAULT_MAXITER_BJORCK</code> </p> Input shape <p>N-D tensor with shape: <code>(batch_size, ..., input_dim)</code>. The most common situation would be a 2D input with shape <code>(batch_size, input_dim)</code>.</p> Output shape <p>N-D tensor with shape: <code>(batch_size, ..., units)</code>. For instance, for a 2D input with shape <code>(batch_size, input_dim)</code>, the output would have shape <code>(batch_size, units)</code>.</p> <p>This documentation reuse the body of the original keras.layers.Dense doc.</p> Source code in <code>deel/lip/layers/dense.py</code> <pre><code>def __init__(\n    self,\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n):\n    \"\"\"\n    This class is a Dense Layer constrained such that all singular of it's kernel\n    are 1. The computation based on Bjorck algorithm.\n    The computation is done in two steps:\n\n    1. reduce the larget singular value to 1, using iterated power method.\n    2. increase other singular values to 1, using Bjorck algorithm.\n\n    Args:\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use.\n            If you don't specify anything, no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix.\n        bias_initializer: Initializer for the bias vector.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix.\n        bias_regularizer: Regularizer function applied to the bias vector.\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \"activation\")..\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix.\n        bias_constraint: Constraint function applied to the bias vector.\n        k_coef_lip: lipschitz constant to ensure\n        eps_spectral: stopping criterion for the iterative power algorithm.\n        eps_bjorck: stopping criterion Bjorck algorithm.\n        beta_bjorck: beta parameter in bjorck algorithm.\n        maxiter_spectral: maximum number of iterations for the power iteration.\n        maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n\n    Input shape:\n        N-D tensor with shape: `(batch_size, ..., input_dim)`.\n        The most common situation would be\n        a 2D input with shape `(batch_size, input_dim)`.\n\n    Output shape:\n        N-D tensor with shape: `(batch_size, ..., units)`.\n        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n        the output would have shape `(batch_size, units)`.\n\n    This documentation reuse the body of the original keras.layers.Dense doc.\n    \"\"\"\n    super(SpectralDense, self).__init__(\n        units=units,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs\n    )\n    self._kwargs = kwargs\n    self.set_klip_factor(k_coef_lip)\n    _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.maxiter_bjorck = maxiter_bjorck\n    self.maxiter_spectral = maxiter_spectral\n    self.u = None\n    self.sig = None\n    self.wbar = None\n    self.built = False\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling","title":"pooling","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.pooling.InvertibleDownSampling","title":"InvertibleDownSampling","text":"<pre><code>InvertibleDownSampling(\n    pool_size,\n    data_format=\"channels_last\",\n    name=None,\n    dtype=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>This pooling layer perform a reshape on the spacial dimensions: it take a (bs, h, w, c) ( if channels_last ) and reshape it to a (bs, h/p_h, w/p_w, cp_wp_h ), where p_w and p_h are the shape of the pool. By doing this the image size is reduced while the number of channels is increased.</p> References <p>Anil et al. paper</p> Note <p>The image shape must be divisible by the pool shape.</p> PARAMETER  DESCRIPTION <code>pool_size</code> <p>tuple describing the pool shape</p> <p> </p> <code>data_format</code> <p>can either be <code>channels_last</code> or <code>channels_first</code></p> <p> DEFAULT: <code>'channels_last'</code> </p> <code>name</code> <p>name of the layer</p> <p> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>dtype of the layer</p> <p> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>params passed to the Layers constructor</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self, pool_size, data_format=\"channels_last\", name=None, dtype=None, **kwargs\n):\n    \"\"\"\n\n    This pooling layer perform a reshape on the spacial dimensions: it take a\n    (bs, h, w, c) ( if channels_last ) and reshape it to a\n    (bs, h/p_h, w/p_w, c*p_w*p_h ), where p_w and p_h are the shape of the pool.\n    By doing this the image size is reduced while the number of channels is\n    increased.\n\n    References:\n        Anil et al. [paper](https://arxiv.org/abs/1911.00937)\n\n    Note:\n        The image shape must be divisible by the pool shape.\n\n    Args:\n        pool_size: tuple describing the pool shape\n        data_format: can either be `channels_last` or `channels_first`\n        name: name of the layer\n        dtype: dtype of the layer\n        **kwargs: params passed to the Layers constructor\n    \"\"\"\n    super(InvertibleDownSampling, self).__init__(name=name, dtype=dtype, **kwargs)\n    self.pool_size = pool_size\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.InvertibleUpSampling","title":"InvertibleUpSampling","text":"<pre><code>InvertibleUpSampling(\n    pool_size,\n    data_format=\"channels_last\",\n    name=None,\n    dtype=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Layer</code></p> <p>This Layer is the inverse of the InvertibleDownSampling layer. It take a (bs, h, w, c) ( if channels_last ) and reshape it to a (bs, h/p_h, w/p_w, cp_wp_h ), where p_w and p_h are the shape of the pool. By doing this the image size is reduced while the number of channels is increased.</p> References <p>Anil et al. paper</p> Note <p>The input number of channels must be divisible by the <code>p_w*p_h</code>.</p> PARAMETER  DESCRIPTION <code>pool_size</code> <p>tuple describing the pool shape (p_h, p_w)</p> <p> </p> <code>data_format</code> <p>can either be <code>channels_last</code> or <code>channels_first</code></p> <p> DEFAULT: <code>'channels_last'</code> </p> <code>name</code> <p>name of the layer</p> <p> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>dtype of the layer</p> <p> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>params passed to the Layers constructor</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self, pool_size, data_format=\"channels_last\", name=None, dtype=None, **kwargs\n):\n    \"\"\"\n\n    This Layer is the inverse of the InvertibleDownSampling layer. It take a\n    (bs, h, w, c) ( if channels_last ) and reshape it to a\n    (bs, h/p_h, w/p_w, c*p_w*p_h ), where p_w and p_h are the shape of the\n    pool. By doing this the image size is reduced while the number of\n    channels is increased.\n\n    References:\n        Anil et al. [paper](https://arxiv.org/abs/1911.00937)\n\n    Note:\n        The input number of channels must be divisible by the `p_w*p_h`.\n\n\n    Args:\n        pool_size: tuple describing the pool shape (p_h, p_w)\n        data_format: can either be `channels_last` or `channels_first`\n        name: name of the layer\n        dtype: dtype of the layer\n        **kwargs: params passed to the Layers constructor\n    \"\"\"\n    super(InvertibleUpSampling, self).__init__(name=name, dtype=dtype, **kwargs)\n    self.pool_size = pool_size\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledAveragePooling2D","title":"ScaledAveragePooling2D","text":"<pre><code>ScaledAveragePooling2D(\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None,\n    k_coef_lip=1.0,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>AveragePooling2D</code>, <code>LipschitzLayer</code></p> <p>Average pooling operation for spatial data, but with a lipschitz bound.</p> PARAMETER  DESCRIPTION <code>pool_size</code> <p>integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). <code>(2, 2)</code> will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.</p> <p> DEFAULT: <code>(2, 2)</code> </p> <code>strides</code> <p>Integer, tuple of 2 integers, or None. Strides values. If None, it will default to <code>pool_size</code>.</p> <p> DEFAULT: <code>None</code> </p> <code>padding</code> <p>One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</p> <p> DEFAULT: <code>'valid'</code> </p> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <p> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>the lipschitz factor to ensure</p> <p> DEFAULT: <code>1.0</code> </p> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> Output shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, pooled_rows, pooled_cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, pooled_rows, pooled_cols)</code>.</li> </ul> <p>This documentation reuse the body of the original keras.layers.AveragePooling2D doc.</p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self,\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None,\n    k_coef_lip=1.0,\n    **kwargs,\n):\n    \"\"\"\n    Average pooling operation for spatial data, but with a lipschitz bound.\n\n    Arguments:\n        pool_size: integer or tuple of 2 integers,\n            factors by which to downscale (vertical, horizontal).\n            `(2, 2)` will halve the input in both spatial dimension.\n            If only one integer is specified, the same window length\n            will be used for both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n            Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        k_coef_lip: the lipschitz factor to ensure\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n\n    This documentation reuse the body of the original keras.layers.AveragePooling2D\n    doc.\n    \"\"\"\n    if not ((strides == pool_size) or (strides is None)):\n        raise RuntimeError(\"stride must be equal to pool_size\")\n    if padding != \"valid\":\n        raise RuntimeError(\"ScaledAveragePooling2D only supports padding='valid'\")\n    super(ScaledAveragePooling2D, self).__init__(\n        pool_size=pool_size,\n        strides=pool_size,\n        padding=padding,\n        data_format=data_format,\n        **kwargs,\n    )\n    self.set_klip_factor(k_coef_lip)\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledGlobalAveragePooling2D","title":"ScaledGlobalAveragePooling2D","text":"<pre><code>ScaledGlobalAveragePooling2D(\n    data_format=None, k_coef_lip=1.0, **kwargs\n)\n</code></pre> <p>             Bases: <code>GlobalAveragePooling2D</code>, <code>LipschitzLayer</code></p> <p>Global average pooling operation for spatial data with Lipschitz bound.</p> PARAMETER  DESCRIPTION <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <p> DEFAULT: <code>None</code> </p> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> <p>Output shape: 2D tensor with shape <code>(batch_size, channels)</code>.</p> <p>This documentation reuse the body of the original keras.layers.GlobalAveragePooling doc.</p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(self, data_format=None, k_coef_lip=1.0, **kwargs):\n    \"\"\"Global average pooling operation for spatial data with Lipschitz bound.\n\n    Arguments:\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n    2D tensor with shape `(batch_size, channels)`.\n\n    This documentation reuse the body of the original\n    keras.layers.GlobalAveragePooling doc.\n    \"\"\"\n    super(ScaledGlobalAveragePooling2D, self).__init__(\n        data_format=data_format, **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledGlobalL2NormPooling2D","title":"ScaledGlobalL2NormPooling2D","text":"<pre><code>ScaledGlobalL2NormPooling2D(\n    data_format=None,\n    k_coef_lip=1.0,\n    eps_grad_sqrt=1e-06,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>GlobalAveragePooling2D</code>, <code>LipschitzLayer</code></p> <p>Average pooling operation for spatial data, with a lipschitz bound. This pooling operation is norm preserving (aka gradient=1 almost everywhere).</p> <p>[1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature Pooling in Visual Recognition \u00bb,p.8.</p> PARAMETER  DESCRIPTION <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <p> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>the lipschitz factor to ensure</p> <p> DEFAULT: <code>1.0</code> </p> <code>eps_grad_sqrt</code> <p>Epsilon value to avoid numerical instability due to non-defined gradient at 0 in the sqrt function</p> <p> DEFAULT: <code>1e-06</code> </p> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> Output shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, pooled_cols)</code>.</li> </ul> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(self, data_format=None, k_coef_lip=1.0, eps_grad_sqrt=1e-6, **kwargs):\n    \"\"\"\n    Average pooling operation for spatial data, with a lipschitz bound. This\n    pooling operation is norm preserving (aka gradient=1 almost everywhere).\n\n    [1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature\n    Pooling in Visual Recognition \u00bb,p.8.\n\n    Arguments:\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        k_coef_lip: the lipschitz factor to ensure\n        eps_grad_sqrt: Epsilon value to avoid numerical instability\n            due to non-defined gradient at 0 in the sqrt function\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, pooled_cols)`.\n    \"\"\"\n    if eps_grad_sqrt &lt; 0.0:\n        raise RuntimeError(\"eps_grad_sqrt must be positive\")\n    super(ScaledGlobalL2NormPooling2D, self).__init__(\n        data_format=data_format, **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self.eps_grad_sqrt = eps_grad_sqrt\n    self._kwargs = kwargs\n    if self.data_format == \"channels_last\":\n        self.axes = [1, 2]\n    else:\n        self.axes = [2, 3]\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledL2NormPooling2D","title":"ScaledL2NormPooling2D","text":"<pre><code>ScaledL2NormPooling2D(\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None,\n    k_coef_lip=1.0,\n    eps_grad_sqrt=1e-06,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>AveragePooling2D</code>, <code>LipschitzLayer</code></p> <p>Average pooling operation for spatial data, with a lipschitz bound. This pooling operation is norm preserving (aka gradient=1 almost everywhere).</p> <p>[1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature Pooling in Visual Recognition \u00bb,p.8.</p> PARAMETER  DESCRIPTION <code>pool_size</code> <p>integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). <code>(2, 2)</code> will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.</p> <p> DEFAULT: <code>(2, 2)</code> </p> <code>strides</code> <p>Integer, tuple of 2 integers, or None. Strides values. If None, it will default to <code>pool_size</code>.</p> <p> DEFAULT: <code>None</code> </p> <code>padding</code> <p>One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</p> <p> DEFAULT: <code>'valid'</code> </p> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <p> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>the lipschitz factor to ensure</p> <p> DEFAULT: <code>1.0</code> </p> <code>eps_grad_sqrt</code> <p>Epsilon value to avoid numerical instability due to non-defined gradient at 0 in the sqrt function</p> <p> DEFAULT: <code>1e-06</code> </p> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> Output shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, pooled_rows, pooled_cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, pooled_rows, pooled_cols)</code>.</li> </ul> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self,\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None,\n    k_coef_lip=1.0,\n    eps_grad_sqrt=1e-6,\n    **kwargs,\n):\n    \"\"\"\n    Average pooling operation for spatial data, with a lipschitz bound. This\n    pooling operation is norm preserving (aka gradient=1 almost everywhere).\n\n    [1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature\n    Pooling in Visual Recognition \u00bb,p.8.\n\n    Arguments:\n        pool_size: integer or tuple of 2 integers,\n            factors by which to downscale (vertical, horizontal).\n            `(2, 2)` will halve the input in both spatial dimension.\n            If only one integer is specified, the same window length\n            will be used for both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n            Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        k_coef_lip: the lipschitz factor to ensure\n        eps_grad_sqrt: Epsilon value to avoid numerical instability\n            due to non-defined gradient at 0 in the sqrt function\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n    \"\"\"\n    if not ((strides == pool_size) or (strides is None)):\n        raise RuntimeError(\"stride must be equal to pool_size\")\n    if padding != \"valid\":\n        raise RuntimeError(\"ScaledL2NormPooling2D only supports padding='valid'\")\n    if eps_grad_sqrt &lt; 0.0:\n        raise RuntimeError(\"eps_grad_sqrt must be positive\")\n    super(ScaledL2NormPooling2D, self).__init__(\n        pool_size=pool_size,\n        strides=pool_size,\n        padding=padding,\n        data_format=data_format,\n        **kwargs,\n    )\n    self.set_klip_factor(k_coef_lip)\n    self.eps_grad_sqrt = eps_grad_sqrt\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.unconstrained","title":"unconstrained","text":"<p>This module contains custom Keras unconstrained layers.</p> <p>Compared to other files in <code>layers</code> folder, the layers defined here are not Lipschitz-constrained. They are base classes for more advanced layers. Do not use these layers as is, since they are not Lipschitz constrained.</p>"},{"location":"api/layers/#deel.lip.layers.unconstrained.PadConv2D","title":"PadConv2D","text":"<pre><code>PadConv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Conv2D</code>, <code>Condensable</code></p> <p>This class is a Conv2D Layer with parameterized padding. Since Conv2D layer only supports <code>\"same\"</code> and <code>\"valid\"</code> padding, this layer will enable other type of padding, such as <code>\"constant\"</code>, <code>\"symmetric\"</code>, <code>\"reflect\"</code> or <code>\"circular\"</code>.</p> Warning <p>The PadConv2D is not a Lipschitz layer and must not be directly used. This must be used as a base class to create a Lipschitz layer with padding.</p> <p>All arguments are the same as the original <code>Conv2D</code> except the <code>padding</code> which is defined as following:</p> PARAMETER  DESCRIPTION <code>padding</code> <p>one of <code>\"same\"</code>, <code>\"valid\"</code> <code>\"constant\"</code>, <code>\"symmetric\"</code>, <code>\"reflect\"</code> or <code>\"circular\"</code> (case-insensitive).</p> <p> DEFAULT: <code>'same'</code> </p> Source code in <code>deel/lip/layers/unconstrained.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n):\n    \"\"\"\n    This class is a Conv2D Layer with parameterized padding.\n    Since Conv2D layer only supports `\"same\"` and `\"valid\"` padding, this layer will\n    enable other type of padding, such as `\"constant\"`, `\"symmetric\"`, `\"reflect\"`\n    or `\"circular\"`.\n\n    Warning:\n        The PadConv2D is not a Lipschitz layer and must not be directly used. This\n        must be used as a base class to create a Lipschitz layer with padding.\n\n    All arguments are the same as the original `Conv2D` except the `padding`\n    which is defined as following:\n\n    Args:\n        padding: one of `\"same\"`, `\"valid\"` `\"constant\"`, `\"symmetric\"`,\n            `\"reflect\"` or `\"circular\"` (case-insensitive).\n    \"\"\"\n    self.pad = lambda x: x\n    self.old_padding = padding\n    self.internal_input_shape = None\n    if padding.lower() != \"same\":  # same is directly processed in Conv2D\n        padding = \"valid\"\n    super(PadConv2D, self).__init__(\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs\n    )\n    self._kwargs = kwargs\n    if self.old_padding.lower() in [\"same\", \"valid\"]:\n        self.pad = lambda x: x\n        self.padding_size = [0, 0]\n    if self.old_padding.lower() in [\"constant\", \"reflect\", \"symmetric\"]:\n        self.padding_size = [self.kernel_size[0] // 2, self.kernel_size[1] // 2]\n        paddings = [\n            [0, 0],\n            [self.padding_size[0], self.padding_size[0]],\n            [self.padding_size[1], self.padding_size[1]],\n            [0, 0],\n        ]\n        self.pad = lambda t: tf.pad(t, paddings, self.old_padding)\n    if self.old_padding.lower() == \"circular\":\n        self.padding_size = [self.kernel_size[0] // 2, self.kernel_size[1] // 2]\n        self.pad = lambda t: _padding_circular(t, self.padding_size)\n</code></pre>"},{"location":"api/losses/","title":"deel.lip.losses","text":"<p>This module contains losses used in Wasserstein distance estimation. See this paper for more information.</p>"},{"location":"api/losses/#deel.lip.losses.CategoricalHinge","title":"CategoricalHinge","text":"<pre><code>CategoricalHinge(\n    min_margin,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalHinge\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Similar to original categorical hinge, but with a settable margin parameter. This implementation is sligthly different from the Keras one.</p> <p><code>y_true</code> and <code>y_pred</code> must be of shape (batch_size, # classes). Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>min_margin</code> <p>margin parameter.</p> <p> TYPE: <code>float</code> </p> <code>reduction</code> <p>reduction of the loss, passed to original loss.</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>name of the loss</p> <p> TYPE: <code>str</code> DEFAULT: <code>'CategoricalHinge'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, min_margin, reduction=Reduction.AUTO, name=\"CategoricalHinge\"):\n    \"\"\"\n    Similar to original categorical hinge, but with a settable margin parameter.\n    This implementation is sligthly different from the Keras one.\n\n    `y_true` and `y_pred` must be of shape (batch_size, # classes).\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin parameter.\n        reduction: reduction of the loss, passed to original loss.\n        name (str): name of the loss\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(CategoricalHinge, self).__init__(name=name, reduction=reduction)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.HKR","title":"HKR","text":"<pre><code>HKR(\n    alpha,\n    min_margin=1.0,\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"HKR\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Wasserstein loss with a regularization parameter based on the hinge margin loss.</p> \\[ \\inf_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim P_-}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim P_+} {\\mathbb{E}} \\left[f(\\textbf{x} )\\right] + \\alpha \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin} -Yf(\\textbf{x})\\right)_+ \\] <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>alpha</code> <p>regularization factor</p> <p> TYPE: <code>float</code> </p> <code>min_margin</code> <p>minimal margin ( see hinge_margin_loss ) Kantorovich-Rubinstein term of the loss. In order to be consistent between hinge and KR, the first label must yield the positive class while the second yields negative class.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>multi_gpu</code> <p>set to True when running on multi-GPU/TPU</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'HKR'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self,\n    alpha,\n    min_margin=1.0,\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"HKR\",\n):\n    r\"\"\"\n    Wasserstein loss with a regularization parameter based on the hinge margin loss.\n\n    $$\n    \\inf_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim P_-}{\\mathbb{E}}\n    \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim P_+}\n    {\\mathbb{E}} \\left[f(\\textbf{x} )\\right] + \\alpha\n    \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin}\n    -Yf(\\textbf{x})\\right)_+\n    $$\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        alpha (float): regularization factor\n        min_margin (float): minimal margin ( see hinge_margin_loss )\n            Kantorovich-Rubinstein term of the loss. In order to be consistent\n            between hinge and KR, the first label must yield the positive class\n            while the second yields negative class.\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.alpha = tf.Variable(alpha, dtype=tf.float32)\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    self.multi_gpu = multi_gpu\n    self.KRloss = KR(multi_gpu=multi_gpu)\n    if alpha == np.inf:  # alpha = inf =&gt; hinge only\n        self.fct = partial(hinge_margin, min_margin=self.min_margin)\n    else:\n        self.fct = self.hkr\n    super(HKR, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.HingeMargin","title":"HingeMargin","text":"<pre><code>HingeMargin(\n    min_margin=1.0,\n    reduction=Reduction.AUTO,\n    name=\"HingeMargin\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Compute the hinge margin loss.</p> \\[ \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin} -Yf(\\textbf{x})\\right)_+ \\] <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>min_margin</code> <p>margin to enforce.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'HingeMargin'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, min_margin=1.0, reduction=Reduction.AUTO, name=\"HingeMargin\"):\n    r\"\"\"\n    Compute the hinge margin loss.\n\n    $$\n    \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin}\n    -Yf(\\textbf{x})\\right)_+\n    $$\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(HingeMargin, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.KR","title":"KR","text":"<pre><code>KR(multi_gpu=False, reduction=Reduction.AUTO, name='KR')\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Loss to estimate Wasserstein-1 distance using Kantorovich-Rubinstein duality. The Kantorovich-Rubinstein duality is formulated as following:</p> \\[ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] \\] <p>Where mu and nu stands for the two distributions, the distribution where the label is 1 and the rest.</p> <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>multi_gpu</code> <p>set to True when running on multi-GPU/TPU</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'KR'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, multi_gpu=False, reduction=Reduction.AUTO, name=\"KR\"):\n    r\"\"\"\n    Loss to estimate Wasserstein-1 distance using Kantorovich-Rubinstein duality.\n    The Kantorovich-Rubinstein duality is formulated as following:\n\n    $$\n    W_1(\\mu, \\nu) =\n    \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}}\n    \\left[f(\\textbf{x} )\\right] -\n    \\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right]\n    $$\n\n    Where mu and nu stands for the two distributions, the distribution where the\n    label is 1 and the rest.\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.eps = 1e-7\n    self.multi_gpu = multi_gpu\n    super(KR, self).__init__(reduction=reduction, name=name)\n    if multi_gpu:\n        self.kr_function = _kr_multi_gpu\n    else:\n        self.kr_function = partial(_kr, epsilon=self.eps)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MultiMargin","title":"MultiMargin","text":"<pre><code>MultiMargin(\n    min_margin=1.0,\n    reduction=Reduction.AUTO,\n    name=\"MultiMargin\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Compute the hinge margin loss for multiclass (equivalent to Pytorch multi_margin_loss)</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>min_margin</code> <p>margin to enforce.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'MultiMargin'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, min_margin=1.0, reduction=Reduction.AUTO, name=\"MultiMargin\"):\n    \"\"\"\n    Compute the hinge margin loss for multiclass (equivalent to Pytorch\n    multi_margin_loss)\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(MultiMargin, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassHKR","title":"MulticlassHKR","text":"<pre><code>MulticlassHKR(\n    alpha=10.0,\n    min_margin=1.0,\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"MulticlassHKR\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>The multiclass version of HKR. This is done by computing the HKR term over each class and averaging the results.</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>alpha</code> <p>regularization factor</p> <p> TYPE: <code>float</code> DEFAULT: <code>10.0</code> </p> <code>min_margin</code> <p>margin to enforce.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>multi_gpu</code> <p>set to True when running on multi-GPU/TPU</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'MulticlassHKR'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self,\n    alpha=10.0,\n    min_margin=1.0,\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"MulticlassHKR\",\n):\n    \"\"\"\n    The multiclass version of HKR. This is done by computing the HKR term over each\n    class and averaging the results.\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        alpha (float): regularization factor\n        min_margin (float): margin to enforce.\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.alpha = tf.Variable(alpha, dtype=tf.float32)\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    self.multi_gpu = multi_gpu\n    self.KRloss = MulticlassKR(multi_gpu=multi_gpu, reduction=reduction, name=name)\n    if alpha == np.inf:  # alpha = inf =&gt; hinge only\n        self.fct = partial(multiclass_hinge, min_margin=self.min_margin)\n    else:\n        self.fct = self.hkr\n    super(MulticlassHKR, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassHinge","title":"MulticlassHinge","text":"<pre><code>MulticlassHinge(\n    min_margin=1.0,\n    reduction=Reduction.AUTO,\n    name=\"MulticlassHinge\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Loss to estimate the Hinge loss in a multiclass setup. It computes the element-wise Hinge term. Note that this formulation differs from the one commonly found in tensorflow/pytorch (which maximises the difference between the two largest logits). This formulation is consistent with the binary classification loss used in a multiclass fashion.</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>min_margin</code> <p>margin to enforce.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'MulticlassHinge'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self, min_margin=1.0, reduction=Reduction.AUTO, name=\"MulticlassHinge\"\n):\n    \"\"\"\n    Loss to estimate the Hinge loss in a multiclass setup. It computes the\n    element-wise Hinge term. Note that this formulation differs from the one\n    commonly found in tensorflow/pytorch (which maximises the difference between\n    the two largest logits). This formulation is consistent with the binary\n    classification loss used in a multiclass fashion.\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(MulticlassHinge, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassKR","title":"MulticlassKR","text":"<pre><code>MulticlassKR(\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"MulticlassKR\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Loss to estimate average of Wasserstein-1 distance using Kantorovich-Rubinstein duality over outputs. In this multiclass setup, the KR term is computed for each class and then averaged.</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>multi_gpu</code> <p>set to True when running on multi-GPU/TPU</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>passed to tf.keras.Loss constructor</p> <p> TYPE: <code>str</code> DEFAULT: <code>'MulticlassKR'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, multi_gpu=False, reduction=Reduction.AUTO, name=\"MulticlassKR\"):\n    r\"\"\"\n    Loss to estimate average of Wasserstein-1 distance using Kantorovich-Rubinstein\n    duality over outputs. In this multiclass setup, the KR term is computed for each\n    class and then averaged.\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.eps = 1e-7\n    self.multi_gpu = multi_gpu\n    super(MulticlassKR, self).__init__(reduction=reduction, name=name)\n    if multi_gpu:\n        self.kr_function = _kr_multi_gpu\n    else:\n        self.kr_function = partial(_kr, epsilon=self.eps)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.TauBinaryCrossentropy","title":"TauBinaryCrossentropy","text":"<pre><code>TauBinaryCrossentropy(\n    tau,\n    reduction=Reduction.AUTO,\n    name=\"TauBinaryCrossentropy\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Similar to the original binary crossentropy, but with a settable temperature parameter. y_pred must be a logits tensor (before sigmoid) and not probabilities.</p> <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1). <code>y_true</code> accepts label values in (0, 1) or (-1, 1).</p> PARAMETER  DESCRIPTION <code>tau</code> <p>temperature parameter.</p> <p> </p> <code>reduction</code> <p>reduction of the loss, passed to original loss.</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>name of the loss</p> <p> DEFAULT: <code>'TauBinaryCrossentropy'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, tau, reduction=Reduction.AUTO, name=\"TauBinaryCrossentropy\"):\n    \"\"\"\n    Similar to the original binary crossentropy, but with a settable temperature\n    parameter. y_pred must be a logits tensor (before sigmoid) and not\n    probabilities.\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1). `y_true`\n    accepts label values in (0, 1) or (-1, 1).\n\n    Args:\n        tau: temperature parameter.\n        reduction: reduction of the loss, passed to original loss.\n        name: name of the loss\n    \"\"\"\n    self.tau = tf.Variable(tau, dtype=tf.float32)\n    super().__init__(name=name, reduction=reduction)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.TauCategoricalCrossentropy","title":"TauCategoricalCrossentropy","text":"<pre><code>TauCategoricalCrossentropy(\n    tau,\n    reduction=Reduction.AUTO,\n    name=\"TauCategoricalCrossentropy\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Similar to original categorical crossentropy, but with a settable temperature parameter.</p> PARAMETER  DESCRIPTION <code>tau</code> <p>temperature parameter.</p> <p> TYPE: <code>float</code> </p> <code>reduction</code> <p>reduction of the loss, passed to original loss.</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>name of the loss</p> <p> TYPE: <code>str</code> DEFAULT: <code>'TauCategoricalCrossentropy'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self, tau, reduction=Reduction.AUTO, name=\"TauCategoricalCrossentropy\"\n):\n    \"\"\"\n    Similar to original categorical crossentropy, but with a settable temperature\n    parameter.\n\n    Args:\n        tau (float): temperature parameter.\n        reduction: reduction of the loss, passed to original loss.\n        name (str): name of the loss\n    \"\"\"\n    self.tau = tf.Variable(tau, dtype=tf.float32)\n    super(TauCategoricalCrossentropy, self).__init__(name=name, reduction=reduction)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.TauSparseCategoricalCrossentropy","title":"TauSparseCategoricalCrossentropy","text":"<pre><code>TauSparseCategoricalCrossentropy(\n    tau,\n    reduction=Reduction.AUTO,\n    name=\"TauSparseCategoricalCrossentropy\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Similar to original sparse categorical crossentropy, but with a settable temperature parameter.</p> PARAMETER  DESCRIPTION <code>tau</code> <p>temperature parameter.</p> <p> TYPE: <code>float</code> </p> <code>reduction</code> <p>reduction of the loss, passed to original loss.</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>name of the loss</p> <p> TYPE: <code>str</code> DEFAULT: <code>'TauSparseCategoricalCrossentropy'</code> </p> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self, tau, reduction=Reduction.AUTO, name=\"TauSparseCategoricalCrossentropy\"\n):\n    \"\"\"\n    Similar to original sparse categorical crossentropy, but with a settable\n    temperature parameter.\n\n    Args:\n        tau (float): temperature parameter.\n        reduction: reduction of the loss, passed to original loss.\n        name (str): name of the loss\n    \"\"\"\n    self.tau = tf.Variable(tau, dtype=tf.float32)\n    super().__init__(name=name, reduction=reduction)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.hinge_margin","title":"hinge_margin","text":"<pre><code>hinge_margin(y_true, y_pred, min_margin)\n</code></pre> <p>Compute the element-wise binary hinge margin loss.</p> <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>min_margin</code> <p>margin to enforce.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <p>tf.Tensor: Element-wise hinge margin loss value.</p> Source code in <code>deel/lip/losses.py</code> <pre><code>def hinge_margin(y_true, y_pred, min_margin):\n    \"\"\"Compute the element-wise binary hinge margin loss.\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n\n    Returns:\n        tf.Tensor: Element-wise hinge margin loss value.\n\n    \"\"\"\n    sign = tf.where(y_true &gt; 0, 1, -1)\n    sign = tf.cast(sign, y_pred.dtype)\n    hinge = tf.nn.relu(min_margin / 2.0 - sign * y_pred)\n    # In binary case (`y_true` of shape (batch_size, 1)), `tf.reduce_mean(axis=-1)`\n    # behaves like `tf.squeeze` to return element-wise loss of shape (batch_size, ).\n    return tf.reduce_mean(hinge, axis=-1)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.multiclass_hinge","title":"multiclass_hinge","text":"<pre><code>multiclass_hinge(y_true, y_pred, min_margin)\n</code></pre> <p>Compute the multi-class hinge margin loss.</p> <p><code>y_true</code> and <code>y_pred</code> must be of shape (batch_size, # classes). Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> PARAMETER  DESCRIPTION <code>y_true</code> <p>tensor of true targets of shape (batch_size, # classes)</p> <p> TYPE: <code>Tensor</code> </p> <code>y_pred</code> <p>tensor of predicted targets of shape (batch_size, # classes)</p> <p> TYPE: <code>Tensor</code> </p> <code>min_margin</code> <p>margin to enforce.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <p>tf.Tensor: Element-wise multi-class hinge margin loss value.</p> Source code in <code>deel/lip/losses.py</code> <pre><code>def multiclass_hinge(y_true, y_pred, min_margin):\n    \"\"\"Compute the multi-class hinge margin loss.\n\n    `y_true` and `y_pred` must be of shape (batch_size, # classes).\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        y_true (tf.Tensor): tensor of true targets of shape (batch_size, # classes)\n        y_pred (tf.Tensor): tensor of predicted targets of shape (batch_size, # classes)\n        min_margin (float): margin to enforce.\n\n    Returns:\n        tf.Tensor: Element-wise multi-class hinge margin loss value.\n    \"\"\"\n    sign = tf.where(y_true &gt; 0, 1, -1)\n    sign = tf.cast(sign, y_pred.dtype)\n    # compute the elementwise hinge term\n    hinge = tf.nn.relu(min_margin / 2.0 - sign * y_pred)\n    # reweight positive elements\n    factor = y_pred.shape[-1] - 1.0\n    hinge = tf.where(sign &gt; 0, hinge * factor, hinge)\n    return tf.reduce_mean(hinge, axis=-1)\n</code></pre>"},{"location":"api/metrics/","title":"deel.lip.metrics","text":"<p>This module contains metrics applicable in provable robustness. See https://arxiv.org/abs/2006.06520 and https://arxiv.org/abs/2108.04062 for more information.</p>"},{"location":"api/metrics/#deel.lip.metrics.BinaryProvableAvgRobustness","title":"BinaryProvableAvgRobustness","text":"<pre><code>BinaryProvableAvgRobustness(\n    lip_const=1.0,\n    negative_robustness=False,\n    reduction=Reduction.AUTO,\n    name=\"BinaryProvableAvgRobustness\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Compute the average provable robustness radius on the dataset.</p> \\[ \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right] \\] <p>\\(\\mathcal{M}_f(x)\\) is a term that: is positive when x is correctly classified and negative otherwise. In both case the value give the robustness radius around x.</p> <p>In the binary classification setup we have:</p> \\[ \\mathcal{M}_f(x) = f(x) \\text{ if } l=1, -f(x) \\text{otherwise} \\] <p>Where \\(D\\) is the dataset, \\(l\\) is the correct label for x and \\(L_f\\) is the lipschitz constant of the network..</p> <p>When <code>negative_robustness</code> is set to <code>True</code> misclassified elements count as negative robustness (\\(\\phi\\) act as identity function), when set to <code>False</code>, misclassified elements yield a robustness radius of 0 ( \\(\\phi(x)=relu( x)\\) ). The elements are not ignored when computing the mean in both cases.</p> <p>This metric works for labels both in {1,0} and {1,-1}.</p> PARAMETER  DESCRIPTION <code>lip_const</code> <p>lipschitz constant of the network</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>metrics name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'BinaryProvableAvgRobustness'</code> </p> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    lip_const=1.0,\n    negative_robustness=False,\n    reduction=Reduction.AUTO,\n    name=\"BinaryProvableAvgRobustness\",\n):\n    r\"\"\"\n\n    Compute the average provable robustness radius on the dataset.\n\n    $$\n    \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right]\n    $$\n\n    $\\mathcal{M}_f(x)$ is a term that: is positive when x is correctly\n    classified and negative otherwise. In both case the value give the robustness\n    radius around x.\n\n    In the binary classification setup we have:\n\n    $$\n    \\mathcal{M}_f(x) = f(x) \\text{ if } l=1, -f(x) \\text{otherwise}\n    $$\n\n    Where $D$ is the dataset, $l$ is the correct label for x and\n    $L_f$ is the lipschitz constant of the network..\n\n    When `negative_robustness` is set to `True` misclassified elements count as\n    negative robustness ($\\phi$ act as identity function), when set to\n    `False`,\n    misclassified elements yield a robustness radius of 0 ( $\\phi(x)=relu(\n    x)$ ). The elements are not ignored when computing the mean in both cases.\n\n    This metric works for labels both in {1,0} and {1,-1}.\n\n    Args:\n        lip_const (float): lipschitz constant of the network\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.negative_robustness = negative_robustness\n    if self.negative_robustness:\n        self.delta_correction = lambda delta: delta\n    else:\n        self.delta_correction = tf.nn.relu\n    super(BinaryProvableAvgRobustness, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.BinaryProvableRobustAccuracy","title":"BinaryProvableRobustAccuracy","text":"<pre><code>BinaryProvableRobustAccuracy(\n    epsilon=36 / 255,\n    lip_const=1.0,\n    reduction=Reduction.AUTO,\n    name=\"BinaryProvableRobustAccuracy\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>The accuracy that can be proved at a given epsilon.</p> PARAMETER  DESCRIPTION <code>epsilon</code> <p>the metric will return the guaranteed accuracy for the radius epsilon.</p> <p> TYPE: <code>float</code> DEFAULT: <code>36 / 255</code> </p> <code>lip_const</code> <p>lipschitz constant of the network</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>metrics name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'BinaryProvableRobustAccuracy'</code> </p> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    epsilon=36 / 255,\n    lip_const=1.0,\n    reduction=Reduction.AUTO,\n    name=\"BinaryProvableRobustAccuracy\",\n):\n    r\"\"\"\n\n    The accuracy that can be proved at a given epsilon.\n\n    Args:\n        epsilon (float): the metric will return the guaranteed accuracy for the\n            radius epsilon.\n        lip_const (float): lipschitz constant of the network\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.epsilon = epsilon\n    super(BinaryProvableRobustAccuracy, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.CategoricalProvableAvgRobustness","title":"CategoricalProvableAvgRobustness","text":"<pre><code>CategoricalProvableAvgRobustness(\n    lip_const=1.0,\n    disjoint_neurons=True,\n    negative_robustness=False,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalProvableAvgRobustness\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Compute the average provable robustness radius on the dataset.</p> \\[ \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right] \\] <p>\\(\\mathcal{M}_f(x)\\) is a term that: is positive when x is correctly classified and negative otherwise. In both case the value give the robustness radius around x.</p> <p>In the multiclass setup we have:</p> \\[ \\mathcal{M}_f(x) =f_l(x) - \\max_{i \\neq l} f_i(x) \\] <p>Where \\(D\\) is the dataset, \\(l\\) is the correct label for x and \\(L_f\\) is the lipschitz constant of the network (\\(L = 2 \\times \\text{lip_const}\\) when <code>disjoint_neurons=True</code>, \\(L = \\sqrt{2} \\times \\text{lip_const}\\) otherwise).</p> <p>When <code>negative_robustness</code> is set to <code>True</code> misclassified elements count as negative robustness (\\(\\phi\\) act as identity function), when set to <code>False</code>, misclassified elements yield a robustness radius of 0 ( \\(\\phi(x)=relu( x)\\) ). The elements are not ignored when computing the mean in both cases.</p> <p>This metric works for labels both in {1,0} and {1,-1}.</p> PARAMETER  DESCRIPTION <code>lip_const</code> <p>lipschitz constant of the network</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>disjoint_neurons</code> <p>must be set to True is your model ends with a FrobeniusDense layer with <code>disjoint_neurons</code> set to True. Set to False otherwise</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>metrics name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'CategoricalProvableAvgRobustness'</code> </p> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    lip_const=1.0,\n    disjoint_neurons=True,\n    negative_robustness=False,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalProvableAvgRobustness\",\n):\n    r\"\"\"\n\n    Compute the average provable robustness radius on the dataset.\n\n    $$\n    \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right]\n    $$\n\n    $\\mathcal{M}_f(x)$ is a term that: is positive when x is correctly\n    classified and negative otherwise. In both case the value give the robustness\n    radius around x.\n\n    In the multiclass setup we have:\n\n    $$\n    \\mathcal{M}_f(x) =f_l(x) - \\max_{i \\neq l} f_i(x)\n    $$\n\n    Where $D$ is the dataset, $l$ is the correct label for x and\n    $L_f$ is the lipschitz constant of the network ($L = 2 \\times\n    \\text{lip_const}$ when `disjoint_neurons=True`, $L = \\sqrt{2} \\times\n    \\text{lip_const}$ otherwise).\n\n    When `negative_robustness` is set to `True` misclassified elements count as\n    negative robustness ($\\phi$ act as identity function), when set to\n    `False`,\n    misclassified elements yield a robustness radius of 0 ( $\\phi(x)=relu(\n    x)$ ). The elements are not ignored when computing the mean in both cases.\n\n    This metric works for labels both in {1,0} and {1,-1}.\n\n    Args:\n        lip_const (float): lipschitz constant of the network\n        disjoint_neurons (bool): must be set to True is your model ends with a\n            FrobeniusDense layer with `disjoint_neurons` set to True. Set to False\n            otherwise\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.disjoint_neurons = disjoint_neurons\n    self.negative_robustness = negative_robustness\n    if disjoint_neurons:\n        self.certificate_factor = 2 * lip_const\n    else:\n        self.certificate_factor = math.sqrt(2) * lip_const\n    if self.negative_robustness:\n        self.delta_correction = lambda delta: delta\n    else:\n        self.delta_correction = tf.nn.relu\n    super(CategoricalProvableAvgRobustness, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.CategoricalProvableRobustAccuracy","title":"CategoricalProvableRobustAccuracy","text":"<pre><code>CategoricalProvableRobustAccuracy(\n    epsilon=36 / 255,\n    lip_const=1.0,\n    disjoint_neurons=True,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalProvableRobustAccuracy\",\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>The accuracy that can be proved at a given epsilon.</p> PARAMETER  DESCRIPTION <code>epsilon</code> <p>the metric will return the guaranteed accuracy for the radius epsilon.</p> <p> TYPE: <code>float</code> DEFAULT: <code>36 / 255</code> </p> <code>lip_const</code> <p>lipschitz constant of the network</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>disjoint_neurons</code> <p>must be set to True if your model ends with a FrobeniusDense layer with <code>disjoint_neurons</code> set to True. Set to False otherwise</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <p> DEFAULT: <code>AUTO</code> </p> <code>name</code> <p>metrics name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'CategoricalProvableRobustAccuracy'</code> </p> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    epsilon=36 / 255,\n    lip_const=1.0,\n    disjoint_neurons=True,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalProvableRobustAccuracy\",\n):\n    r\"\"\"\n\n    The accuracy that can be proved at a given epsilon.\n\n    Args:\n        epsilon (float): the metric will return the guaranteed accuracy for the\n            radius epsilon.\n        lip_const (float): lipschitz constant of the network\n        disjoint_neurons (bool): must be set to True if your model ends with a\n            FrobeniusDense layer with `disjoint_neurons` set to True. Set to False\n            otherwise\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.epsilon = epsilon\n    self.disjoint_neurons = disjoint_neurons\n    if disjoint_neurons:\n        self.certificate_factor = 2 * lip_const\n    else:\n        self.certificate_factor = math.sqrt(2) * lip_const\n    super(CategoricalProvableRobustAccuracy, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/model/","title":"deel.lip.model","text":"<p>This module contains equivalents for Model and Sequential. These classes add support for condensation and vanilla exportation.</p>"},{"location":"api/model/#deel.lip.model.Model","title":"Model","text":"<p>             Bases: <code>Model</code></p> <p>Equivalent of keras.Model but support condensation and vanilla exportation.</p> Warning <p>As lipschitz constant are multiplicative along layer, the Model class cannot set a global Lipschitz constant (problem with branching inside a model).</p>"},{"location":"api/model/#deel.lip.model.Model.condense","title":"condense","text":"<pre><code>condense()\n</code></pre> <p>The condense operation allows to overwrite the kernel with constrained kernel and ensure that other variables are still consistent.</p> Source code in <code>deel/lip/model.py</code> <pre><code>def condense(self):\n    \"\"\"\n    The condense operation allows to overwrite the kernel with constrained kernel\n    and ensure that other variables are still consistent.\n    \"\"\"\n    for layer in self.layers:\n        if isinstance(layer, Condensable):\n            layer.condense()\n</code></pre>"},{"location":"api/model/#deel.lip.model.Model.vanilla_export","title":"vanilla_export","text":"<pre><code>vanilla_export()\n</code></pre> <p>Export this model to a \"Vanilla\" model, i.e. a model without Condensable layers.</p> RETURNS DESCRIPTION <code>Model</code> <p>A Keras model, identical to this model, but where condensable layers have been replaced with their vanilla equivalent (e.g. SpectralConv2D with Conv2D).</p> Source code in <code>deel/lip/model.py</code> <pre><code>def vanilla_export(self) -&gt; KerasModel:\n    \"\"\"\n    Export this model to a \"Vanilla\" model, i.e. a model without Condensable\n    layers.\n\n    Returns:\n        A Keras model, identical to this model, but where condensable layers have\n            been replaced with their vanilla equivalent (e.g. SpectralConv2D with\n            Conv2D).\n    \"\"\"\n    return vanillaModel(self)\n</code></pre>"},{"location":"api/model/#deel.lip.model.Sequential","title":"Sequential","text":"<pre><code>Sequential(layers=None, name=None, k_coef_lip=1.0)\n</code></pre> <p>             Bases: <code>Sequential</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>Equivalent of keras.Sequential but allow to set k-lip factor globally. Also support condensation and vanilla exportation. For now constant repartition is implemented (each layer get n_sqrt(k_lip_factor), where n is the number of layers) But in the future other repartition function may be implemented.</p> PARAMETER  DESCRIPTION <code>layers</code> <p>list of layers to add to the model.</p> <p> TYPE: <code>list</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>name of the model, can be None</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>k_coef_lip</code> <p>the Lipschitz coefficient to ensure globally on the model.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> Source code in <code>deel/lip/model.py</code> <pre><code>def __init__(\n    self,\n    layers=None,\n    name=None,\n    k_coef_lip=1.0,\n):\n    \"\"\"\n    Equivalent of keras.Sequential but allow to set k-lip factor globally. Also\n    support condensation and vanilla exportation.\n    For now constant repartition is implemented (each layer\n    get n_sqrt(k_lip_factor), where n is the number of layers)\n    But in the future other repartition function may be implemented.\n\n    Args:\n        layers (list): list of layers to add to the model.\n        name (str): name of the model, can be None\n        k_coef_lip (float): the Lipschitz coefficient to ensure globally on the\n            model.\n    \"\"\"\n    super(Sequential, self).__init__(layers, name)\n    self.set_klip_factor(k_coef_lip)\n</code></pre>"},{"location":"api/model/#deel.lip.model.Sequential.coef_lip","title":"coef_lip  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>coef_lip = None\n</code></pre> <p>define correction coefficient (ie. Lipschitz bound ) of the layer ( multiply the output of the layer by this constant )</p>"},{"location":"api/model/#deel.lip.model.Sequential.k_coef_lip","title":"k_coef_lip  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>k_coef_lip = 1.0\n</code></pre> <p>variable used to store the lipschitz factor</p>"},{"location":"api/model/#deel.lip.model.vanillaModel","title":"vanillaModel","text":"<pre><code>vanillaModel(model)\n</code></pre> <p>Transform a model to its equivalent \"vanilla\" model, i.e. a model where <code>Condensable</code> layers are replaced with their vanilla equivalent. For example, <code>SpectralConv2D</code> layers are converted to tf.keras <code>Conv2D</code> layers.</p> <p>The input model can be a tf.keras Sequential/Model or a deel.lip Sequential/Model.</p> PARAMETER  DESCRIPTION <code>model</code> <p>a tf.keras or deel.lip model with Condensable layers.</p> <p> </p> RETURNS DESCRIPTION <p>A Keras model, identical to the input model where <code>Condensable</code> layers are replaced with their vanilla counterparts.</p> Source code in <code>deel/lip/model.py</code> <pre><code>def vanillaModel(model):\n    \"\"\"\n    Transform a model to its equivalent \"vanilla\" model, i.e. a model where\n    `Condensable` layers are replaced with their vanilla equivalent. For example,\n    `SpectralConv2D` layers are converted to tf.keras `Conv2D` layers.\n\n    The input model can be a tf.keras Sequential/Model or a deel.lip Sequential/Model.\n\n    Args:\n        model: a tf.keras or deel.lip model with Condensable layers.\n\n    Returns:\n        A Keras model, identical to the input model where `Condensable` layers are\n            replaced with their vanilla counterparts.\n    \"\"\"\n\n    def _replace_condensable_layer(layer):\n        # Return a vanilla layer if Condensable, else return a copy of the layer\n        if isinstance(layer, Condensable):\n            return layer.vanilla_export()\n        new_layer = layer.__class__.from_config(layer.get_config())\n        new_layer.build(layer.input_shape)\n        new_layer.set_weights(layer.get_weights())\n        return new_layer\n\n    return clone_model(model, clone_function=_replace_condensable_layer)\n</code></pre>"},{"location":"api/normalizers/","title":"deel.lip.normalizers","text":"<p>This module contains computation function, for Bjorck and spectral normalization. This is done for internal use only.</p>"},{"location":"api/normalizers/#deel.lip.normalizers.bjorck_normalization","title":"bjorck_normalization","text":"<pre><code>bjorck_normalization(\n    w,\n    eps=DEFAULT_EPS_BJORCK,\n    beta=DEFAULT_BETA_BJORCK,\n    maxiter=DEFAULT_MAXITER_BJORCK,\n)\n</code></pre> <p>apply Bjorck normalization on w.</p> PARAMETER  DESCRIPTION <code>w</code> <p>weight to normalize, in order to work properly, we must have max_eigenval(w) ~= 1</p> <p> TYPE: <code>Tensor</code> </p> <code>eps</code> <p>epsilon stopping criterion: norm(wt - wt-1) must be less than eps</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta</code> <p>beta used in each iteration, must be in the interval ]0, 0.5]</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>maxiter</code> <p>maximum number of iterations for the algorithm</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_MAXITER_BJORCK</code> </p> RETURNS DESCRIPTION <p>tf.Tensor: the orthonormal weights</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def bjorck_normalization(\n    w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK\n):\n    \"\"\"\n    apply Bjorck normalization on w.\n\n    Args:\n        w (tf.Tensor): weight to normalize, in order to work properly, we must have\n            max_eigenval(w) ~= 1\n        eps (float): epsilon stopping criterion: norm(wt - wt-1) must be less than eps\n        beta (float): beta used in each iteration, must be in the interval ]0, 0.5]\n        maxiter (int): maximum number of iterations for the algorithm\n\n    Returns:\n        tf.Tensor: the orthonormal weights\n\n    \"\"\"\n    # create a fake old_w that does'nt pass the loop condition\n    # it won't affect computation as the first action done in the loop overwrite it.\n    old_w = 10 * w\n    # define the loop condition\n\n    def cond(w, old_w):\n        return tf.linalg.norm(w - old_w) &gt;= eps\n\n    # define the loop body\n    def body(w, old_w):\n        old_w = w\n        w = (1 + beta) * w - beta * _wwtw(w)\n        return w, old_w\n\n    # apply the loop\n    w, old_w = tf.while_loop(\n        cond,\n        body,\n        (w, old_w),\n        parallel_iterations=30,\n        maximum_iterations=maxiter,\n        swap_memory=SWAP_MEMORY,\n    )\n    return w\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.get_conv_operators","title":"get_conv_operators","text":"<pre><code>get_conv_operators(\n    kernel,\n    u_shape,\n    stride=1.0,\n    conv_first=True,\n    pad_func=None,\n)\n</code></pre> <p>Return two functions corresponding to the linear convolution operator and its adjoint.</p> PARAMETER  DESCRIPTION <code>kernel</code> <p>the convolution kernel to normalize</p> <p> TYPE: <code>Tensor</code> </p> <code>u_shape</code> <p>shape of a singular vector (as a 4D tensor).</p> <p> TYPE: <code>tuple</code> </p> <code>stride</code> <p>stride parameter of convolutions. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1.0</code> </p> <code>conv_first</code> <p>RO or CO case , should be True in CO case (stride^2*C&lt;M). Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>pad_func</code> <p>function for applying padding (None is padding same). Defaults to None.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>two functions for the linear convolution operator and its adjoint operator.</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def get_conv_operators(kernel, u_shape, stride=1.0, conv_first=True, pad_func=None):\n    \"\"\"\n    Return two functions corresponding to the linear convolution operator and its\n    adjoint.\n\n    Args:\n        kernel (tf.Tensor): the convolution kernel to normalize\n        u_shape (tuple): shape of a singular vector (as a 4D tensor).\n        stride (int, optional): stride parameter of convolutions. Defaults to 1.\n        conv_first (bool, optional): RO or CO case , should be True in CO case\n            (stride^2*C&lt;M). Defaults to True.\n        pad_func (Callable, optional): function for applying padding (None is padding\n            same). Defaults to None.\n\n    Returns:\n        tuple: two functions for the linear convolution operator and its adjoint\n            operator.\n    \"\"\"\n\n    def identity(x):\n        return x\n\n    # If pad_func is None, standard convolution with SAME padding\n    # Else, pad_func padding function (externally defined)\n    #       + standard convolution with VALID padding.\n    if pad_func is None:\n        pad_type = \"SAME\"\n        _pad_func = identity\n    else:\n        pad_type = \"VALID\"\n        _pad_func = pad_func\n\n    def _conv(u, w, stride):\n        u_pad = _pad_func(u)\n        return tf.nn.conv2d(u_pad, w, stride, pad_type)\n\n    def _conv_transpose(u, w, output_shape, stride):\n        if pad_func is None:\n            return tf.nn.conv2d_transpose(u, w, output_shape, stride, pad_type)\n        else:\n            u_upscale = _zero_upscale2D(u, (stride, stride))\n            w_adj = _maybe_transpose_kernel(w, True)\n            return _conv(u_upscale, w_adj, stride=1)\n\n    if conv_first:\n\n        def linear_op(u):\n            return _conv(u, kernel, stride)\n\n        def adjoint_op(v):\n            return _conv_transpose(v, kernel, u_shape, stride)\n\n    else:\n        v_shape = (\n            (u_shape[0],)\n            + (u_shape[1] * stride, u_shape[2] * stride)\n            + (kernel.shape[-2],)\n        )\n\n        def linear_op(u):\n            return _conv_transpose(u, kernel, v_shape, stride)\n\n        def adjoint_op(v):\n            return _conv(v, kernel, stride)\n\n    return linear_op, adjoint_op\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.reshaped_kernel_orthogonalization","title":"reshaped_kernel_orthogonalization","text":"<pre><code>reshaped_kernel_orthogonalization(\n    kernel,\n    u,\n    adjustment_coef,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n)\n</code></pre> <p>Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It apply the power method to find the largest singular value and apply the Bjorck algorithm to the rescaled kernel. This greatly improve the stability and and speed convergence of the bjorck algorithm.</p> PARAMETER  DESCRIPTION <code>kernel</code> <p>the kernel to orthogonalize</p> <p> TYPE: <code>Tensor</code> </p> <code>u</code> <p>the vector used to do the power iteration method</p> <p> TYPE: <code>Tensor</code> </p> <code>adjustment_coef</code> <p>the adjustment coefficient as used in convolution</p> <p> TYPE: <code>float</code> </p> <code>eps_spectral</code> <p>stopping criterion in spectral algorithm</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>eps_bjorck</code> <p>stopping criterion in bjorck algorithm</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_BJORCK</code> </p> <code>beta</code> <p>the beta used in the bjorck algorithm</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_BETA_BJORCK</code> </p> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_MAXITER_SPECTRAL</code> </p> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_MAXITER_BJORCK</code> </p> RETURNS DESCRIPTION <p>tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest singular value</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def reshaped_kernel_orthogonalization(\n    kernel,\n    u,\n    adjustment_coef,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n):\n    \"\"\"\n    Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It\n    apply the power method to find the largest singular value and apply the Bjorck\n    algorithm to the rescaled kernel. This greatly improve the stability and and\n    speed convergence of the bjorck algorithm.\n\n    Args:\n        kernel (tf.Tensor): the kernel to orthogonalize\n        u (tf.Tensor): the vector used to do the power iteration method\n        adjustment_coef (float): the adjustment coefficient as used in convolution\n        eps_spectral (float): stopping criterion in spectral algorithm\n        eps_bjorck (float): stopping criterion in bjorck algorithm\n        beta (float): the beta used in the bjorck algorithm\n        maxiter_spectral (int): maximum number of iterations for the power iteration\n        maxiter_bjorck (int): maximum number of iterations for bjorck algorithm\n\n    Returns:\n        tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest\n            singular value\n\n    \"\"\"\n    W_shape = kernel.shape\n    # Flatten the Tensor\n    W_reshaped = tf.reshape(kernel, [-1, W_shape[-1]])\n    W_bar, u, sigma = spectral_normalization(\n        W_reshaped, u, eps=eps_spectral, maxiter=maxiter_spectral\n    )\n    if (eps_bjorck is not None) and (beta is not None):\n        W_bar = bjorck_normalization(\n            W_bar, eps=eps_bjorck, beta=beta, maxiter=maxiter_bjorck\n        )\n    W_bar = W_bar * adjustment_coef\n    W_bar = K.reshape(W_bar, kernel.shape)\n    return W_bar, u, sigma\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.set_stop_grad_spectral","title":"set_stop_grad_spectral","text":"<pre><code>set_stop_grad_spectral(value)\n</code></pre> <p>Set the global STOP_GRAD_SPECTRAL to values. This function must be called before constructing the model (first call of <code>reshaped_kernel_orthogonalization</code>) in order to be accounted.</p> PARAMETER  DESCRIPTION <code>value</code> <p>boolean, when set to True, disable back-propagation through the power iteration algorithm. The back-propagation will account how updates affects the maximum singular value but not how it affects the largest singular vector. When set to False, back-propagate through the while loop.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def set_stop_grad_spectral(value: bool):\n    \"\"\"\n    Set the global STOP_GRAD_SPECTRAL to values. This function must be called before\n    constructing the model (first call of `reshaped_kernel_orthogonalization`) in\n    order to be accounted.\n\n    Args:\n        value: boolean, when set to True, disable back-propagation through the power\n            iteration algorithm. The back-propagation will account how updates affects\n            the maximum singular value but not how it affects the largest singular\n            vector. When set to False, back-propagate through the while loop.\n\n    \"\"\"\n    global STOP_GRAD_SPECTRAL\n    STOP_GRAD_SPECTRAL = value\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.set_swap_memory","title":"set_swap_memory","text":"<pre><code>set_swap_memory(value)\n</code></pre> <p>Set the global SWAP_MEMORY to values. This function must be called before constructing the model (first call of <code>reshaped_kernel_orthogonalization</code>) in order to be accounted.</p> PARAMETER  DESCRIPTION <code>value</code> <p>boolean that will be used as the swap_memory parameter in while loops in spectral and bjorck algorithms.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def set_swap_memory(value: bool):\n    \"\"\"\n    Set the global SWAP_MEMORY to values. This function must be called before\n    constructing the model (first call of `reshaped_kernel_orthogonalization`) in\n    order to be accounted.\n\n    Args:\n        value: boolean that will be used as the swap_memory parameter in while loops\n            in spectral and bjorck algorithms.\n\n    \"\"\"\n    global SWAP_MEMORY\n    SWAP_MEMORY = value\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.spectral_normalization","title":"spectral_normalization","text":"<pre><code>spectral_normalization(\n    kernel,\n    u,\n    eps=DEFAULT_EPS_SPECTRAL,\n    maxiter=DEFAULT_MAXITER_SPECTRAL,\n)\n</code></pre> <p>Normalize the kernel to have its maximum singular value equal to 1.</p> PARAMETER  DESCRIPTION <code>kernel</code> <p>the kernel to normalize, assuming a 2D kernel.</p> <p> TYPE: <code>Tensor</code> </p> <code>u</code> <p>initialization of the maximum singular vector.</p> <p> TYPE: <code>Tensor</code> </p> <code>eps</code> <p>stopping criterion of the algorithm, when norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>maxiter</code> <p>maximum number of iterations for the algorithm. Defaults to DEFAULT_MAXITER_SPECTRAL.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_MAXITER_SPECTRAL</code> </p> RETURNS DESCRIPTION <p>the normalized kernel, the maximum singular vector, and the maximum singular value.</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def spectral_normalization(\n    kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL\n):\n    \"\"\"\n    Normalize the kernel to have its maximum singular value equal to 1.\n\n    Args:\n        kernel (tf.Tensor): the kernel to normalize, assuming a 2D kernel.\n        u (tf.Tensor): initialization of the maximum singular vector.\n        eps (float, optional): stopping criterion of the algorithm, when\n            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n        maxiter (int, optional): maximum number of iterations for the algorithm.\n            Defaults to DEFAULT_MAXITER_SPECTRAL.\n\n    Returns:\n        the normalized kernel, the maximum singular vector, and the maximum singular\n            value.\n    \"\"\"\n\n    if u is None:\n        u = tf.random.uniform(\n            shape=(1, kernel.shape[-1]), minval=0.0, maxval=1.0, dtype=kernel.dtype\n        )\n\n    def linear_op(u):\n        return u @ tf.transpose(kernel)\n\n    def adjoint_op(v):\n        return v @ kernel\n\n    u = _power_iteration(linear_op, adjoint_op, u, eps, maxiter)\n\n    # Compute the largest singular value and the normalized kernel.\n    # We assume that in the worst case we converged to sigma + eps (as u and v are\n    # normalized after each iteration)\n    # In order to be sure that operator norm of normalized kernel is strictly less than\n    # one we use sigma + eps, which ensures stability of Bj\u00f6rck algorithm even when\n    # beta=0.5\n    sigma = tf.reshape(tf.norm(linear_op(u)), (1, 1))\n    normalized_kernel = kernel / (sigma + eps)\n    return normalized_kernel, u, sigma\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.spectral_normalization_conv","title":"spectral_normalization_conv","text":"<pre><code>spectral_normalization_conv(\n    kernel,\n    u,\n    stride=1.0,\n    conv_first=True,\n    pad_func=None,\n    eps=DEFAULT_EPS_SPECTRAL,\n    maxiter=DEFAULT_MAXITER_SPECTRAL,\n)\n</code></pre> <p>Normalize the convolution kernel to have its max eigenvalue == 1.</p> PARAMETER  DESCRIPTION <code>kernel</code> <p>the convolution kernel to normalize</p> <p> TYPE: <code>Tensor</code> </p> <code>u</code> <p>initialization for the max eigen vector (as a 4d tensor)</p> <p> TYPE: <code>Tensor</code> </p> <code>stride</code> <p>stride parameter of convolutions</p> <p> TYPE: <code>int</code> DEFAULT: <code>1.0</code> </p> <code>conv_first</code> <p>RO or CO case , should be True in CO case (stride^2*C&lt;M)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>pad_func</code> <p>function for applying padding (None is padding same)</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>eps</code> <p>epsilon stopping criterion: norm(ut - ut-1) must be less than eps</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_EPS_SPECTRAL</code> </p> <code>maxiter</code> <p>maximum number of iterations for the power iteration algorithm.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DEFAULT_MAXITER_SPECTRAL</code> </p> RETURNS DESCRIPTION <p>the normalized kernel w_bar, the maximum eigen vector, and the maximum eigen value</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def spectral_normalization_conv(\n    kernel,\n    u,\n    stride=1.0,\n    conv_first=True,\n    pad_func=None,\n    eps=DEFAULT_EPS_SPECTRAL,\n    maxiter=DEFAULT_MAXITER_SPECTRAL,\n):\n    \"\"\"\n    Normalize the convolution kernel to have its max eigenvalue == 1.\n\n    Args:\n        kernel (tf.Tensor): the convolution kernel to normalize\n        u (tf.Tensor): initialization for the max eigen vector (as a 4d tensor)\n        stride (int): stride parameter of convolutions\n        conv_first (bool): RO or CO case , should be True in CO case (stride^2*C&lt;M)\n        pad_func (Callable): function for applying padding (None is padding same)\n        eps (float): epsilon stopping criterion: norm(ut - ut-1) must be less than eps\n        maxiter (int): maximum number of iterations for the power iteration algorithm.\n\n    Returns:\n        the normalized kernel w_bar, the maximum eigen vector, and the maximum eigen\n            value\n    \"\"\"\n\n    if eps &lt; 0:\n        return kernel, u, 1.0\n\n    linear_op, adjoint_op = get_conv_operators(\n        kernel, u.shape, stride, conv_first, pad_func\n    )\n\n    u = tf.math.l2_normalize(u) + tf.random.uniform(u.shape, minval=-eps, maxval=eps)\n    u = _power_iteration(linear_op, adjoint_op, u, eps, maxiter)\n\n    # Compute the largest singular value and the normalized kernel\n    sigma = tf.norm(linear_op(u))\n    normalized_kernel = kernel / (sigma + eps)\n    return normalized_kernel, u, sigma\n</code></pre>"},{"location":"api/utils/","title":"deel.lip.utils","text":"<p>Contains utility functions.</p>"},{"location":"api/utils/#deel.lip.utils.evaluate_lip_const","title":"evaluate_lip_const","text":"<pre><code>evaluate_lip_const(model, x, eps=0.0001, seed=None)\n</code></pre> <p>Evaluate the Lipschitz constant of a model, with the naive method. Please note that the estimation of the lipschitz constant is done locally around input sample. This may not correctly estimate the behaviour in the whole domain.</p> PARAMETER  DESCRIPTION <code>model</code> <p>built keras model used to make predictions</p> <p> TYPE: <code>Model</code> </p> <code>x</code> <p>inputs used to compute the lipschitz constant</p> <p> </p> <code>eps</code> <p>magnitude of noise to add to input in order to compute the constant</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>seed</code> <p>seed used when generating the noise ( can be set to None )</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>float</code> <p>the empirically evaluated lipschitz constant. The computation might also be inaccurate in high dimensional space.</p> Source code in <code>deel/lip/utils.py</code> <pre><code>def evaluate_lip_const(model: Model, x, eps=1e-4, seed=None):\n    \"\"\"\n    Evaluate the Lipschitz constant of a model, with the naive method.\n    Please note that the estimation of the lipschitz constant is done locally around\n    input sample. This may not correctly estimate the behaviour in the whole domain.\n\n    Args:\n        model: built keras model used to make predictions\n        x: inputs used to compute the lipschitz constant\n        eps (float): magnitude of noise to add to input in order to compute the constant\n        seed (int): seed used when generating the noise ( can be set to None )\n\n    Returns:\n        float: the empirically evaluated lipschitz constant. The computation might also\n            be inaccurate in high dimensional space.\n\n    \"\"\"\n    y_pred = model.predict(x)\n    # x = np.repeat(x, 100, 0)\n    # y_pred = np.repeat(y_pred, 100, 0)\n    x_var = x + K.random_uniform(\n        shape=x.shape, minval=eps * 0.25, maxval=eps, seed=seed\n    )\n    y_pred_var = model.predict(x_var)\n    dx = x - x_var\n    dfx = y_pred - y_pred_var\n    ndx = K.sqrt(K.sum(K.square(dx), axis=range(1, len(x.shape))))\n    ndfx = K.sqrt(K.sum(K.square(dfx), axis=range(1, len(y_pred.shape))))\n    lip_cst = K.max(ndfx / ndx)\n    print(f\"lip cst: {lip_cst:.3f}\")\n    return lip_cst\n</code></pre>"},{"location":"api/utils/#deel.lip.utils.evaluate_lip_const_gen","title":"evaluate_lip_const_gen","text":"<pre><code>evaluate_lip_const_gen(\n    model, generator, eps=0.0001, seed=None\n)\n</code></pre> <p>Evaluate the Lipschitz constant of a model, with the naive method. Please note that the estimation of the lipschitz constant is done locally around input sample. This may not correctly estimate the behaviour in the whole domain. The computation might also be inaccurate in high dimensional space.</p> <p>This is the generator version of evaluate_lip_const.</p> PARAMETER  DESCRIPTION <code>model</code> <p>built keras model used to make predictions</p> <p> TYPE: <code>Model</code> </p> <code>generator</code> <p>used to select datapoints where to compute the lipschitz constant</p> <p> TYPE: <code>Generator[Tuple[ndarray, ndarray], Any, None]</code> </p> <code>eps</code> <p>magnitude of noise to add to input in order to compute the constant</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>seed</code> <p>seed used when generating the noise ( can be set to None )</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>float</code> <p>the empirically evaluated lipschitz constant.</p> Source code in <code>deel/lip/utils.py</code> <pre><code>def evaluate_lip_const_gen(\n    model: Model,\n    generator: Generator[Tuple[np.ndarray, np.ndarray], Any, None],\n    eps=1e-4,\n    seed=None,\n):\n    \"\"\"\n    Evaluate the Lipschitz constant of a model, with the naive method.\n    Please note that the estimation of the lipschitz constant is done locally around\n    input sample. This may not correctly estimate the behaviour in the whole domain.\n    The computation might also be inaccurate in high dimensional space.\n\n    This is the generator version of evaluate_lip_const.\n\n    Args:\n        model: built keras model used to make predictions\n        generator: used to select datapoints where to compute the lipschitz constant\n        eps (float): magnitude of noise to add to input in order to compute the constant\n        seed (int): seed used when generating the noise ( can be set to None )\n\n    Returns:\n        float: the empirically evaluated lipschitz constant.\n\n    \"\"\"\n    x, _ = generator.send(None)\n    return evaluate_lip_const(model, x, eps, seed=seed)\n</code></pre>"},{"location":"api/utils/#deel.lip.utils.process_labels_for_multi_gpu","title":"process_labels_for_multi_gpu","text":"<pre><code>process_labels_for_multi_gpu(labels)\n</code></pre> <p>Process labels to be fed to any loss based on KR estimation with a multi-GPU/TPU strategy.</p> <p>When using a multi-GPU/TPU strategy, the flag <code>multi_gpu</code> in KR-based losses must be set to True and the labels have to be pre-processed with this function.</p> <p>For binary classification, the labels should be of shape [batch_size, 1]. For multiclass problems, the labels must be one-hot encoded (1 or 0) with shape [batch_size, number of classes].</p> PARAMETER  DESCRIPTION <code>labels</code> <p>tensor containing the labels</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <p>tf.Tensor: labels processed for KR-based losses with multi-GPU/TPU strategy.</p> Source code in <code>deel/lip/utils.py</code> <pre><code>@tf.function\ndef process_labels_for_multi_gpu(labels):\n    \"\"\"Process labels to be fed to any loss based on KR estimation with a multi-GPU/TPU\n    strategy.\n\n    When using a multi-GPU/TPU strategy, the flag `multi_gpu` in KR-based losses must be\n    set to True and the labels have to be pre-processed with this function.\n\n    For binary classification, the labels should be of shape [batch_size, 1].\n    For multiclass problems, the labels must be one-hot encoded (1 or 0) with shape\n    [batch_size, number of classes].\n\n    Args:\n        labels (tf.Tensor): tensor containing the labels\n\n    Returns:\n        tf.Tensor: labels processed for KR-based losses with multi-GPU/TPU strategy.\n    \"\"\"\n    eps = 1e-7\n    labels = tf.cast(tf.where(labels &gt; 0, 1, 0), labels.dtype)\n    batch_size = tf.cast(tf.shape(labels)[0], labels.dtype)\n    counts = tf.reduce_sum(labels, axis=0)\n\n    pos = labels / (counts + eps)\n    neg = (1 - labels) / (batch_size - counts + eps)\n    # Since element-wise KR terms are averaged by loss reduction later on, it is needed\n    # to multiply by batch_size here.\n    return batch_size * (pos - neg)\n</code></pre>"},{"location":"notebooks/Getting_started_1/","title":"Getting started 1 - Creating a 1-Lipschitz neural network","text":"<p>The goal of this series of tutorials is to show the different usages of <code>deel-lip</code>.</p> <p>In this first notebook, our objective is to show how to create 1-Lipschitz neural networks with <code>deel-lip</code>. </p> <p>In particular, we will cover the following:  1. \ud83d\udcda Theoretical background  A brief theoretical background on Lipschitz continuous functions. This section can be safely skipped if one is not interested in the theory. 2. \ud83e\uddf1 Creating a 1-Lipschitz neural network with <code>deel-lip</code> and <code>keras</code>  An example of how to create a 1-Lipschitz neural network with <code>deel-lip</code> and <code>keras</code>. 3. \ud83d\udd28 Design rules for 1-Lipschitz neural networks with <code>deel-lip</code>  A set of neural network design rules that one must respect in order to enforce the 1-Lipschitz constraint.</p> <pre><code>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Model\n\ninput_shape = (28, 28, 1)\nnum_classes=10\n\n# a basic model that does not follow any Lipschitz constraint\nmodel = keras.Sequential([\n        layers.Input(shape=input_shape),\n        layers.Flatten(),\n        layers.Dense(64),\n        layers.Activation('relu'),\n        layers.Dense(32),\n        layers.Activation('relu'),\n        layers.Dense(num_classes)\n    ])\n\n\nmodel.compile(optimizer='adam',\n          loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n          metrics=['accuracy'])\n\nmodel.summary()\n</code></pre> <pre>\n<code>Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n\n dense (Dense)               (None, 64)                50240     \n\n activation (Activation)     (None, 64)                0         \n\n dense_1 (Dense)             (None, 32)                2080      \n\n activation_1 (Activation)   (None, 32)                0         \n\n dense_2 (Dense)             (None, 10)                330       \n\n=================================================================\nTotal params: 52650 (205.66 KB)\nTrainable params: 52650 (205.66 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n</code>\n</pre> <p>Alternatively, it is equivalent to write:</p> <pre><code>inputs = keras.layers.Input(input_shape)\nx = keras.layers.Flatten()(inputs)\nx = layers.Dense(64)(x)\nx = layers.Activation('relu')(x)\nx = layers.Dense(32)(x)\nx = layers.Activation('relu')(x)\ny = layers.Dense(num_classes)(x)\nmodel = Model(inputs=inputs, outputs=y)\nmodel.summary()\n</code></pre> <pre>\n<code>Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n\n flatten_1 (Flatten)         (None, 784)               0         \n\n dense_3 (Dense)             (None, 64)                50240     \n\n activation_2 (Activation)   (None, 64)                0         \n\n dense_4 (Dense)             (None, 32)                2080      \n\n activation_3 (Activation)   (None, 32)                0         \n\n dense_5 (Dense)             (None, 10)                330       \n\n=================================================================\nTotal params: 52650 (205.66 KB)\nTrainable params: 52650 (205.66 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n</code>\n</pre> <p><code>deel-lip</code> extends <code>keras</code>' capabilities by introducing custom <code>layers</code> and <code>model</code> modules, to provide the ability to control the Lipschitz constant of layers objects or of complete neural networks, while keeping a user-friendly interface.</p> <p>Below is a 1-Lipschitz replication of the previous MLP toy-example, using <code>deel-lip</code>:</p> <pre><code>import deel\nfrom deel import lip\n</code></pre> <pre><code>Lip_model = lip.model.Sequential([    \n        keras.layers.Input(shape=input_shape),\n        keras.layers.Flatten(),\n        lip.layers.SpectralDense(64),\n        lip.layers.GroupSort2(),\n        lip.layers.SpectralDense(32),\n        lip.layers.GroupSort2(),\n        lip.layers.SpectralDense(num_classes)\n    ],\n\n)\n\nLip_model.compile(optimizer='adam',\n          loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n          metrics=['accuracy'])\n\nLip_model.summary()\n</code></pre> <pre>\n<code>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten_2 (Flatten)         (None, 784)               0         \n\n spectral_dense (SpectralDe  (None, 64)                100481    \n nse)                                                            \n\n group_sort2 (GroupSort2)    (None, 64)                0         \n\n spectral_dense_1 (Spectral  (None, 32)                4161      \n Dense)                                                          \n\n group_sort2_1 (GroupSort2)  (None, 32)                0         \n\n spectral_dense_2 (Spectral  (None, 10)                661       \n Dense)                                                          \n\n=================================================================\nTotal params: 105303 (411.34 KB)\nTrainable params: 52650 (205.66 KB)\nNon-trainable params: 52653 (205.68 KB)\n_________________________________________________________________\n</code>\n</pre> <pre>\n<code>C:\\Users\\kierszbaums\\anaconda.related\\envs\\1_lipschitz\\deel_lip\\lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer Orthogonal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n  warnings.warn(\n</code>\n</pre> <p>Alternatively, it is equivalent to write:</p> <pre><code>inputs = keras.layers.Input(input_shape)\nx = keras.layers.Flatten()(inputs)\nx = lip.layers.SpectralDense(64)(x)\nx = lip.layers.GroupSort2()(x)\nx = lip.layers.SpectralDense(32)(x)\nx = lip.layers.GroupSort2()(x)\ny = lip.layers.SpectralDense(num_classes)(x)\nLip_model = lip.model.Model(inputs=inputs, outputs=y)\nLip_model.summary()\n</code></pre> <pre>\n<code>Model: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n\n flatten_3 (Flatten)         (None, 784)               0         \n\n spectral_dense_3 (Spectral  (None, 64)                100481    \n Dense)                                                          \n\n group_sort2_2 (GroupSort2)  (None, 64)                0         \n\n spectral_dense_4 (Spectral  (None, 32)                4161      \n Dense)                                                          \n\n group_sort2_3 (GroupSort2)  (None, 32)                0         \n\n spectral_dense_5 (Spectral  (None, 10)                661       \n Dense)                                                          \n\n=================================================================\nTotal params: 105303 (411.34 KB)\nTrainable params: 52650 (205.66 KB)\nNon-trainable params: 52653 (205.68 KB)\n_________________________________________________________________\n</code>\n</pre> <p>\ud83d\udca1 Keep in mind that all the classes above inherit from their respective <code>keras</code> equivalent (e.g. <code>Dense</code> for <code>SpectralDense</code>).    As a result, these objects conveniently use the same interface and the same parameters as their keras equivalent.</p> <p>Activation function selection:</p> <p>The ReLU activation function is Lipschitz continuous with a Lipschtiz constant of 1. </p> <p>However, the 'GroupSort2' activation function provided in the <code>layers</code> submodule of <code>deel-lip</code> has additional properties that can enhance the adversarial robustness of 1-Lipschitz neural networks.</p> <p>\ud83d\udca1 Interested readers can find information relevant to other 1-Lipschitz activation functions that exist within <code>deel-lip</code> here.</p> <p>Loss function selection:</p> <p>One can use <code>keras</code> loss functions to train 1-Lipschitz neural networks. Doing so will not interfere with the 1-Lipschitz continuity of the model.  </p> <p>\ud83d\udca1 <code>deel-lip</code> also has a <code>losses</code> submodule that contains several loss functions. They have been developed to enhance the adversarial robustness of the learnt  1-Lipschitz models.</p>"},{"location":"notebooks/Getting_started_1/#getting-started-1-creating-a-1-lipschitz-neural-network","title":"\ud83d\udc4b Getting started 1: Creating a 1-Lipschitz neural network","text":""},{"location":"notebooks/Getting_started_1/#theoretical-background","title":"\ud83d\udcda Theoretical background","text":""},{"location":"notebooks/Getting_started_1/#what-is-the-lipschitz-constant","title":"What is the Lipschitz constant","text":"<p>The <code>deel-lip</code> package allows to control the Lipschitz constant of a layer or of a whole neural network. The Lipschitz constant is a mathematical property of a function (in our context of work, a layer or a model) that characterizes how much the output of the function can change with respect to changes in its input. </p> <p>In mathematical terms, a function \\(f\\) is Lipschitz continuous with a Lipschitz constant L or more simply L-Lipschitz if for any given pair of points \\(x_1,x_2\\), \\(L\\) provides a bound on the rate of change of \\(f\\):  </p> \\[||f(x_1)-f(x_2)||\\leq L||x_1-x_2||.\\] <p>For instance, given a 1-Lipschitz dense layer (a.k.a fully connected layer) with a weight matrix \\(W\\) and a bias vector \\(b\\), we have for any two inputs \\(x_1\\) and \\(x_2\\): \\(\\(||(W.x_1+b)-(W.x_2+b)|| \\leq 1||x_1-x_2||.\\)\\)</p> <p>\ud83d\udca1 The norm we refer to throughout our notebooks is the Euclidean norm (L2). This is because <code>deel-lip</code> operates with this norm. You will find more information about the role of the norm in the context of adversarially robust 1-Lipschitz deep learning models in the notebook titled 'Getting Started 2'.</p>"},{"location":"notebooks/Getting_started_1/#a-simple-requirement-for-creating-1-lipschitz-neural-network","title":"A simple requirement for creating 1-Lipschitz neural network","text":"<p>The composition property of Lipschitz continuous functions states that if you have a function f that is \\(L_1\\)-Lipschitz and another function g that is \\(L_2\\)-Lispchitz, then their composition function h = (f o g) which applies f after g is also Lipschitz continuous with a Lipschitz constant \\(L \\leq L_1\\) * \\(L_2\\).</p> <p>A feed-forward or sequential neural network is essentially a stack of layers, where each layer transforms the output of the previous layer(s) and feeds its output to the next ones. </p> <p>By the composition property of Lipschitz functions, it suffices for each of the n individual layers of a neural network model to be 1-Lipschitz, for the whole model to be 1-Lipschitz.</p> <p>For instance, given a 1-Lipschitz dense layer parametrized by \\((W,b)\\), and a ReLU (Rectified Linear Unit) activation layer which is naturally 1-Lipschitz, the combination of the two is also 1-Lispchitz.  This is shown in the equations below, where we have for any two inputs \\(x_1\\) and \\(x_2\\):</p> \\[||(W.x_1+b)-(W.x_2+b)||\\leq 1||x_1-x_2||,$$ $$||ReLU(x_1)-ReLU(x_2)||\\leq 1||x_1-x_2||,$$ and: $$||ReLU(W.x_1+b)-ReLU(W.x_2+b)||\\leq 1||(W.x_1+b)-(W.x_2+b)||\\leq 1^2||x_1-x_2||.\\] <p>The <code>deel-lip</code> package allows to create 1-Lipschitz neural networks, by providing the user with means to enforce the Lipschitz constant at one on a selected set of layers (such as dense layers).  It also ensures that 1-Lipschitz continuity is retained during training.</p>"},{"location":"notebooks/Getting_started_1/#creating-a-1-lipschitz-neural-network-with-deel-lip-and-keras","title":"\ud83e\uddf1 Creating a 1-Lipschitz neural network with <code>deel-lip</code> and <code>keras</code>","text":"<p><code>keras</code> is an open-source high-level deep learning API written in Python. It allows to build, train, and deploy deep learning models.</p> <p>One can produce a neural network architecture using keras with a few lines of code, as shown in the toy-example multi-layer perceptron (MLP) below:</p>"},{"location":"notebooks/Getting_started_1/#design-rules-for-1-lipschitz-neural-networks-with-deel-lip","title":"\ud83d\udd28 Design rules for 1-Lipschitz neural networks with <code>deel-lip</code>","text":"<p>Layer selection: <code>deel-lip</code> vs <code>keras</code>   In our 1-Lipschitz MLP examples above, we have used a mixture of objects from both <code>keras</code> and <code>deel-lip</code> <code>layers</code> submodule (e.g. the <code>Input</code> layer for <code>keras</code>, the <code>SpectralDense</code> layer for <code>deel-lip</code>).</p> <p>More generally, for the particular types of layers that do not interfere with the Lipschitz property of any neural network they belong to, no alternative has been coded in <code>deel-lip</code> and the existing <code>keras</code> layer object can be used. </p> <p>This is the case for the following keras layers: <code>MaxPooling</code>, <code>GlobalMaxPooling</code>, <code>Flatten</code> and <code>Input</code>.</p> <p>Below is the full list of <code>keras</code> layers for which <code>deel-lip</code> provides a Lipschitz equivalent. If one wants to ensure a model's Lipschitz continuity, the alternative <code>deel-lip</code> layers must be employed instead of the original <code>keras</code> counterparts.</p> tensorflow.keras.layers deel.lip.layers <code>Dense</code> <code>SpectralDense</code> <code>Conv2D</code> <code>SpectralConv2D</code> <code>AveragePooling2D</code><code>GlobalAveragePooling2D</code> <code>ScaledAveragePooling2D</code><code>ScaledGlobalAveragePooling2D</code> <p></p> <p>\ud83d\udca1 Although there are additional Lipschitz continuous layers available in <code>deel-lip</code>, the ones mentioned above are perfectly suitable and recommended for practical use. Interested readers can find information about the other layers here.</p> <p> </p> <p>\ud83d\udea8 Note: When creating a 1-Lipschitz neural network, one should avoid using the following layers:  - <code>Dropout</code>: Our current recommendation is to avoid using it, since it can induce a modification of the Lipschitz constant of the model. - <code>BatchNormalization</code>: It is not 1-Lipschitz </p>"},{"location":"notebooks/Getting_started_1/#congratulations","title":"\ud83c\udf89 Congratulations","text":"<p>You now know how to create 1-Lipschitz neural networks!</p> <p>In the next tutorial, we will see how to train and assess adversarially robust 1-Lipschitz neural networks on the classification task, using <code>deel-lip</code>'s <code>losses</code> submodule.</p>"},{"location":"notebooks/demo0/","title":"Demo 0: Example & Usage","text":"<pre><code>from deel.lip.layers import (\n    SpectralDense,\n    SpectralConv2D,\n    ScaledL2NormPooling2D,\n    FrobeniusDense,\n)\nfrom deel.lip.model import Sequential\nfrom deel.lip.activations import GroupSort\nfrom deel.lip.losses import MulticlassHKR, MulticlassKR\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\n\n# Sequential (resp Model) from deel.model has the same properties as any lipschitz model.\n# It act only as a container, with features specific to lipschitz\n# functions (condensation, vanilla_exportation...) but The layers are fully compatible\n# with the tf.keras.model.Sequential/Model\nmodel = Sequential(\n    [\n        Input(shape=(28, 28, 1)),\n        # Lipschitz layers preserve the API of their superclass ( here Conv2D )\n        # an optional param is available: k_coef_lip which control the lipschitz\n        # constant of the layer\n        SpectralConv2D(\n            filters=16,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        # usual pooling layer are implemented (avg, max...), but new layers are also available\n        ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        SpectralConv2D(\n            filters=16,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        # our layers are fully interoperable with existing keras layers\n        Flatten(),\n        SpectralDense(\n            32,\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        FrobeniusDense(\n            10, activation=None, use_bias=False, kernel_initializer=\"orthogonal\"\n        ),\n    ],\n    # similary model has a parameter to set the lipschitz constant\n    # to set automatically the constant of each layer\n    k_coef_lip=1.0,\n    name=\"hkr_model\",\n)\n\n# HKR (Hinge-Krantorovich-Rubinstein) optimize robustness along with accuracy\nmodel.compile(\n    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n    # note also in the case of lipschitz networks, more robustness require more parameters.\n    loss=MulticlassHKR(alpha=50, min_margin=0.05),\n    optimizer=Adam(1e-3),\n    metrics=[\"accuracy\", MulticlassKR()],\n)\n\nmodel.summary()\n\n# load data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n# standardize and reshape the data\nx_train = np.expand_dims(x_train, -1)\nmean = x_train.mean()\nstd = x_train.std()\nx_train = (x_train - mean) / std\nx_test = np.expand_dims(x_test, -1)\nx_test = (x_test - mean) / std\n# one hot encode the labels\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# fit the model\nmodel.fit(\n    x_train,\n    y_train,\n    batch_size=2048,\n    epochs=30,\n    validation_data=(x_test, y_test),\n    shuffle=True,\n)\n\n# once training is finished you can convert\n# SpectralDense layers into Dense layers and SpectralConv2D into Conv2D\n# which optimize performance for inference\nvanilla_model = model.vanilla_export()\n</code></pre> <pre>\n<code>/home/thibaut.boissin/projects/deel-lip/deel/lip/model.py:56: UserWarning: Sequential model contains a layer wich is not a Lipschitz layer: flatten_2\n  layer.name\n</code>\n</pre> <pre>\n<code>Model: \"hkr_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nspectral_conv2d_4 (SpectralC (None, 28, 28, 16)        321       \n_________________________________________________________________\nscaled_l2norm_pooling2d_4 (S (None, 14, 14, 16)        0         \n_________________________________________________________________\nspectral_conv2d_5 (SpectralC (None, 14, 14, 16)        4641      \n_________________________________________________________________\nscaled_l2norm_pooling2d_5 (S (None, 7, 7, 16)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 784)               0         \n_________________________________________________________________\nspectral_dense_2 (SpectralDe (None, 32)                50241     \n_________________________________________________________________\nfrobenius_dense_2 (Frobenius (None, 10)                640       \n=================================================================\nTotal params: 55,843\nTrainable params: 27,920\nNon-trainable params: 27,923\n_________________________________________________________________\nEpoch 1/30\n30/30 [==============================] - 3s 43ms/step - loss: 6.5323 - accuracy: 0.1522 - MulticlassKR: 0.0183 - val_loss: 2.3933 - val_accuracy: 0.4873 - val_MulticlassKR: 0.0942\nEpoch 2/30\n30/30 [==============================] - 1s 39ms/step - loss: 2.0856 - accuracy: 0.5528 - MulticlassKR: 0.1149 - val_loss: 1.3480 - val_accuracy: 0.7091 - val_MulticlassKR: 0.1653\nEpoch 3/30\n30/30 [==============================] - 1s 35ms/step - loss: 1.2743 - accuracy: 0.7298 - MulticlassKR: 0.1743 - val_loss: 0.9228 - val_accuracy: 0.7942 - val_MulticlassKR: 0.2097\nEpoch 4/30\n30/30 [==============================] - 1s 36ms/step - loss: 0.9001 - accuracy: 0.7975 - MulticlassKR: 0.2168 - val_loss: 0.6864 - val_accuracy: 0.8368 - val_MulticlassKR: 0.2486\nEpoch 5/30\n30/30 [==============================] - 1s 35ms/step - loss: 0.6889 - accuracy: 0.8338 - MulticlassKR: 0.2546 - val_loss: 0.5352 - val_accuracy: 0.8650 - val_MulticlassKR: 0.2835\nEpoch 6/30\n30/30 [==============================] - 1s 37ms/step - loss: 0.5256 - accuracy: 0.8609 - MulticlassKR: 0.2879 - val_loss: 0.4442 - val_accuracy: 0.8805 - val_MulticlassKR: 0.3166\nEpoch 7/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.4469 - accuracy: 0.8735 - MulticlassKR: 0.3186 - val_loss: 0.3349 - val_accuracy: 0.8911 - val_MulticlassKR: 0.3470\nEpoch 8/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.3493 - accuracy: 0.8835 - MulticlassKR: 0.3480 - val_loss: 0.2641 - val_accuracy: 0.8961 - val_MulticlassKR: 0.3787\nEpoch 9/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.2722 - accuracy: 0.8938 - MulticlassKR: 0.3818 - val_loss: 0.2122 - val_accuracy: 0.8993 - val_MulticlassKR: 0.4127\nEpoch 10/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.2036 - accuracy: 0.9013 - MulticlassKR: 0.4153 - val_loss: 0.1330 - val_accuracy: 0.9079 - val_MulticlassKR: 0.4487\nEpoch 11/30\n30/30 [==============================] - 1s 35ms/step - loss: 0.1472 - accuracy: 0.9059 - MulticlassKR: 0.4505 - val_loss: 0.0799 - val_accuracy: 0.9126 - val_MulticlassKR: 0.4861\nEpoch 12/30\n30/30 [==============================] - 1s 35ms/step - loss: 0.0939 - accuracy: 0.9103 - MulticlassKR: 0.4915 - val_loss: 0.0371 - val_accuracy: 0.9142 - val_MulticlassKR: 0.5313\nEpoch 13/30\n30/30 [==============================] - 1s 40ms/step - loss: 0.0499 - accuracy: 0.9100 - MulticlassKR: 0.5346 - val_loss: -0.0211 - val_accuracy: 0.9206 - val_MulticlassKR: 0.5729\nEpoch 14/30\n30/30 [==============================] - 1s 39ms/step - loss: -0.0216 - accuracy: 0.9162 - MulticlassKR: 0.5760 - val_loss: -0.0682 - val_accuracy: 0.9200 - val_MulticlassKR: 0.6219\nEpoch 15/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.0666 - accuracy: 0.9168 - MulticlassKR: 0.6248 - val_loss: -0.1301 - val_accuracy: 0.9236 - val_MulticlassKR: 0.6742\nEpoch 16/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.1223 - accuracy: 0.9197 - MulticlassKR: 0.6778 - val_loss: -0.1777 - val_accuracy: 0.9270 - val_MulticlassKR: 0.7275\nEpoch 17/30\n30/30 [==============================] - 1s 36ms/step - loss: -0.1605 - accuracy: 0.9199 - MulticlassKR: 0.7291 - val_loss: -0.2426 - val_accuracy: 0.9272 - val_MulticlassKR: 0.7900\nEpoch 18/30\n30/30 [==============================] - 1s 36ms/step - loss: -0.2278 - accuracy: 0.9218 - MulticlassKR: 0.7886 - val_loss: -0.2883 - val_accuracy: 0.9305 - val_MulticlassKR: 0.8471\nEpoch 19/30\n30/30 [==============================] - 1s 40ms/step - loss: -0.2246 - accuracy: 0.9170 - MulticlassKR: 0.8478 - val_loss: -0.3104 - val_accuracy: 0.9183 - val_MulticlassKR: 0.9070\nEpoch 20/30\n30/30 [==============================] - 1s 34ms/step - loss: -0.3066 - accuracy: 0.9213 - MulticlassKR: 0.9085 - val_loss: -0.3778 - val_accuracy: 0.9284 - val_MulticlassKR: 0.9754\nEpoch 21/30\n30/30 [==============================] - 1s 39ms/step - loss: -0.3736 - accuracy: 0.9241 - MulticlassKR: 0.9739 - val_loss: -0.4258 - val_accuracy: 0.9280 - val_MulticlassKR: 1.0388\nEpoch 22/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.4180 - accuracy: 0.9229 - MulticlassKR: 1.0337 - val_loss: -0.4805 - val_accuracy: 0.9302 - val_MulticlassKR: 1.1069\nEpoch 23/30\n30/30 [==============================] - 1s 38ms/step - loss: -0.4624 - accuracy: 0.9234 - MulticlassKR: 1.1055 - val_loss: -0.5607 - val_accuracy: 0.9312 - val_MulticlassKR: 1.1803\nEpoch 24/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.5279 - accuracy: 0.9257 - MulticlassKR: 1.1797 - val_loss: -0.5866 - val_accuracy: 0.9275 - val_MulticlassKR: 1.2456\nEpoch 25/30\n30/30 [==============================] - 1s 38ms/step - loss: -0.5482 - accuracy: 0.9218 - MulticlassKR: 1.2388 - val_loss: -0.6441 - val_accuracy: 0.9310 - val_MulticlassKR: 1.3125\nEpoch 26/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.6375 - accuracy: 0.9263 - MulticlassKR: 1.3103 - val_loss: -0.6890 - val_accuracy: 0.9295 - val_MulticlassKR: 1.3795\nEpoch 27/30\n30/30 [==============================] - 1s 42ms/step - loss: -0.6668 - accuracy: 0.9230 - MulticlassKR: 1.3719 - val_loss: -0.7413 - val_accuracy: 0.9271 - val_MulticlassKR: 1.4496\nEpoch 28/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.7483 - accuracy: 0.9264 - MulticlassKR: 1.4371 - val_loss: -0.7748 - val_accuracy: 0.9296 - val_MulticlassKR: 1.5096\nEpoch 29/30\n30/30 [==============================] - 1s 49ms/step - loss: -0.7495 - accuracy: 0.9229 - MulticlassKR: 1.4900 - val_loss: -0.8622 - val_accuracy: 0.9332 - val_MulticlassKR: 1.5644\nEpoch 30/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.8047 - accuracy: 0.9246 - MulticlassKR: 1.5530 - val_loss: -0.8732 - val_accuracy: 0.9297 - val_MulticlassKR: 1.6220\n</code>\n</pre>"},{"location":"notebooks/demo0/#demo-0-example-and-usage","title":"Demo 0: Example and usage","text":"<p>In order to make things simple the following rules have been followed during development:</p> <ul> <li><code>deel-lip</code> follows the <code>keras</code> package structure.</li> <li>All elements (layers, activations, initializers, ...) are compatible     with standard the <code>keras</code> elements.</li> <li>When a k-Lipschitz layer overrides a standard keras layer, it uses     the same interface and the same parameters. The only difference is a     new parameter to control the Lipschitz constant of a layer.</li> </ul>"},{"location":"notebooks/demo0/#which-layers-are-safe-to-use","title":"Which layers are safe to use?","text":"<p>The following table indicates which layers are safe to use in a Lipshitz network, and which are not.</p> layer 1-lip? deel-lip equivalent comments <code>Dense</code> no <code>SpectralDense</code><code>FrobeniusDense</code> <code>SpectralDense</code> and <code>FrobeniusDense</code> are similar when there is a single output. <code>Conv2D</code> no <code>SpectralConv2D</code><code>FrobeniusConv2D</code> <code>SpectralConv2D</code> also implements Bj\u00f6rck normalization. <code>MaxPooling</code><code>GlobalMaxPooling</code> yes n/a <code>AveragePooling2D</code><code>GlobalAveragePooling2D</code> no <code>ScaledAveragePooling2D</code><code>ScaledGlobalAveragePooling2D</code> The lipschitz constant is bounded by <code>sqrt(pool_h * pool_h)</code>. <code>Flatten</code> yes n/a <code>Dropout</code> no None The lipschitz constant is bounded by the dropout factor. <code>BatchNormalization</code> no None We suspect that layer normalization already limits internal covariate shift."},{"location":"notebooks/demo0/#design-tips","title":"Design tips","text":"<p>Designing lipschitz networks requires a careful design in order to avoid vanishing/exploding gradient problems.</p> <p>Choosing pooling layers:</p> layer advantages disadvantages <code>ScaledAveragePooling2D</code> and <code>MaxPooling2D</code> very similar to original implementation (just add a scaling factor for avg). not norm preserving nor gradient norm preserving. <code>InvertibleDownSampling</code> norm preserving and gradient norm preserving. increases the number of channels (and the number of parameters of the next layer). <code>ScaledL2NormPooling2D</code> (sqrt(avgpool(x**2))) norm preserving. lower numerical stability of the gradient when inputs are close to zero. <p>Choosing activations:</p> layer advantages disadvantages <code>ReLU</code> create a strong vanishing gradient effect. If you manage to learn with it, please call 911. <code>MaxMin</code> (stack([ReLU(x), ReLU(-x)])) have similar properties to ReLU, but is norm and gradient norm preserving double the number of outputs <code>GroupSort</code> Input and GradientNorm preserving. Also limit the need of biases (as it is shift invariant). more computationally expensive, (when its parameter n is large) <p>Please note that when learning with the <code>HKR_loss</code> and <code>HKR_multiclass_loss</code>, no activation is required on the last layer.</p>"},{"location":"notebooks/demo0/#how-to-use-it","title":"How to use it ?","text":"<p>Here is an example of 1-lipschitz network trained on MNIST:</p>"},{"location":"notebooks/demo1/","title":"Demo 1: Wasserstein distance estimation on toy example","text":"<pre><code># pip install deel-lip -qqq\n</code></pre> <pre><code>from datetime import datetime\nimport os\nimport numpy as np\nimport math\n\nimport matplotlib.pyplot as plt \n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Flatten, ReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\nfrom deel.lip.layers import SpectralConv2D, SpectralDense, FrobeniusDense\nfrom deel.lip.activations import MaxMin, GroupSort, FullSort\nfrom deel.lip.losses import KR, HKR\nfrom deel.lip.model import Model\n</code></pre> <pre>\n<code>Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_d1mx9in because the default path (/home/thibaut.boissin/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n2021-09-08 18:20:20.330918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <pre><code>img_size = 64 \nfrac_value = 0.3  # proportion of the center square\n</code></pre> <pre><code>def generate_toy_images(shape,frac=0,v=1):\n    \"\"\"\n    function that generate a single image.\n\n    Args:\n        shape: shape of the output image\n        frac: proportion of the center square\n        value: value assigned to the center square\n    \"\"\"\n    img = np.zeros(shape)\n    if frac==0:\n        return img\n    frac=frac**0.5\n    #print(frac)\n    l=int(shape[0]*frac)\n    ldec=(shape[0]-l)//2\n    #print(l)\n    w=int(shape[1]*frac)\n    wdec=(shape[1]-w)//2\n    img[ldec:ldec+l,wdec:wdec+w,:]=v\n    return img\n\n\ndef binary_generator(batch_size,shape,frac=0):\n    \"\"\"\n    generate a batch with half of black images, hald of images with a white square.\n    \"\"\"\n    batch_x = np.zeros(((batch_size,)+(shape)), dtype=np.float16)\n    batch_y=np.zeros((batch_size,1), dtype=np.float16)\n    batch_x[batch_size//2:,]=generate_toy_images(shape,frac=frac,v=1)\n    batch_y[batch_size//2:]=1\n    while True:\n        yield  batch_x, batch_y\n\n\ndef ternary_generator(batch_size,shape,frac=0):\n    \"\"\"\n    Same as binary generator, but images can have a white square of value 1, or value -1\n    \"\"\"\n    batch_x = np.zeros(((batch_size,)+(shape)), dtype=np.float16)\n    batch_y=np.zeros((batch_size,1), dtype=np.float16)\n    batch_x[3*batch_size//4:,]=generate_toy_images(shape,frac=frac,v=1)\n    batch_x[batch_size//2:3*batch_size//4,]=generate_toy_images(shape,frac=frac,v=-1)\n    batch_y[batch_size//2:]=1\n    #indexes_shuffle = np.arange(batch_size)\n    while True:\n        #np.random.shuffle(indexes_shuffle)\n        #yield  batch_x[indexes_shuffle,], batch_y[indexes_shuffle,]\n        yield  batch_x, batch_y\n</code></pre> <pre><code>def display_img(img):\n    \"\"\"\n    Display an image\n    \"\"\"\n    if img.shape[-1] == 1:\n        img = np.tile(img,(3,))\n    fig, ax = plt.subplots()\n\n    imgplot = ax.imshow((img*255).astype(np.uint))\n</code></pre> <p>Now let's take a look at the generated batches</p> <pre><code>test=binary_generator(2,(img_size,img_size,1),frac=frac_value)\nimgs, y=next(test)\n\ndisplay_img(imgs[0])\ndisplay_img(imgs[1])\nprint(\"Norm L2 \"+str(np.linalg.norm(imgs[1])))\nprint(\"Norm L2(count pixels) \"+str(math.sqrt(np.size(imgs[1][imgs[1]==1]))))\n</code></pre> <pre>\n<code>Norm L2 35.0\nNorm L2(count pixels) 35.0\n</code>\n</pre> <pre><code>test=ternary_generator(4,(img_size,img_size,1),frac=frac_value)\nimgs, y=next(test)\n\nfor i in range(4):\n    display_img(0.5*(imgs[i]+1.0)) # we ensure that there is no negative value wehn displaying images\n\nprint(\"Norm L2(imgs[2]-imgs[0])\"+str(np.linalg.norm(imgs[2]-imgs[0])))\nprint(\"Norm L2(imgs[2]) \"+str(np.linalg.norm(imgs[2])))\nprint(\"Norm L2(count pixels) \"+str(math.sqrt(np.size(imgs[2][imgs[2]==-1]))))\n</code></pre> <pre>\n<code>Norm L2(imgs[2]-imgs[0])35.0\nNorm L2(imgs[2]) 35.0\nNorm L2(count pixels) 35.0\n</code>\n</pre> <pre><code>batch_size=64\nepochs=5\nsteps_per_epoch=6400\n</code></pre> <pre><code>generator = ternary_generator   #binary_generator, ternary_generator\nactivation = FullSort #ReLU, MaxMin, GroupSort\n</code></pre> <pre><code>K.clear_session()\n## please note that the previous helper function has the same behavior as the following code:\ninputs = Input((img_size, img_size, 1))\nx = Flatten()(inputs)\nx = SpectralDense(128, activation=FullSort())(x)\nx = SpectralDense(64, activation=FullSort())(x)\nx = SpectralDense(32, activation=FullSort())(x)\ny = FrobeniusDense(1, activation=None)(x)\nwass = Model(inputs=inputs, outputs=y)\nwass.summary()\n</code></pre> <pre>\n<code>2021-09-08 18:20:38.075170: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:20:38.076265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-08 18:20:38.116402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.116842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:20:38.116868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:20:38.119558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:20:38.119602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:20:38.120389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:20:38.120583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:20:38.122025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:20:38.122661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:20:38.122768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:20:38.122832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.123234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.123588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:20:38.124825: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:20:38.124895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.125224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:20:38.125241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:20:38.125254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:20:38.125266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:20:38.125278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:20:38.125289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:20:38.125300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:20:38.125311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:20:38.125323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:20:38.125366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.125711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.126022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:20:38.126048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:20:38.409201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-08 18:20:38.409221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-08 18:20:38.409225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-08 18:20:38.409352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.409615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.409848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.410069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9056 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n2021-09-08 18:20:38.493063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:20:38.861293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:20:38.861380: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n</code>\n</pre> <pre>\n<code>Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 4096)              0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 128)               1048833   \n_________________________________________________________________\nspectral_dense_1 (SpectralDe (None, 64)                16513     \n_________________________________________________________________\nspectral_dense_2 (SpectralDe (None, 32)                4161      \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 1)                 65        \n=================================================================\nTotal params: 1,069,572\nTrainable params: 534,785\nNon-trainable params: 534,787\n_________________________________________________________________\n</code>\n</pre> <pre><code>optimizer = Adam(lr=0.01)\n</code></pre> <pre><code>wass.compile(loss=HKR(alpha=0), optimizer=optimizer, metrics=[KR])\n</code></pre> <pre><code>wass.fit_generator( generator(batch_size,(img_size,img_size,1),frac=frac_value),\n                steps_per_epoch=steps_per_epoch// batch_size,\n                epochs=epochs,verbose=1)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n2021-09-08 18:20:39.823710: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-08 18:20:39.842379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n</code>\n</pre> <pre>\n<code>Epoch 1/5\n100/100 [==============================] - 6s 50ms/step - loss: -24.9882 - KR: 24.9882\nEpoch 2/5\n100/100 [==============================] - 5s 49ms/step - loss: -34.9959 - KR: 34.9959\nEpoch 3/5\n100/100 [==============================] - 5s 49ms/step - loss: -34.9964 - KR: 34.9964\nEpoch 4/5\n100/100 [==============================] - 5s 50ms/step - loss: -34.9961 - KR: 34.9961\nEpoch 5/5\n100/100 [==============================] - 5s 50ms/step - loss: -34.9957 - KR: 34.9957\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7f6a6b73cfd0&gt;</code>\n</pre> <p>As we can see the loss converge to the value 35 which is the wasserstein distance between the two distributions (square and non-square).</p>"},{"location":"notebooks/demo1/#demo-1-wasserstein-distance-estimation-on-toy-example","title":"Demo 1: Wasserstein distance estimation on toy example","text":"<p>In this notebook we will see how to estimate the wasserstein distance with a Neural net by using the Kantorovich-Rubinestein dual representation.</p>"},{"location":"notebooks/demo1/#wasserstein-distance","title":"Wasserstein distance","text":"<p>The wasserstein distance measure the distance between two probability distribution. Wikipedia article gives a more intuitive definition of it:</p> <p>&gt; Intuitively, if each distribution is viewed as a unit amount of \"dirt\" piled on M, the metric is the minimum \"cost\" of turning one pile into the other, which is assumed to be the amount of dirt that needs to be moved times the mean distance it has to be moved. Because of this analogy, the metric is known in computer science as the earth mover's distance.</p> <p>Mathematically it is defined as:</p> \\[ W_1(\\mu,\\nu) = \\inf_{\\pi \\in \\Pi(\\mu,\\nu)}\\underset{x,z \\sim \\pi}{\\mathbb{E}}\\parallel \\textbf{x}-\\textbf{z} \\parallel \\] <p>where \\(\\Pi(\\mu,\\nu)\\) is the set of all probability measures on \\(\\Omega\\times \\Omega\\) with marginals \\(\\mu\\) and \\(\\nu\\). In most case this equation is not tractable.</p>"},{"location":"notebooks/demo1/#kr-dual-formulation","title":"KR dual formulation","text":"<p>In our setup, the KR dual formulation is stated as following: $$ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] -\\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] $$</p> <p>This state the problem as an optimization problem over the 1-lipschitz functions. Therefore k-Lipschitz networks allows us to solve this maximization problem.</p> <p>[1] C. Anil, J. Lucas, et R. Grosse, \u00ab\u00a0Sorting out Lipschitz function approximation\u00a0\u00bb, arXiv:1811.05381 [cs, stat], nov. 2018.</p> <p>We will illustrate this on a synthetic image dataset where \\(W_1\\) is known.</p>"},{"location":"notebooks/demo1/#parameters-input-images","title":"Parameters input images","text":"<p>The synthetic dataset will be composed image with black or white squares allowing us to check if the computed wasserstein distance is correct. One distribution will be the set of black images, while the other will be the set of images with a square on it. these two distribution are diracs, and the wasserstein distance can be analyticaly computed:</p> <p>In the case to the two diracs the wasserstein distance is then the L1 distance between the two images.</p>"},{"location":"notebooks/demo1/#generate-images","title":"Generate images","text":""},{"location":"notebooks/demo1/#for-binary-generator","title":"for binary generator","text":""},{"location":"notebooks/demo1/#for-ternary-generator","title":"for ternary generator","text":""},{"location":"notebooks/demo1/#expe-parameters","title":"Expe parameters","text":"<p>Now we know the wasserstein distance between the black image and the images with a square on it. For both binary generator and ternary generator this distance is 35.</p> <p>We will then compute this distance using a neural network.</p>"},{"location":"notebooks/demo1/#build-lipschitz-model","title":"Build lipschitz Model","text":""},{"location":"notebooks/demo1/#learn-on-toy-dataset","title":"Learn on toy dataset","text":""},{"location":"notebooks/demo2/","title":"Demo 2: HKR Classifier on toy dataset","text":"<pre><code># pip install deel-lip -qqq\n</code></pre> <pre><code>import numpy as np\nfrom sklearn.datasets import make_moons, make_circles  # the synthetic dataset\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n\n# in order to build our classifier we will use element from tensorflow along with\n# layers from deel-lip\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import ReLU, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import binary_accuracy\n\nfrom deel.lip.model import Model  # use of deel.lip is not mandatory but offers the vanilla_export feature\nfrom deel.lip.layers import SpectralConv2D, SpectralDense, FrobeniusDense\nfrom deel.lip.activations import MaxMin, GroupSort, FullSort, GroupSort2\nfrom deel.lip.losses import HKR, KR, HingeMargin  # custom losses for HKR robust classif\n</code></pre> <pre>\n<code>Matplotlib created a temporary config/cache directory at /tmp/matplotlib-lzatifz2 because the default path (/home/thibaut.boissin/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n2021-09-08 18:23:52.158609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <pre><code>circle_or_moons = 1  # 0 for circle , 1 for moons\nn_samples=5000  # number of sample in the dataset\nnoise=0.05  # amount of noise to add in the data. Tested with 0.14 for circles 0.05 for two moons\nfactor=0.4  # scale factor between the inner and the outer circle\n</code></pre> <pre><code>if circle_or_moons == 0:\n    X,Y=make_circles(n_samples=n_samples,noise=noise,factor=factor)\nelse:\n    X,Y=make_moons(n_samples=n_samples,noise=noise)\n\n# When working with the HKR-classifier, using labels {-1, 1} instead of {0, 1} is advised.\n# This will be explained further on \nY[Y==1]=-1\nY[Y==0]=1\n</code></pre> <pre><code>X1=X[Y==1]\nX2=X[Y==-1]\nsns.scatterplot(X1[:1000,0],X1[:1000,1])\nsns.scatterplot(X2[:1000,0],X2[:1000,1])\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n</code>\n</pre> <pre>\n<code>&lt;AxesSubplot:&gt;</code>\n</pre> <pre><code>batch_size=256\nsteps_per_epoch=40480\nepoch=10\nhidden_layers_size = [256,128,64]  # stucture of the network\nactivation = FullSort  # other lipschitz activation are ReLU, MaxMin, GroupSort2, GroupSort\nmin_margin= 0.29  # minimum margin to enforce between the values of f for each class\n</code></pre> <pre><code># build data generator\ndef otp_generator(batch_size, X, Y):\n    Y_ix = np.array([i for i in range(Y.shape[0])])\n    Y0_ix = Y_ix[Y == 1]\n    Y1_ix = Y_ix[Y == -1]\n    half = Y.shape[0] // 2\n    while True:\n        batch_x = np.zeros(((batch_size,) + (X[0].shape)), dtype=np.float32)\n        batch_y = np.zeros((batch_size, 1), dtype=np.float32)\n        ind = np.random.choice(Y0_ix, size=batch_size // 2, replace=False)\n        batch_x[:batch_size // 2, ] = X[ind]\n        batch_y[:batch_size // 2, 0] = Y[ind]\n        ind = np.random.choice(Y1_ix, size=batch_size // 2, replace=False)\n        batch_x[batch_size // 2:, ] = X[ind]\n        batch_y[batch_size // 2:, 0] = Y[ind]\n\n        yield batch_x, batch_y\ngen=otp_generator(batch_size,X,Y)\n</code></pre> <pre><code>K.clear_session()\n# please note that calling the previous helper function has the exact\n# same effect as the following code:\ninputs = Input((2,))\nx = SpectralDense(256, activation=activation())(inputs)\nx = SpectralDense(128, activation=activation())(x)\nx = SpectralDense(64, activation=activation())(x)\ny = FrobeniusDense(1, activation=None)(x)\nwass = Model(inputs=inputs, outputs=y)\nwass.summary()\n</code></pre> <pre>\n<code>2021-09-08 18:23:54.376987: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:23:54.377747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-08 18:23:54.415033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.415345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:23:54.415372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:23:54.417208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:23:54.417243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:23:54.417819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:23:54.417963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:23:54.419000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:23:54.419454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:23:54.419534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:23:54.419584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.419873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.420126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:23:54.421463: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:23:54.421518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.421774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:23:54.421789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:23:54.421800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:23:54.421811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:23:54.421820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:23:54.421830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:23:54.421840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:23:54.421850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:23:54.421860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:23:54.421899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.422177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.422438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:23:54.422462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:23:54.700971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-08 18:23:54.700991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-08 18:23:54.700995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-08 18:23:54.701140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.701410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.701645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.701868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9056 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n2021-09-08 18:23:54.766864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:23:55.126952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:23:55.127037: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n</code>\n</pre> <pre>\n<code>Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 2)]               0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 256)               1537      \n_________________________________________________________________\nspectral_dense_1 (SpectralDe (None, 128)               65793     \n_________________________________________________________________\nspectral_dense_2 (SpectralDe (None, 64)                16513     \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 1)                 129       \n=================================================================\nTotal params: 83,972\nTrainable params: 41,985\nNon-trainable params: 41,987\n_________________________________________________________________\n</code>\n</pre> <p>As we can see the network has a gradient equal to 1 almost everywhere as all the layers respect this property.</p> <p>It is good to note that the last layer is a <code>FrobeniusDense</code> this is because, when we have a single output, it become equivalent to normalize the frobenius norm and the spectral norm (as we only have a single singular value)</p> <pre><code>optimizer = Adam(lr=0.01)\n</code></pre> <pre><code># as the output of our classifier is in the real range [-1, 1], binary accuracy must be redefined\ndef HKR_binary_accuracy(y_true, y_pred):\n    S_true= tf.dtypes.cast(tf.greater_equal(y_true[:,0], 0),dtype=tf.float32)\n    S_pred= tf.dtypes.cast(tf.greater_equal(y_pred[:,0], 0),dtype=tf.float32)\n    return binary_accuracy(S_true,S_pred)\n</code></pre> <pre><code>wass.compile(\n    loss=HKR(alpha=10,min_margin=min_margin),  # HKR stands for the hinge regularized KR loss\n    metrics=[\n        KR,  # shows the KR term of the loss\n        HingeMargin(min_margin=min_margin),  # shows the hinge term of the loss\n        HKR_binary_accuracy  # shows the classification accuracy\n    ],\n    optimizer=optimizer\n)\n</code></pre> <pre><code>wass.fit_generator(\n    gen,\n    steps_per_epoch=steps_per_epoch // batch_size, \n    epochs=epoch,\n    verbose=1\n)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n2021-09-08 18:23:56.416569: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-08 18:23:56.434380: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n</code>\n</pre> <pre>\n<code>Epoch 1/10\n158/158 [==============================] - 4s 13ms/step - loss: 0.6832 - KR: 0.5668 - HingeMargin: 0.1250 - HKR_binary_accuracy: 0.7808\nEpoch 2/10\n158/158 [==============================] - 2s 13ms/step - loss: -0.7488 - KR: 0.9578 - HingeMargin: 0.0209 - HKR_binary_accuracy: 0.9795\nEpoch 3/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.7921 - KR: 0.9734 - HingeMargin: 0.0181 - HKR_binary_accuracy: 0.9865\nEpoch 4/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8035 - KR: 0.9783 - HingeMargin: 0.0175 - HKR_binary_accuracy: 0.9875\nEpoch 5/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8232 - KR: 0.9749 - HingeMargin: 0.0152 - HKR_binary_accuracy: 0.9913\nEpoch 6/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8207 - KR: 0.9690 - HingeMargin: 0.0148 - HKR_binary_accuracy: 0.9920\nEpoch 7/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8376 - KR: 0.9940 - HingeMargin: 0.0156 - HKR_binary_accuracy: 0.9911\nEpoch 8/10\n158/158 [==============================] - 2s 13ms/step - loss: -0.8252 - KR: 0.9878 - HingeMargin: 0.0163 - HKR_binary_accuracy: 0.9888\nEpoch 9/10\n158/158 [==============================] - 2s 14ms/step - loss: -0.8320 - KR: 0.9810 - HingeMargin: 0.0149 - HKR_binary_accuracy: 0.9926\nEpoch 10/10\n158/158 [==============================] - 2s 13ms/step - loss: -0.8296 - KR: 0.9783 - HingeMargin: 0.0149 - HKR_binary_accuracy: 0.9924\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7eff68093750&gt;</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\nbatch_size=1024\n\nx = np.linspace(X[:,0].min()-0.2, X[:,0].max()+0.2, 120)\ny = np.linspace(X[:,1].min()-0.2, X[:,1].max()+0.2,120)\nxx, yy = np.meshgrid(x, y, sparse=False)\nX_pred=np.stack((xx.ravel(),yy.ravel()),axis=1)\n</code></pre> <pre><code># make predictions of f\npred=wass.predict(X_pred)\n\nY_pred=pred\nY_pred=Y_pred.reshape(x.shape[0],y.shape[0])\n</code></pre> <pre><code>#plot the results\nfig = plt.figure(figsize=(10,7))\nax1 = fig.add_subplot(111)\n\nsns.scatterplot(X[Y==1,0],X[Y==1,1],alpha=0.1,ax=ax1)\nsns.scatterplot(X[Y==-1,0],X[Y==-1,1],alpha=0.1,ax=ax1)\ncset =ax1.contour(xx,yy,Y_pred,cmap='twilight')\nax1.clabel(cset, inline=1, fontsize=10)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n</code>\n</pre> <pre>\n<code>&lt;a list of 7 text.Text objects&gt;</code>\n</pre> <pre><code>from deel.lip.model import vanillaModel\n## this is equivalent to test2 = wass.vanilla_export()\ntest2 = vanillaModel(wass)\ntest2.summary()\n</code></pre> <pre>\n<code>Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 2)]               0         \n_________________________________________________________________\nspectral_dense (Dense)       (None, 256)               768       \n_________________________________________________________________\nspectral_dense_1 (Dense)     (None, 128)               32896     \n_________________________________________________________________\nspectral_dense_2 (Dense)     (None, 64)                8256      \n_________________________________________________________________\nfrobenius_dense (Dense)      (None, 1)                 65        \n=================================================================\nTotal params: 41,985\nTrainable params: 41,985\nNon-trainable params: 0\n_________________________________________________________________\n</code>\n</pre> <pre><code>pred_test=test2.predict(X_pred)\nY_pred=pred_test\nY_pred=Y_pred.reshape(x.shape[0],y.shape[0])\n</code></pre> <pre><code>fig = plt.figure(figsize=(10,7))\nax1 = fig.add_subplot(111)\n#ax2 = fig.add_subplot(312)\n#ax3 = fig.add_subplot(313)\nsns.scatterplot(X[Y==1,0],X[Y==1,1],alpha=0.1,ax=ax1)\nsns.scatterplot(X[Y==-1,0],X[Y==-1,1],alpha=0.1,ax=ax1)\ncset =ax1.contour(xx,yy,Y_pred,cmap='twilight')\nax1.clabel(cset, inline=1, fontsize=10)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n</code>\n</pre> <pre>\n<code>&lt;a list of 7 text.Text objects&gt;</code>\n</pre>"},{"location":"notebooks/demo2/#demo-2-hkr-classifier-on-toy-dataset","title":"Demo 2: HKR Classifier on toy dataset","text":"<p>In this demo notebook we will show how to build a robust classifier based on the regularized version of the Kantorovitch-Rubinstein duality. We will perform this on the <code>two moons</code> synthetic dataset.</p>"},{"location":"notebooks/demo2/#parameters","title":"Parameters","text":"<p>Let's first construct our two moons dataset</p>"},{"location":"notebooks/demo2/#relation-with-optimal-transport","title":"Relation with optimal transport","text":"<p>In this setup we can solve the optimal transport problem between the distribution of <code>X[Y==1]</code> and <code>X[Y==-1]</code>. This usually require to match each element of the first distribution with an element of the second distribution such that this minimize a global cost. In our setup this cost is the $ l_1 $ distance, which will allow us to make use of the KR dual formulation. The overall cost  is then the \\(W_1\\) distance.</p>"},{"location":"notebooks/demo2/#wasserstein-distance","title":"Wasserstein distance","text":"<p>The wasserstein distance measure the distance between two probability distribution. Wikipedia article gives a more intuitive definition of it:</p> <p>&gt; Intuitively, if each distribution is viewed as a unit amount of \"dirt\" piled on {\\displaystyle M}M, the metric is the minimum \"cost\" of turning one pile into the other, which is assumed to be the amount of dirt that needs to be moved times the mean distance it has to be moved. Because of this analogy, the metric is known in computer science as the earth mover's distance.</p> <p>Mathematically it is defined as:</p> \\[ W_1(\\mu,\\nu) = \\inf_{\\pi \\in \\Pi(\\mu,\\nu)}\\underset{x,z \\sim \\pi}{\\mathbb{E}}\\parallel \\textbf{x}-\\textbf{z} \\parallel \\] <p>where \\(\\Pi(\\mu,\\nu)\\) is the set of all probability measures on \\(\\Omega\\times \\Omega\\) with marginals \\(\\mu\\) and \\(\\nu\\). In most case this equation is not tractable.</p> <p>However the \\(W_1\\) distance is known to be untractable in general.</p>"},{"location":"notebooks/demo2/#kr-dual-formulation","title":"KR dual formulation","text":"<p>In our setup, the KR dual formulation is stated as following: $$ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] -\\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] $$</p> <p>This state the problem as an optimization problem over the 1-lipschitz functions. Therefore k-Lipschitz networks allows us to solve this maximization problem.</p>"},{"location":"notebooks/demo2/#hinge-kr-classification","title":"Hinge-KR classification","text":"<p>When dealing with \\(W_1\\) one may note that many functions maximize the maximization problem described above. Also we want this function to be meaningfull in terms of classification. To do so, we want f to be centered in 0, which can be done without altering the inital problem. By doing so we can use the obtained function for binary classification, by looking at the sign of \\(f\\).</p> <p>In order to enforce this, we will add a Hinge term to the loss. It has been shown that this new problem is still a optimal transport problem and that this problem admit a meaningfull optimal solution.</p>"},{"location":"notebooks/demo2/#hkr-classifier","title":"HKR-Classifier","text":"<p>Now we will show how to build a binary classifier based on the regularized version of the KR dual problem.</p> <p>In order to ensure the 1-Lipschitz constraint <code>deel-lip</code> uses spectral normalization. These layers also can also use Bjork orthonormalization to ensure that the gradient of the layer is 1 almost everywhere. Experiment shows that the optimal solution lie in this sub-class of functions.</p>"},{"location":"notebooks/demo2/#build-lipschitz-model","title":"Build lipschitz Model","text":"<p>Let's build our model now.</p>"},{"location":"notebooks/demo2/#learn-classification-on-toy-dataset","title":"Learn classification on toy dataset","text":"<p>Now we are ready to learn the classification task on the two moons dataset.</p>"},{"location":"notebooks/demo2/#plot-output-countour-line","title":"Plot output countour line","text":"<p>As we can see the classifier get a pretty good accuracy. Let's now take a look at the learnt function.  As we are in the 2D space, we can draw a countour plot to visualize f.</p>"},{"location":"notebooks/demo2/#transfer-network-to-a-classical-mlp-and-compare-outputs","title":"Transfer network to a classical MLP and compare outputs","text":"<p>As we saw, our networks use custom layers in order to constrain training. However during inference layers behave exactly as regular <code>Dense</code> or <code>Conv2d</code> layers. Deel-lip has a functionnality to export a model to it's vanilla keras equivalent. Making it more  convenient for inference.</p>"},{"location":"notebooks/demo3/","title":"Demo 3: HKR Classifier on MNIST dataset","text":"<pre><code># pip install deel-lip -qqq\n</code></pre> <pre><code>import tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.python.keras.layers import Input, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import binary_accuracy\nfrom tensorflow.keras.models import Sequential\n\nfrom deel.lip.layers import (\n    SpectralConv2D,\n    SpectralDense,\n    FrobeniusDense,\n    ScaledL2NormPooling2D,\n)\nfrom deel.lip.activations import MaxMin, GroupSort, GroupSort2, FullSort\nfrom deel.lip.losses import HKR, KR, HingeMargin\n</code></pre> <pre>\n<code>2021-09-08 18:34:34.803681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <pre><code>from tensorflow.keras.datasets import mnist\n\n# first we select the two classes\nselected_classes = [0, 8]  # must be two classes as we perform binary classification\n\n\ndef prepare_data(x, y, class_a=0, class_b=8):\n    \"\"\"\n    This function convert the MNIST data to make it suitable for our binary classification\n    setup.\n    \"\"\"\n    # select items from the two selected classes\n    mask = (y == class_a) + (\n        y == class_b\n    )  # mask to select only items from class_a or class_b\n    x = x[mask]\n    y = y[mask]\n    x = x.astype(\"float32\")\n    y = y.astype(\"float32\")\n    # convert from range int[0,255] to float32[-1,1]\n    x /= 255\n    x = x.reshape((-1, 28, 28, 1))\n    # change label to binary classification {-1,1}\n    y[y == class_a] = 1.0\n    y[y == class_b] = -1.0\n    return x, y\n\n\n# now we load the dataset\n(x_train, y_train_ord), (x_test, y_test_ord) = mnist.load_data()\n\n# prepare the data\nx_train, y_train = prepare_data(\n    x_train, y_train_ord, selected_classes[0], selected_classes[1]\n)\nx_test, y_test = prepare_data(\n    x_test, y_test_ord, selected_classes[0], selected_classes[1]\n)\n\n# display infos about dataset\nprint(\n    \"train set size: %i samples, classes proportions: %.3f percent\"\n    % (y_train.shape[0], 100 * y_train[y_train == 1].sum() / y_train.shape[0])\n)\nprint(\n    \"test set size: %i samples, classes proportions: %.3f percent\"\n    % (y_test.shape[0], 100 * y_test[y_test == 1].sum() / y_test.shape[0])\n)\n</code></pre> <pre>\n<code>train set size: 11774 samples, classes proportions: 50.306 percent\ntest set size: 1954 samples, classes proportions: 50.154 percent\n</code>\n</pre> <pre><code># training parameters\nepochs = 10\nbatch_size = 128\n\n# network parameters\nactivation = GroupSort  # ReLU, MaxMin, GroupSort2\n\n# loss parameters\nmin_margin = 1.0\nalpha = 10.0\n</code></pre> <p>Now we can build the network. Here the experiment is done with a MLP. But <code>Deel-lip</code> also provide state of the art 1-Lipschitz convolutions.</p> <pre><code>K.clear_session()\n# helper function to build the 1-lipschitz MLP\nwass = Sequential(\n    layers=[\n        Input((28, 28, 1)),\n        Flatten(),\n        SpectralDense(32, GroupSort2(), use_bias=True),\n        SpectralDense(16, GroupSort2(), use_bias=True),\n        FrobeniusDense(1, activation=None, use_bias=False),\n    ],\n    name=\"lipModel\",\n)\nwass.summary()\n</code></pre> <pre>\n<code>Model: \"lipModel\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 32)                50241     \n_________________________________________________________________\nspectral_dense_1 (SpectralDe (None, 16)                1057      \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 1)                 32        \n=================================================================\nTotal params: 51,330\nTrainable params: 25,664\nNon-trainable params: 25,666\n_________________________________________________________________\n</code>\n</pre> <pre><code>optimizer = Adam(lr=0.001)\n</code></pre> <pre><code># as the output of our classifier is in the real range [-1, 1], binary accuracy must be redefined\ndef HKR_binary_accuracy(y_true, y_pred):\n    S_true = tf.dtypes.cast(tf.greater_equal(y_true[:, 0], 0), dtype=tf.float32)\n    S_pred = tf.dtypes.cast(tf.greater_equal(y_pred[:, 0], 0), dtype=tf.float32)\n    return binary_accuracy(S_true, S_pred)\n</code></pre> <pre><code>wass.compile(\n    loss=HKR(\n        alpha=alpha, min_margin=min_margin\n    ),  # HKR stands for the hinge regularized KR loss\n    metrics=[\n        KR,  # shows the KR term of the loss\n        HingeMargin(min_margin=min_margin),  # shows the hinge term of the loss\n        HKR_binary_accuracy,  # shows the classification accuracy\n    ],\n    optimizer=optimizer,\n)\n</code></pre> <pre><code>wass.fit(\n    x=x_train,\n    y=y_train,\n    validation_data=(x_test, y_test),\n    batch_size=batch_size,\n    shuffle=True,\n    epochs=epochs,\n    verbose=1,\n)\n</code></pre> <pre>\n<code>Epoch 1/10\n92/92 [==============================] - 2s 10ms/step - loss: -1.6675 - KR: 3.7144 - HingeMargin: 0.2047 - HKR_binary_accuracy: 0.9382 - val_loss: -5.0961 - val_KR: 5.5990 - val_HingeMargin: 0.0519 - val_HKR_binary_accuracy: 0.9786\nEpoch 2/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.0297 - KR: 5.5716 - HingeMargin: 0.0542 - HKR_binary_accuracy: 0.9793 - val_loss: -5.4469 - val_KR: 5.7710 - val_HingeMargin: 0.0354 - val_HKR_binary_accuracy: 0.9879\nEpoch 3/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.3788 - KR: 5.7838 - HingeMargin: 0.0405 - HKR_binary_accuracy: 0.9858 - val_loss: -5.6435 - val_KR: 5.9555 - val_HingeMargin: 0.0334 - val_HKR_binary_accuracy: 0.9860\nEpoch 4/10\n92/92 [==============================] - 1s 8ms/step - loss: -5.6172 - KR: 5.9671 - HingeMargin: 0.0350 - HKR_binary_accuracy: 0.9874 - val_loss: -5.7918 - val_KR: 6.0764 - val_HingeMargin: 0.0308 - val_HKR_binary_accuracy: 0.9879\nEpoch 5/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.7598 - KR: 6.0676 - HingeMargin: 0.0308 - HKR_binary_accuracy: 0.9891 - val_loss: -5.8711 - val_KR: 6.1062 - val_HingeMargin: 0.0264 - val_HKR_binary_accuracy: 0.9899\nEpoch 6/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.7647 - KR: 6.0829 - HingeMargin: 0.0318 - HKR_binary_accuracy: 0.9879 - val_loss: -5.8503 - val_KR: 6.1463 - val_HingeMargin: 0.0315 - val_HKR_binary_accuracy: 0.9879\nEpoch 7/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8007 - KR: 6.1082 - HingeMargin: 0.0307 - HKR_binary_accuracy: 0.9884 - val_loss: -5.8470 - val_KR: 6.1179 - val_HingeMargin: 0.0296 - val_HKR_binary_accuracy: 0.9879\nEpoch 8/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8268 - KR: 6.1185 - HingeMargin: 0.0292 - HKR_binary_accuracy: 0.9897 - val_loss: -5.8439 - val_KR: 6.1153 - val_HingeMargin: 0.0294 - val_HKR_binary_accuracy: 0.9889\nEpoch 9/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8865 - KR: 6.1548 - HingeMargin: 0.0268 - HKR_binary_accuracy: 0.9910 - val_loss: -5.8800 - val_KR: 6.1668 - val_HingeMargin: 0.0312 - val_HKR_binary_accuracy: 0.9874\nEpoch 10/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8578 - KR: 6.1453 - HingeMargin: 0.0288 - HKR_binary_accuracy: 0.9892 - val_loss: -5.9233 - val_KR: 6.1783 - val_HingeMargin: 0.0282 - val_HKR_binary_accuracy: 0.9889\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7fce2c6635d0&gt;</code>\n</pre> <p>As we can see the model reach a very decent accuracy on this task.</p>"},{"location":"notebooks/demo3/#demo-3-hkr-classifier-on-mnist-dataset","title":"Demo 3: HKR classifier on MNIST dataset","text":"<p>This notebook will demonstrate learning a binary task on the MNIST0-8 dataset.</p>"},{"location":"notebooks/demo3/#data-preparation","title":"data preparation","text":"<p>For this task we will select two classes: 0 and 8. Labels are changed to {-1,1}, wich is compatible with the Hinge term used in the loss.</p>"},{"location":"notebooks/demo3/#build-lipschitz-model","title":"Build lipschitz Model","text":"<p>Let's first explicit the paremeters of this experiment</p>"},{"location":"notebooks/demo3/#learn-classification-on-mnist","title":"Learn classification on MNIST","text":"<p>Now the model is build, we can learn the task.</p>"},{"location":"notebooks/demo4/","title":"Demo 4: HKR Multiclass and fooling","text":"<pre><code># pip install deel-lip foolbox -qqq\n</code></pre> <pre><code>from deel.lip.layers import (\n    SpectralDense,\n    SpectralConv2D,\n    ScaledL2NormPooling2D,\n    ScaledAveragePooling2D,\n    FrobeniusDense,\n)\nfrom deel.lip.model import Sequential\nfrom deel.lip.activations import GroupSort, FullSort\nfrom deel.lip.losses import MulticlassHKR, MulticlassKR\nfrom deel.lip.callbacks import CondenseCallback\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n</code></pre> <pre>\n<code>2021-09-09 14:03:36.448213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <p>For this example, the dataset <code>fashion_mnist</code> will be used. In order to keep things simple, no data augmentation will be performed.</p> <pre><code># load data\n(x_train, y_train_ord), (x_test, y_test_ord) = fashion_mnist.load_data()\n# standardize and reshape the data\nx_train = np.expand_dims(x_train, -1) / 255\nx_test = np.expand_dims(x_test, -1) / 255\n# one hot encode the labels\ny_train = to_categorical(y_train_ord)\ny_test = to_categorical(y_test_ord)\n</code></pre> <p>Let's build the network. </p> <pre><code># Sequential (resp Model) from deel.model has the same properties as any lipschitz model.\n# It act only as a container, with features specific to lipschitz\n# functions (condensation, vanilla_exportation...)\nmodel = Sequential(\n    [\n        Input(shape=x_train.shape[1:]),\n        # Lipschitz layers preserve the API of their superclass ( here Conv2D )\n        # an optional param is available: k_coef_lip which control the lipschitz\n        # constant of the layer\n        SpectralConv2D(\n            filters=16,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        # usual pooling layer are implemented (avg, max...), but new layers are also available\n      ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        SpectralConv2D(\n            filters=32,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n      ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        # our layers are fully interoperable with existing keras layers\n        Flatten(),\n        SpectralDense(\n            64,\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        FrobeniusDense(\n            y_train.shape[-1], activation=None, use_bias=False, kernel_initializer=\"orthogonal\"\n        ),\n    ],\n    # similary model has a parameter to set the lipschitz constant\n    # to set automatically the constant of each layer\n    k_coef_lip=1.0,\n    name=\"hkr_model\",\n)\n\n# HKR (Hinge-Krantorovich-Rubinstein) optimize robustness along with accuracy\nmodel.compile(\n    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n    # note also in the case of lipschitz networks, more robustness require more parameters.\n    loss=MulticlassHKR(alpha=100, min_margin=.25),\n    optimizer=Adam(1e-4),\n    metrics=[\"accuracy\", MulticlassKR()],\n)\n\nmodel.summary()\n</code></pre> <pre>\n<code>2021-09-09 14:03:38.719310: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-09 14:03:38.719800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-09 14:03:38.750242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.750491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\ncoreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n2021-09-09 14:03:38.750504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-09 14:03:38.751559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-09 14:03:38.751584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-09 14:03:38.752047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-09 14:03:38.752161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-09 14:03:38.753239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-09 14:03:38.753476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-09 14:03:38.753540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-09 14:03:38.753583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.753826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.754040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-09 14:03:38.754479: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-09 14:03:38.754559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.754781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\ncoreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n2021-09-09 14:03:38.754792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-09 14:03:38.754799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-09 14:03:38.754806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-09 14:03:38.754812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-09 14:03:38.754818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-09 14:03:38.754824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-09 14:03:38.754831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-09 14:03:38.754837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-09 14:03:38.754865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.755095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.755303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-09 14:03:38.755319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-09 14:03:39.211037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-09 14:03:39.211059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-09 14:03:39.211064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-09 14:03:39.211182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:39.211426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:39.211643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:39.211849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7250 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\n</code>\n</pre> <pre>\n<code>Model: \"hkr_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nspectral_conv2d (SpectralCon (None, 28, 28, 16)        321       \n_________________________________________________________________\nscaled_l2norm_pooling2d (Sca (None, 14, 14, 16)        0         \n_________________________________________________________________\nspectral_conv2d_1 (SpectralC (None, 14, 14, 32)        9281      \n_________________________________________________________________\nscaled_l2norm_pooling2d_1 (S (None, 7, 7, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1568)              0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 64)                200833    \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 10)                1280      \n=================================================================\nTotal params: 211,715\nTrainable params: 105,856\nNon-trainable params: 105,859\n_________________________________________________________________\n</code>\n</pre> <pre>\n<code>/home/thibaut.boissin/projects/repo_github/deel-lip/deel/lip/model.py:56: UserWarning: Sequential model contains a layer wich is not a Lipschitz layer: flatten\n  layer.name\n</code>\n</pre> <pre><code># fit the model\nmodel.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=100,\n    validation_data=(x_test, y_test),\n    shuffle=True,\n    verbose=1,\n)\n</code></pre> <pre>\n<code>2021-09-09 14:03:40.083840: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-09 14:03:40.100871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n</code>\n</pre> <pre>\n<code>Epoch 1/100\n</code>\n</pre> <pre>\n<code>2021-09-09 14:03:42.102055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-09 14:03:42.320388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-09 14:03:42.331382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n</code>\n</pre> <pre>\n<code>15/15 [==============================] - 5s 117ms/step - loss: 41.2174 - accuracy: 0.1382 - MulticlassKR: 0.0467 - val_loss: 29.5743 - val_accuracy: 0.2798 - val_MulticlassKR: 0.1810\nEpoch 2/100\n15/15 [==============================] - 1s 81ms/step - loss: 25.3826 - accuracy: 0.4441 - MulticlassKR: 0.2389 - val_loss: 19.8280 - val_accuracy: 0.5547 - val_MulticlassKR: 0.3549\nEpoch 3/100\n15/15 [==============================] - 1s 81ms/step - loss: 18.3231 - accuracy: 0.5899 - MulticlassKR: 0.4017 - val_loss: 16.0346 - val_accuracy: 0.6183 - val_MulticlassKR: 0.4835\nEpoch 4/100\n15/15 [==============================] - 1s 81ms/step - loss: 15.0896 - accuracy: 0.6402 - MulticlassKR: 0.5135 - val_loss: 13.9297 - val_accuracy: 0.6470 - val_MulticlassKR: 0.5607\nEpoch 5/100\n15/15 [==============================] - 1s 81ms/step - loss: 13.2237 - accuracy: 0.6814 - MulticlassKR: 0.5821 - val_loss: 12.5531 - val_accuracy: 0.6814 - val_MulticlassKR: 0.6186\nEpoch 6/100\n15/15 [==============================] - 1s 81ms/step - loss: 12.0225 - accuracy: 0.7057 - MulticlassKR: 0.6364 - val_loss: 11.6916 - val_accuracy: 0.6964 - val_MulticlassKR: 0.6655\nEpoch 7/100\n15/15 [==============================] - 1s 81ms/step - loss: 11.2456 - accuracy: 0.7178 - MulticlassKR: 0.6803 - val_loss: 11.0661 - val_accuracy: 0.7131 - val_MulticlassKR: 0.7020\nEpoch 8/100\n15/15 [==============================] - 1s 81ms/step - loss: 10.7023 - accuracy: 0.7343 - MulticlassKR: 0.7144 - val_loss: 10.6094 - val_accuracy: 0.7190 - val_MulticlassKR: 0.7339\nEpoch 9/100\n15/15 [==============================] - 1s 81ms/step - loss: 10.2158 - accuracy: 0.7353 - MulticlassKR: 0.7471 - val_loss: 10.2140 - val_accuracy: 0.7255 - val_MulticlassKR: 0.7639\nEpoch 10/100\n15/15 [==============================] - 1s 80ms/step - loss: 9.9306 - accuracy: 0.7444 - MulticlassKR: 0.7743 - val_loss: 9.8911 - val_accuracy: 0.7341 - val_MulticlassKR: 0.7875\nEpoch 11/100\n15/15 [==============================] - 1s 80ms/step - loss: 9.4766 - accuracy: 0.7500 - MulticlassKR: 0.8008 - val_loss: 9.5676 - val_accuracy: 0.7397 - val_MulticlassKR: 0.8139\nEpoch 12/100\n15/15 [==============================] - 1s 80ms/step - loss: 9.2583 - accuracy: 0.7547 - MulticlassKR: 0.8227 - val_loss: 9.3108 - val_accuracy: 0.7445 - val_MulticlassKR: 0.8375\nEpoch 13/100\n15/15 [==============================] - 1s 81ms/step - loss: 9.0268 - accuracy: 0.7571 - MulticlassKR: 0.8463 - val_loss: 9.0594 - val_accuracy: 0.7461 - val_MulticlassKR: 0.8565\nEpoch 14/100\n15/15 [==============================] - 1s 80ms/step - loss: 8.7289 - accuracy: 0.7631 - MulticlassKR: 0.8653 - val_loss: 8.8221 - val_accuracy: 0.7563 - val_MulticlassKR: 0.8798\nEpoch 15/100\n15/15 [==============================] - 1s 81ms/step - loss: 8.5468 - accuracy: 0.7660 - MulticlassKR: 0.8856 - val_loss: 8.6213 - val_accuracy: 0.7566 - val_MulticlassKR: 0.8976\nEpoch 16/100\n15/15 [==============================] - 1s 80ms/step - loss: 8.3208 - accuracy: 0.7699 - MulticlassKR: 0.9078 - val_loss: 8.4393 - val_accuracy: 0.7672 - val_MulticlassKR: 0.9187\nEpoch 17/100\n15/15 [==============================] - 1s 80ms/step - loss: 8.1348 - accuracy: 0.7747 - MulticlassKR: 0.9288 - val_loss: 8.2421 - val_accuracy: 0.7644 - val_MulticlassKR: 0.9369\nEpoch 18/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.8150 - accuracy: 0.7807 - MulticlassKR: 0.9479 - val_loss: 8.0528 - val_accuracy: 0.7741 - val_MulticlassKR: 0.9598\nEpoch 19/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.7277 - accuracy: 0.7813 - MulticlassKR: 0.9697 - val_loss: 7.8976 - val_accuracy: 0.7749 - val_MulticlassKR: 0.9754\nEpoch 20/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.5802 - accuracy: 0.7822 - MulticlassKR: 0.9866 - val_loss: 7.7375 - val_accuracy: 0.7784 - val_MulticlassKR: 0.9936\nEpoch 21/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.3151 - accuracy: 0.7893 - MulticlassKR: 1.0068 - val_loss: 7.5871 - val_accuracy: 0.7818 - val_MulticlassKR: 1.0131\nEpoch 22/100\n15/15 [==============================] - 1s 81ms/step - loss: 7.2699 - accuracy: 0.7901 - MulticlassKR: 1.0211 - val_loss: 7.4710 - val_accuracy: 0.7807 - val_MulticlassKR: 1.0305\nEpoch 23/100\n15/15 [==============================] - 1s 83ms/step - loss: 7.1052 - accuracy: 0.7939 - MulticlassKR: 1.0391 - val_loss: 7.3397 - val_accuracy: 0.7854 - val_MulticlassKR: 1.0450\nEpoch 24/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.0167 - accuracy: 0.7962 - MulticlassKR: 1.0562 - val_loss: 7.2212 - val_accuracy: 0.7870 - val_MulticlassKR: 1.0637\nEpoch 25/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.8205 - accuracy: 0.8002 - MulticlassKR: 1.0749 - val_loss: 7.1256 - val_accuracy: 0.7895 - val_MulticlassKR: 1.0808\nEpoch 26/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.7542 - accuracy: 0.8013 - MulticlassKR: 1.0923 - val_loss: 7.0068 - val_accuracy: 0.7897 - val_MulticlassKR: 1.0966\nEpoch 27/100\n15/15 [==============================] - 1s 81ms/step - loss: 6.6025 - accuracy: 0.8022 - MulticlassKR: 1.1069 - val_loss: 6.8967 - val_accuracy: 0.7924 - val_MulticlassKR: 1.1105\nEpoch 28/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.5729 - accuracy: 0.8033 - MulticlassKR: 1.1220 - val_loss: 6.8168 - val_accuracy: 0.7951 - val_MulticlassKR: 1.1275\nEpoch 29/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.5147 - accuracy: 0.8074 - MulticlassKR: 1.1347 - val_loss: 6.7141 - val_accuracy: 0.7971 - val_MulticlassKR: 1.1425\nEpoch 30/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.4094 - accuracy: 0.8059 - MulticlassKR: 1.1528 - val_loss: 6.6193 - val_accuracy: 0.7998 - val_MulticlassKR: 1.1605\nEpoch 31/100\n15/15 [==============================] - 1s 82ms/step - loss: 6.3102 - accuracy: 0.8090 - MulticlassKR: 1.1664 - val_loss: 6.5371 - val_accuracy: 0.8005 - val_MulticlassKR: 1.1746\nEpoch 32/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.1902 - accuracy: 0.8078 - MulticlassKR: 1.1889 - val_loss: 6.4705 - val_accuracy: 0.8004 - val_MulticlassKR: 1.1924\nEpoch 33/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.1780 - accuracy: 0.8127 - MulticlassKR: 1.1991 - val_loss: 6.3850 - val_accuracy: 0.8033 - val_MulticlassKR: 1.2076\nEpoch 34/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.1156 - accuracy: 0.8123 - MulticlassKR: 1.2147 - val_loss: 6.3106 - val_accuracy: 0.8091 - val_MulticlassKR: 1.2191\nEpoch 35/100\n15/15 [==============================] - 1s 81ms/step - loss: 6.0083 - accuracy: 0.8143 - MulticlassKR: 1.2322 - val_loss: 6.2621 - val_accuracy: 0.8086 - val_MulticlassKR: 1.2360\nEpoch 36/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.9177 - accuracy: 0.8158 - MulticlassKR: 1.2462 - val_loss: 6.1842 - val_accuracy: 0.8101 - val_MulticlassKR: 1.2483\nEpoch 37/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7953 - accuracy: 0.8186 - MulticlassKR: 1.2662 - val_loss: 6.1092 - val_accuracy: 0.8119 - val_MulticlassKR: 1.2654\nEpoch 38/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7620 - accuracy: 0.8179 - MulticlassKR: 1.2781 - val_loss: 6.0499 - val_accuracy: 0.8126 - val_MulticlassKR: 1.2815\nEpoch 39/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7588 - accuracy: 0.8187 - MulticlassKR: 1.2897 - val_loss: 5.9959 - val_accuracy: 0.8131 - val_MulticlassKR: 1.2936\nEpoch 40/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7005 - accuracy: 0.8208 - MulticlassKR: 1.3042 - val_loss: 5.9460 - val_accuracy: 0.8152 - val_MulticlassKR: 1.3039\nEpoch 41/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.6319 - accuracy: 0.8232 - MulticlassKR: 1.3146 - val_loss: 5.8816 - val_accuracy: 0.8148 - val_MulticlassKR: 1.3217\nEpoch 42/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.6429 - accuracy: 0.8232 - MulticlassKR: 1.3291 - val_loss: 5.8772 - val_accuracy: 0.8151 - val_MulticlassKR: 1.3317\nEpoch 43/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.5395 - accuracy: 0.8245 - MulticlassKR: 1.3460 - val_loss: 5.8039 - val_accuracy: 0.8189 - val_MulticlassKR: 1.3538\nEpoch 44/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.4303 - accuracy: 0.8249 - MulticlassKR: 1.3593 - val_loss: 5.7421 - val_accuracy: 0.8189 - val_MulticlassKR: 1.3669\nEpoch 45/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.3844 - accuracy: 0.8268 - MulticlassKR: 1.3762 - val_loss: 5.6846 - val_accuracy: 0.8217 - val_MulticlassKR: 1.3765\nEpoch 46/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.3307 - accuracy: 0.8281 - MulticlassKR: 1.3873 - val_loss: 5.6413 - val_accuracy: 0.8234 - val_MulticlassKR: 1.3881\nEpoch 47/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.3788 - accuracy: 0.8258 - MulticlassKR: 1.3938 - val_loss: 5.6087 - val_accuracy: 0.8214 - val_MulticlassKR: 1.3971\nEpoch 48/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.2561 - accuracy: 0.8314 - MulticlassKR: 1.4119 - val_loss: 5.5684 - val_accuracy: 0.8215 - val_MulticlassKR: 1.4106\nEpoch 49/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.2374 - accuracy: 0.8276 - MulticlassKR: 1.4266 - val_loss: 5.5116 - val_accuracy: 0.8255 - val_MulticlassKR: 1.4254\nEpoch 50/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.2404 - accuracy: 0.8299 - MulticlassKR: 1.4328 - val_loss: 5.4923 - val_accuracy: 0.8248 - val_MulticlassKR: 1.4351\nEpoch 51/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.2273 - accuracy: 0.8302 - MulticlassKR: 1.4446 - val_loss: 5.4473 - val_accuracy: 0.8252 - val_MulticlassKR: 1.4494\nEpoch 52/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.1193 - accuracy: 0.8302 - MulticlassKR: 1.4615 - val_loss: 5.4205 - val_accuracy: 0.8219 - val_MulticlassKR: 1.4643\nEpoch 53/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.1053 - accuracy: 0.8338 - MulticlassKR: 1.4739 - val_loss: 5.3770 - val_accuracy: 0.8238 - val_MulticlassKR: 1.4766\nEpoch 54/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.9836 - accuracy: 0.8338 - MulticlassKR: 1.4889 - val_loss: 5.3285 - val_accuracy: 0.8259 - val_MulticlassKR: 1.4896\nEpoch 55/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.9996 - accuracy: 0.8337 - MulticlassKR: 1.4994 - val_loss: 5.3168 - val_accuracy: 0.8272 - val_MulticlassKR: 1.4970\nEpoch 56/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.9064 - accuracy: 0.8372 - MulticlassKR: 1.5095 - val_loss: 5.2652 - val_accuracy: 0.8284 - val_MulticlassKR: 1.5102\nEpoch 57/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.9659 - accuracy: 0.8335 - MulticlassKR: 1.5204 - val_loss: 5.2111 - val_accuracy: 0.8284 - val_MulticlassKR: 1.5191\nEpoch 58/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.9272 - accuracy: 0.8351 - MulticlassKR: 1.5316 - val_loss: 5.1873 - val_accuracy: 0.8310 - val_MulticlassKR: 1.5290\nEpoch 59/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.8504 - accuracy: 0.8367 - MulticlassKR: 1.5386 - val_loss: 5.1892 - val_accuracy: 0.8263 - val_MulticlassKR: 1.5440\nEpoch 60/100\n15/15 [==============================] - 1s 82ms/step - loss: 4.7810 - accuracy: 0.8399 - MulticlassKR: 1.5500 - val_loss: 5.1203 - val_accuracy: 0.8298 - val_MulticlassKR: 1.5517\nEpoch 61/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.7313 - accuracy: 0.8394 - MulticlassKR: 1.5630 - val_loss: 5.1206 - val_accuracy: 0.8292 - val_MulticlassKR: 1.5662\nEpoch 62/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.7666 - accuracy: 0.8406 - MulticlassKR: 1.5742 - val_loss: 5.0925 - val_accuracy: 0.8295 - val_MulticlassKR: 1.5692\nEpoch 63/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.6527 - accuracy: 0.8418 - MulticlassKR: 1.5808 - val_loss: 5.0593 - val_accuracy: 0.8302 - val_MulticlassKR: 1.5836\nEpoch 64/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.7434 - accuracy: 0.8410 - MulticlassKR: 1.5952 - val_loss: 5.0201 - val_accuracy: 0.8329 - val_MulticlassKR: 1.5966\nEpoch 65/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.7347 - accuracy: 0.8386 - MulticlassKR: 1.6056 - val_loss: 5.0073 - val_accuracy: 0.8337 - val_MulticlassKR: 1.6002\nEpoch 66/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.6701 - accuracy: 0.8414 - MulticlassKR: 1.6104 - val_loss: 4.9744 - val_accuracy: 0.8345 - val_MulticlassKR: 1.6125\nEpoch 67/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.5813 - accuracy: 0.8430 - MulticlassKR: 1.6230 - val_loss: 4.9599 - val_accuracy: 0.8336 - val_MulticlassKR: 1.6252\nEpoch 68/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.6265 - accuracy: 0.8420 - MulticlassKR: 1.6316 - val_loss: 4.9260 - val_accuracy: 0.8310 - val_MulticlassKR: 1.6337\nEpoch 69/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.6232 - accuracy: 0.8426 - MulticlassKR: 1.6420 - val_loss: 4.8940 - val_accuracy: 0.8365 - val_MulticlassKR: 1.6376\nEpoch 70/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.5432 - accuracy: 0.8430 - MulticlassKR: 1.6507 - val_loss: 4.8714 - val_accuracy: 0.8355 - val_MulticlassKR: 1.6471\nEpoch 71/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.4822 - accuracy: 0.8438 - MulticlassKR: 1.6584 - val_loss: 4.8362 - val_accuracy: 0.8358 - val_MulticlassKR: 1.6575\nEpoch 72/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.4781 - accuracy: 0.8444 - MulticlassKR: 1.6695 - val_loss: 4.8306 - val_accuracy: 0.8372 - val_MulticlassKR: 1.6670\nEpoch 73/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.5386 - accuracy: 0.8424 - MulticlassKR: 1.6777 - val_loss: 4.8021 - val_accuracy: 0.8364 - val_MulticlassKR: 1.6715\nEpoch 74/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.4138 - accuracy: 0.8447 - MulticlassKR: 1.6880 - val_loss: 4.7918 - val_accuracy: 0.8377 - val_MulticlassKR: 1.6845\nEpoch 75/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.4090 - accuracy: 0.8476 - MulticlassKR: 1.6962 - val_loss: 4.7612 - val_accuracy: 0.8368 - val_MulticlassKR: 1.6925\nEpoch 76/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.4482 - accuracy: 0.8459 - MulticlassKR: 1.6987 - val_loss: 4.7491 - val_accuracy: 0.8363 - val_MulticlassKR: 1.7041\nEpoch 77/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.3394 - accuracy: 0.8462 - MulticlassKR: 1.7108 - val_loss: 4.7155 - val_accuracy: 0.8387 - val_MulticlassKR: 1.7075\nEpoch 78/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.3768 - accuracy: 0.8482 - MulticlassKR: 1.7117 - val_loss: 4.6795 - val_accuracy: 0.8396 - val_MulticlassKR: 1.7135\nEpoch 79/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.3540 - accuracy: 0.8476 - MulticlassKR: 1.7259 - val_loss: 4.6666 - val_accuracy: 0.8388 - val_MulticlassKR: 1.7266\nEpoch 80/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.2509 - accuracy: 0.8469 - MulticlassKR: 1.7359 - val_loss: 4.6558 - val_accuracy: 0.8357 - val_MulticlassKR: 1.7321\nEpoch 81/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.2792 - accuracy: 0.8461 - MulticlassKR: 1.7397 - val_loss: 4.6639 - val_accuracy: 0.8364 - val_MulticlassKR: 1.7419\nEpoch 82/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.2849 - accuracy: 0.8465 - MulticlassKR: 1.7502 - val_loss: 4.6150 - val_accuracy: 0.8389 - val_MulticlassKR: 1.7488\nEpoch 83/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.2858 - accuracy: 0.8466 - MulticlassKR: 1.7563 - val_loss: 4.6256 - val_accuracy: 0.8382 - val_MulticlassKR: 1.7551\nEpoch 84/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.1836 - accuracy: 0.8491 - MulticlassKR: 1.7594 - val_loss: 4.5682 - val_accuracy: 0.8401 - val_MulticlassKR: 1.7607\nEpoch 85/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1970 - accuracy: 0.8497 - MulticlassKR: 1.7701 - val_loss: 4.5760 - val_accuracy: 0.8405 - val_MulticlassKR: 1.7660\nEpoch 86/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1455 - accuracy: 0.8507 - MulticlassKR: 1.7759 - val_loss: 4.5417 - val_accuracy: 0.8425 - val_MulticlassKR: 1.7734\nEpoch 87/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1810 - accuracy: 0.8506 - MulticlassKR: 1.7823 - val_loss: 4.5125 - val_accuracy: 0.8417 - val_MulticlassKR: 1.7786\nEpoch 88/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1159 - accuracy: 0.8518 - MulticlassKR: 1.7922 - val_loss: 4.5125 - val_accuracy: 0.8391 - val_MulticlassKR: 1.7913\nEpoch 89/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.1807 - accuracy: 0.8500 - MulticlassKR: 1.7990 - val_loss: 4.4882 - val_accuracy: 0.8402 - val_MulticlassKR: 1.7938\nEpoch 90/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1548 - accuracy: 0.8504 - MulticlassKR: 1.8031 - val_loss: 4.5046 - val_accuracy: 0.8421 - val_MulticlassKR: 1.8073\nEpoch 91/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1227 - accuracy: 0.8501 - MulticlassKR: 1.8102 - val_loss: 4.4483 - val_accuracy: 0.8408 - val_MulticlassKR: 1.8036\nEpoch 92/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.1302 - accuracy: 0.8512 - MulticlassKR: 1.8124 - val_loss: 4.4501 - val_accuracy: 0.8435 - val_MulticlassKR: 1.8101\nEpoch 93/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.0846 - accuracy: 0.8502 - MulticlassKR: 1.8184 - val_loss: 4.4205 - val_accuracy: 0.8425 - val_MulticlassKR: 1.8175\nEpoch 94/100\n15/15 [==============================] - 1s 80ms/step - loss: 3.9720 - accuracy: 0.8539 - MulticlassKR: 1.8275 - val_loss: 4.4813 - val_accuracy: 0.8381 - val_MulticlassKR: 1.8186\nEpoch 95/100\n15/15 [==============================] - 1s 81ms/step - loss: 3.9978 - accuracy: 0.8542 - MulticlassKR: 1.8309 - val_loss: 4.3855 - val_accuracy: 0.8440 - val_MulticlassKR: 1.8287\nEpoch 96/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.0764 - accuracy: 0.8506 - MulticlassKR: 1.8369 - val_loss: 4.3828 - val_accuracy: 0.8443 - val_MulticlassKR: 1.8371\nEpoch 97/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.0436 - accuracy: 0.8517 - MulticlassKR: 1.8470 - val_loss: 4.3730 - val_accuracy: 0.8457 - val_MulticlassKR: 1.8344\nEpoch 98/100\n15/15 [==============================] - 1s 81ms/step - loss: 3.9989 - accuracy: 0.8532 - MulticlassKR: 1.8491 - val_loss: 4.3596 - val_accuracy: 0.8445 - val_MulticlassKR: 1.8446\nEpoch 99/100\n15/15 [==============================] - 1s 80ms/step - loss: 3.9820 - accuracy: 0.8541 - MulticlassKR: 1.8539 - val_loss: 4.3444 - val_accuracy: 0.8442 - val_MulticlassKR: 1.8477\nEpoch 100/100\n15/15 [==============================] - 1s 80ms/step - loss: 3.9592 - accuracy: 0.8523 - MulticlassKR: 1.8626 - val_loss: 4.3177 - val_accuracy: 0.8448 - val_MulticlassKR: 1.8529\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7f9e52213c10&gt;</code>\n</pre> <pre><code># once training is finished you can convert\n# SpectralDense layers into Dense layers and SpectralConv2D into Conv2D\n# which optimize performance for inference\nvanilla_model = model.vanilla_export()\n</code></pre> <pre><code>import foolbox as fb\nfrom tensorflow import convert_to_tensor\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n</code></pre> <pre>\n<code>Matplotlib created a temporary config/cache directory at /tmp/matplotlib-an1t4aqt because the default path (/home/thibaut.boissin/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n</code>\n</pre> <pre><code># we will test it on 10 samples one of each class\nnb_adv = 10\n\nhkr_fmodel = fb.TensorFlowModel(vanilla_model, bounds=(0., 1.), device=\"/GPU:0\")\n</code></pre> <p>In order to test the robustness of the model, the first correctly classified element of each class are selected.</p> <pre><code># strategy: first\n# we select a sample from each class.\nimages_list = []\nlabels_list = []\n# select only a few element from the test set\nselected=np.random.choice(len(y_test_ord), 500)\nsub_y_test_ord = y_test_ord[:300]\nsub_x_test = x_test[:300]\n# drop misclassified elements\nmisclassified_mask = tf.equal(tf.argmax(vanilla_model.predict(sub_x_test), axis=-1), sub_y_test_ord)\nsub_x_test = sub_x_test[misclassified_mask]\nsub_y_test_ord = sub_y_test_ord[misclassified_mask]\n# now we will build a list with input image for each element of the matrix\nfor i in range(10):\n  # select the first element of the ith label\n  label_mask = [sub_y_test_ord==i]\n  x = sub_x_test[label_mask][0]\n  y = sub_y_test_ord[label_mask][0]\n  # convert it to tensor for use with foolbox\n  images = convert_to_tensor(x.astype(\"float32\"), dtype=\"float32\")\n  labels = convert_to_tensor(y, dtype=\"int64\")\n  # repeat the input 10 times, one per misclassification target\n  images_list.append(images)\n  labels_list.append(labels)\nimages = convert_to_tensor(images_list)\nlabels = convert_to_tensor(labels_list)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/deel-lip_github/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n/home/thibaut.boissin/envs/deel-lip_github/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n</code>\n</pre> <p>In order to build a certficate, we take for each sample the top 2 output and apply this formula: $$ \\epsilon \\geq \\frac{\\text{top}_1 - \\text{top}_2}{2} $$ Where epsilon is the robustness radius for the considered sample.</p> <pre><code>values, classes = tf.math.top_k(hkr_fmodel(images), k=2)\ncertificates = (values[:, 0] - values[:, 1]) / 2\ncertificates\n</code></pre> <pre>\n<code>&lt;tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.25511226, 1.0321686 , 0.34624586, 0.5743104 , 0.12979731,\n       0.19581676, 0.08184442, 0.34386343, 0.68743587, 0.12055641],\n      dtype=float32)&gt;</code>\n</pre> <p>now we will attack the model to check if the certificates are respected. In this setup <code>L2CarliniWagnerAttack</code> is used but in practice as these kind of networks are gradient norm preserving, other attacks gives very similar results.</p> <pre><code>attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=6, steps=8000)\nimgs, advs, success = attack(hkr_fmodel, images, labels, epsilons=None)\ndist_to_adv = np.sqrt(np.sum(np.square(images - advs), axis=(1,2,3)))\ndist_to_adv\n</code></pre> <pre>\n<code>array([1.3944995 , 3.5208094 , 1.6824133 , 1.9192038 , 0.5746496 ,\n       0.7780392 , 0.39687884, 1.1619285 , 2.367604  , 0.48984095],\n      dtype=float32)</code>\n</pre> <p>As we can see the certificate are respected.</p> <pre><code>tf.assert_less(certificates, dist_to_adv)\n</code></pre> <p>Finally we can take a visual look at the obtained examples. We first start with utility functions for display.</p> <pre><code>class_mapping = {\n  0: \"T-shirt/top\",\n  1: \"Trouser\",\n  2: \"Pullover\",\n  3: \"Dress\",\n  4: \"Coat\",\n  5: \"Sandal\",\n  6: \"Shirt\",\n  7: \"Sneaker\",\n  8: \"Bag\",\n  9: \"Ankle boot\",\n}\n</code></pre> <pre><code>def adversarial_viz(model, images, advs, class_mapping):\n  \"\"\"\n  This functions shows for each sample: \n  - the original image\n  - the adversarial image\n  - the difference map\n  - the certificate and the observed distance to adversarial \n  \"\"\"\n  scale = 1.5\n  kwargs={}\n  nb_imgs = images.shape[0]\n  # compute certificates\n  values, classes = tf.math.top_k(model(images), k=2)\n  certificates = (values[:, 0] - values[:, 1]) / 2\n  # compute difference distance to adversarial\n  dist_to_adv = np.sqrt(np.sum(np.square(images - advs), axis=(1,2,3)))\n  # find classes labels for imgs and advs\n  orig_classes = [class_mapping[i] for i in tf.argmax(model(images), axis=-1).numpy()]\n  advs_classes = [class_mapping[i] for i in tf.argmax(model(advs), axis=-1).numpy()]\n  # compute differences maps\n  if images.shape[-1] != 3:\n    diff_pos = np.clip(advs - images, 0, 1.)\n    diff_neg = np.clip(images - advs, 0, 1.)\n    diff_map = np.concatenate([diff_neg, diff_pos, np.zeros_like(diff_neg)], axis=-1)\n  else:\n    diff_map = np.abs(advs - images)\n  # expands image to be displayed\n  if images.shape[-1] != 3:\n    images = np.repeat(images, 3, -1)\n  if advs.shape[-1] != 3:\n    advs = np.repeat(advs, 3, -1)\n  # create plot\n  figsize = (3 * scale, nb_imgs * scale)\n  fig, axes = plt.subplots(\n    ncols=3,\n    nrows=nb_imgs,\n    figsize=figsize,\n    squeeze=False,\n    constrained_layout=True,\n    **kwargs,\n  )\n  for i in range(nb_imgs):\n    ax = axes[i][0]\n    ax.set_title(orig_classes[i])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.axis(\"off\")\n    ax.imshow(images[i])\n    ax = axes[i][1]\n    ax.set_title(advs_classes[i])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.axis(\"off\")\n    ax.imshow(advs[i])\n    ax = axes[i][2]\n    ax.set_title(f\"certif: {certificates[i]:.2f}, obs: {dist_to_adv[i]:.2f}\")\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.axis(\"off\")\n    ax.imshow(diff_map[i]/diff_map[i].max())\n</code></pre> <p>When looking at the adversarial examples we can see that the network has interresting properties:</p> <pre><code>adversarial_viz(hkr_fmodel, images, advs, class_mapping)\n</code></pre>"},{"location":"notebooks/demo4/#demo-4-hkr-multiclass-and-fooling","title":"Demo 4: HKR multiclass and fooling","text":"<p>This notebook will show how to train a lispchitz network in a multiclass setup. The HKR is extended to multiclass using a one-vs all setup. It will go through the process of designing and training the network. It will also show how to create robustness certificates from the output of the network. Finally these certificates will be checked by attacking the network. </p>"},{"location":"notebooks/demo4/#installation","title":"installation","text":"<p>First, we install the required libraries. <code>Foolbox</code> will allow to perform adversarial attacks on the trained network.</p>"},{"location":"notebooks/demo4/#the-architecture","title":"the architecture","text":"<p>The original one vs all setup would require 10 different networks ( 1 per class ), however, in practice we use a network with a common body and 10 1-lipschitz heads. Experiments have shown that this setup don't affect the network performance. In order to ease the creation of such network, <code>FrobeniusDense</code> layer has a parameter for this:  whenr <code>disjoint_neurons=True</code> it act as the stacking of 10 single neurons head. Note that, altough each head is a 1-lipschitz function the overall network is not 1-lipschitz (Concatenation is not 1-lipschitz). We will see later how this affects the certficate creation.</p>"},{"location":"notebooks/demo4/#the-loss","title":"the loss","text":"<p>The multiclass loss can be found in <code>HKR_multiclass_loss</code>. The loss has two params: <code>alpha</code> and <code>min_margin</code>. Decreasing <code>alpha</code> and increasing <code>min_margin</code> improve robustness (at the cost of accuracy). note also in the case of lipschitz networks, more robustness require more parameters. For more information see our paper.</p> <p>In this setup choosing <code>alpha=100</code>, <code>min_margin=.25</code> provide a good robustness without hurting the accuracy too much.</p> <p>Finally the <code>KR_multiclass_loss()</code> indicate the robustness of the network ( proxy of the average certificate )</p>"},{"location":"notebooks/demo4/#notes-about-constraint-enforcement","title":"notes about constraint enforcement","text":"<p>There are currently 3 way to enforce a constraint in a network: 1. regularization 2. weight reparametrization 3. weight projection</p> <p>The first one don't provide the required garanties, this is why <code>deel-lip</code> focuses on the later two. Weight reparametrization is done directly in the layers (parameter <code>niter_bjorck</code>) this trick allow to perform arbitrary gradient updates without breaking the constraint. However this is done in the graph, increasing ressources consumption. The last method project the weights between each batch, ensuring the constraint at an more affordable computational cost. It can be done in <code>deel-lip</code> using the <code>CondenseCallback</code>. The main problem with this method is a reduced efficiency of each update.</p> <p>As a rule of thumb, when reparametrization is used alone, setting <code>niter_bjorck</code> to at least 15 is advised. However when combined with weight projection, this setting can be lowered greatly.</p>"},{"location":"notebooks/demo4/#model-exportation","title":"model exportation","text":"<p>Once training is finished, the model can be optimized for inference by using the <code>vanilla_export()</code> method.</p>"},{"location":"notebooks/demo4/#certificates-generation-and-adversarial-attacks","title":"certificates generation and adversarial attacks","text":""},{"location":"notebooks/demo4/#predictability","title":"predictability","text":"<p>by looking at the certificates, we can predict if the adversarial example will be close of not</p>"},{"location":"notebooks/demo4/#disparity-among-classes","title":"disparity among classes","text":"<p>As we can see, the attacks are very efficent on similar classes (eg. T-shirt/top, and Shirt ). This denote that all classes are not made equal regarding robustness.</p>"},{"location":"notebooks/demo4/#explainability","title":"explainability","text":"<p>The network is more explainable: attacks can be used as counterfactuals. We can tell that removing the inscription on a T-shirt turns it into a shirt makes sense. Non robust examples reveals that the network rely on textures rather on shapes to make it's decision.</p>"}]}