{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Explore DEEL-LIP docs \u00bb"},{"location":"#welcome-to-deel-lip-documentation","title":"\ud83d\udc4b Welcome to deel-lip documentation!","text":"<p>Controlling the Lipschitz constant of a layer or a whole neural network has many applications ranging from adversarial robustness to Wasserstein distance estimation.</p> <p>This library provides an efficient implementation of k-Lispchitz layers for keras.</p>"},{"location":"#table-of-contents","title":"\ud83d\udcda Table of contents","text":"<ul> <li>\ud83d\udcda Table of contents</li> <li>\ud83d\udd25 Tutorials</li> <li>\ud83d\ude80 Quick Start</li> <li>\ud83d\udce6 What's Included</li> <li>\ud83d\udc4d Contributing</li> <li>\ud83d\udc40 See Also</li> <li>\ud83d\ude4f Acknowledgments</li> <li>\ud83d\uddde\ufe0f Citation</li> <li>\ud83d\udcdd License</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>You can install <code>deel-lip</code> directly from pypi:</p> <pre><code>pip install deel-lip\n</code></pre> <p>In order to use <code>deel-lip</code>, you also need a valid tensorflow installation. <code>deel-lip</code> supports tensorflow versions 2.x.</p>"},{"location":"#tutorials","title":"\ud83d\udd25 Tutorials","text":"Tutorial Name Notebook Getting Started Wasserstein distance estimation on toy example HKR Classifier on toy dataset HKR classifier on MNIST dataset HKR multiclass and fooling"},{"location":"#whats-included","title":"\ud83d\udce6 What's Included","text":"<ul> <li>k-Lipschitz variant of keras layers such as <code>Dense</code>, <code>Conv2D</code> and    <code>Pooling</code>,</li> <li>activation functions compatible with <code>keras</code>,</li> <li>kernel initializers and kernel constraints for <code>keras</code>,</li> <li>loss functions that make use of Lipschitz constrained networks (see    our paper for more    information),</li> <li>tools to monitor the singular values of kernels during training,</li> <li>tools to convert k-Lipschitz network to regular network for faster    inference.</li> </ul>"},{"location":"#contributing","title":"\ud83d\udc4d Contributing","text":"<p>To contribute, you can open an issue, or fork this repository and then submit changes through a pull-request. We use black to format the code and follow PEP-8 convention. To check that your code will pass the lint-checks, you can run:</p> <pre><code>tox -e py36-lint\n</code></pre> <p>You need <code>tox</code> in order to run this. You can install it via <code>pip</code>:</p> <pre><code>pip install tox\n</code></pre>"},{"location":"#see-also","title":"\ud83d\udc40 See Also","text":"<p>More from the DEEL project:</p> <ul> <li>Xplique a Python library exclusively dedicated to explaining neural networks.</li> <li>Influenciae Python toolkit dedicated to computing influence values for the discovery of potentially problematic samples in a dataset.</li> <li>deel-torchlip a Python library for training k-Lipschitz neural networks on PyTorch.</li> <li>DEEL White paper a summary of the DEEL team on the challenges of certifiable AI and the role of data quality, representativity and explainability for this purpose.</li> </ul>"},{"location":"#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<p>  This project received funding from the French \u201dInvesting for the Future \u2013 PIA3\u201d program within the Artificial and Natural Intelligence Toulouse Institute (ANITI). The authors gratefully acknowledge the support of the  DEEL  project.</p>"},{"location":"#citation","title":"\ud83d\uddde\ufe0f Citation","text":"<p>This library has been built to support the work presented in the paper Achieving robustness in classification using optimaltransport with Hinge regularization which aim provable and efficient robustness by design.</p> <p>This work can be cited as:</p> <pre><code>@misc{2006.06520,\n    Author = {Mathieu Serrurier and Franck Mamalet and Alberto Gonz\u00e1lez-Sanz and Thibaut Boissin and Jean-Michel Loubes and Eustasio del Barrio},\n    Title = {Achieving robustness in classification using optimal transport with hinge regularization},\n    Year = {2020},\n    Eprint = {arXiv:2006.06520},\n}\n</code></pre>"},{"location":"#license","title":"\ud83d\udcdd License","text":"<p>The package is released under  MIT license.</p>"},{"location":"api/activations/","title":"deel.lip.activations","text":"<p>Warning</p> <p><code>deel.lip.activations</code> module is deprecated. All activation layers and functions are now available directly in <code>deel.lip.layers</code> module, e.g. <code>deel.lip.layers.GroupSort2</code>.</p> <p><code>deel.lip.activations</code> module is still available for retro-compatibility but will be definitely removed in deel-lip 1.6.0.</p>"},{"location":"api/callbacks/","title":"deel.lip.callbacks","text":"<p>This module contains callbacks that can be added to keras training process.</p>"},{"location":"api/callbacks/#deel.lip.callbacks.CondenseCallback","title":"<code>CondenseCallback</code>","text":"<p>         Bases: <code>Callback</code></p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>class CondenseCallback(Callback):\n    def __init__(self, on_epoch: bool = True, on_batch: bool = False):\n\"\"\"\n        Automatically condense layers of a model on batches/epochs. Condensing a layer\n        consists in overwriting the kernel with the constrained weights. This prevents\n        the explosion/vanishing of values inside the original kernel.\n\n        Warning:\n            Overwriting the kernel may disturb the optimizer, especially if it has a\n            non-zero momentum.\n\n        Args:\n            on_epoch: if True apply the constraint between epochs\n            on_batch: if True apply constraints between batches\n        \"\"\"\n        super().__init__()\n        self.on_epoch = on_epoch\n        self.on_batch = on_batch\n\n    def _condense_model(self):\n        for layer in self.model.layers:\n            if isinstance(layer, Condensable) or hasattr(layer, \"condense\"):\n                layer.condense()\n\n    def on_train_batch_end(self, batch: int, logs: Optional[Dict[str, float]] = None):\n        if self.on_batch:\n            self._condense_model()\n        super(CondenseCallback, self).on_train_batch_end(batch, logs)\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict[str, float]] = None):\n        if self.on_epoch:\n            self._condense_model()\n        super(CondenseCallback, self).on_epoch_end(epoch, logs)\n\n    def get_config(self):\n        config = {\"on_epoch\": self.on_epoch, \"on_batch\": self.on_batch}\n        base_config = super(CondenseCallback, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.CondenseCallback.__init__","title":"<code>__init__(on_epoch=True, on_batch=False)</code>","text":"<p>Automatically condense layers of a model on batches/epochs. Condensing a layer consists in overwriting the kernel with the constrained weights. This prevents the explosion/vanishing of values inside the original kernel.</p> Warning <p>Overwriting the kernel may disturb the optimizer, especially if it has a non-zero momentum.</p> <p>Parameters:</p> Name Type Description Default <code>on_epoch</code> <code>bool</code> <p>if True apply the constraint between epochs</p> <code>True</code> <code>on_batch</code> <code>bool</code> <p>if True apply constraints between batches</p> <code>False</code> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(self, on_epoch: bool = True, on_batch: bool = False):\n\"\"\"\n    Automatically condense layers of a model on batches/epochs. Condensing a layer\n    consists in overwriting the kernel with the constrained weights. This prevents\n    the explosion/vanishing of values inside the original kernel.\n\n    Warning:\n        Overwriting the kernel may disturb the optimizer, especially if it has a\n        non-zero momentum.\n\n    Args:\n        on_epoch: if True apply the constraint between epochs\n        on_batch: if True apply constraints between batches\n    \"\"\"\n    super().__init__()\n    self.on_epoch = on_epoch\n    self.on_batch = on_batch\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.LossParamLog","title":"<code>LossParamLog</code>","text":"<p>         Bases: <code>Callback</code></p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>class LossParamLog(Callback):\n    def __init__(self, param_name, rate=1):\n\"\"\"\n        Logger to print values of a loss parameter at each epoch.\n\n        Args:\n            param_name (str): name of the parameter of the loss to log.\n            rate (int): logging rate (in epochs)\n        \"\"\"\n        self.param_name = param_name\n        self.rate = rate\n\n    def on_epoch_end(self, epoch: int, logs=None):\n        if epoch % self.rate == 0:\n            tf.print(\n                \"\\n\",\n                self.model.loss.name,\n                self.param_name,\n                self.model.loss.__getattribute__(self.param_name),\n            )\n        super(LossParamLog, self).on_train_batch_end(epoch, logs)\n\n    def get_config(self):\n        return {\n            \"param_name\": self.param_name,\n            \"rate\": self.rate,\n        }\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.LossParamLog.__init__","title":"<code>__init__(param_name, rate=1)</code>","text":"<p>Logger to print values of a loss parameter at each epoch.</p> <p>Parameters:</p> Name Type Description Default <code>param_name</code> <code>str</code> <p>name of the parameter of the loss to log.</p> required <code>rate</code> <code>int</code> <p>logging rate (in epochs)</p> <code>1</code> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(self, param_name, rate=1):\n\"\"\"\n    Logger to print values of a loss parameter at each epoch.\n\n    Args:\n        param_name (str): name of the parameter of the loss to log.\n        rate (int): logging rate (in epochs)\n    \"\"\"\n    self.param_name = param_name\n    self.rate = rate\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.LossParamScheduler","title":"<code>LossParamScheduler</code>","text":"<p>         Bases: <code>Callback</code></p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>class LossParamScheduler(Callback):\n    def __init__(self, param_name, fp, xp, step=0):\n\"\"\"\n        Scheduler to modify a loss parameter during training. It uses a linear\n        interpolation (defined by fp and xp) depending on the optimization step.\n\n        Args:\n            param_name (str): name of the parameter of the loss to tune. Must be a\n                tf.Variable.\n            fp (list): values of the loss parameter as steps given by the xp.\n            xp (list): step where the parameter equals fp.\n            step (int): step value, for serialization/deserialization purposes.\n        \"\"\"\n        self.xp = xp\n        self.fp = fp\n        self.step = step\n        self.param_name = param_name\n\n    def on_train_batch_begin(self, batch: int, logs=None):\n        new_value = np.interp(self.step, self.xp, self.fp)\n        self.model.loss.__getattribute__(self.param_name).assign(new_value)\n        self.step += 1\n        super(LossParamScheduler, self).on_train_batch_end(batch, logs)\n\n    def get_config(self):\n        return {\n            \"xp\": self.xp,\n            \"fp\": self.fp,\n            \"step\": self.step,\n            \"param_name\": self.param_name,\n        }\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.LossParamScheduler.__init__","title":"<code>__init__(param_name, fp, xp, step=0)</code>","text":"<p>Scheduler to modify a loss parameter during training. It uses a linear interpolation (defined by fp and xp) depending on the optimization step.</p> <p>Parameters:</p> Name Type Description Default <code>param_name</code> <code>str</code> <p>name of the parameter of the loss to tune. Must be a tf.Variable.</p> required <code>fp</code> <code>list</code> <p>values of the loss parameter as steps given by the xp.</p> required <code>xp</code> <code>list</code> <p>step where the parameter equals fp.</p> required <code>step</code> <code>int</code> <p>step value, for serialization/deserialization purposes.</p> <code>0</code> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(self, param_name, fp, xp, step=0):\n\"\"\"\n    Scheduler to modify a loss parameter during training. It uses a linear\n    interpolation (defined by fp and xp) depending on the optimization step.\n\n    Args:\n        param_name (str): name of the parameter of the loss to tune. Must be a\n            tf.Variable.\n        fp (list): values of the loss parameter as steps given by the xp.\n        xp (list): step where the parameter equals fp.\n        step (int): step value, for serialization/deserialization purposes.\n    \"\"\"\n    self.xp = xp\n    self.fp = fp\n    self.step = step\n    self.param_name = param_name\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.MonitorCallback","title":"<code>MonitorCallback</code>","text":"<p>         Bases: <code>Callback</code></p> Source code in <code>deel/lip/callbacks.py</code> <pre><code>class MonitorCallback(Callback):\n    def __init__(\n        self,\n        monitored_layers: Iterable[str],\n        logdir: str,\n        target: str = \"kernel\",\n        what: str = \"max\",\n        on_epoch: bool = True,\n        on_batch: bool = False,\n    ):\n\"\"\"\n        Allow to monitor the singular values of specified layers during training. This\n        analyze the singular values of the original kernel (before reparametrization).\n        Two modes can be chosen: \"max\" plots the largest singular value over training,\n        while \"all\" plots the distribution of the singular values over training (series\n        of distribution).\n\n        Args:\n            monitored_layers: list of layer name to monitor.\n            logdir: path to the logging directory.\n            target: describe what to monitor, can either \"kernel\" or \"wbar\". Setting\n                to \"kernel\" check values of the unconstrained weights while setting to\n                \"wbar\" check values of the constrained weights (allowing to check if\n                the parameters are correct to ensure lipschitz constraint)\n            what: either \"max\", which display the largest singular value over the\n                training process, or \"all\", which plot the distribution of all singular\n                values.\n            on_epoch: if True apply the constraint between epochs.\n            on_batch: if True apply constraints between batches.\n        \"\"\"\n        self.on_epoch = on_epoch\n        self.on_batch = on_batch\n        assert target in {\"kernel\", \"wbar\"}\n        self.target = target\n        assert what in {\"max\", \"all\"}\n        self.what = what\n        self.logdir = logdir\n        self.file_writer = tf.summary.create_file_writer(\n            os.path.join(logdir, \"metrics\")\n        )\n        self.monitored_layers = monitored_layers\n        if on_batch and on_epoch:\n            self.on_epoch = False  # avoid display bug (inconsistent steps)\n        self.epochs = 0\n        super().__init__()\n\n    def _monitor(self, step):\n        step = self.params[\"steps\"] * self.epochs + step\n        for layer_name in self.monitored_layers:\n            layer = self.model.get_layer(layer_name)\n            if (\n                (self.target == \"kernel\")\n                and (self.what == \"max\")\n                and hasattr(layer, \"sig\")\n            ):\n                sig = layer.sig[0, 0]\n            elif hasattr(layer, self.target):\n                kernel = getattr(layer, self.target)\n                w_shape = kernel.shape.as_list()\n                sigmas = tf.linalg.svd(\n                    tf.keras.backend.reshape(kernel, [-1, w_shape[-1]]),\n                    full_matrices=False,\n                    compute_uv=False,\n                ).numpy()\n                sig = sigmas[0]\n            else:\n                RuntimeWarning(\n                    f\"[MonitorCallback] layer {layer_name} has no \"\n                    f\"attribute {self.target}\"\n                )\n                return\n            if self.what == \"max\":\n                with self.file_writer.as_default():\n                    result = tf.summary.scalar(\n                        f\"{layer_name}_{self.target}_sigmas\", sig, step=step\n                    )\n            else:\n                with self.file_writer.as_default():\n                    result = tf.summary.histogram(\n                        f\"{layer_name}_{self.target}_sigmas\",\n                        sigmas,\n                        step=step,\n                        buckets=None,\n                        description=\"distribution of singular values for layer %s\"\n                        % layer_name,\n                    )\n            if not result:\n                RuntimeWarning(\n                    \"[MonitorCallback] unable to find filewriter, no logs were written,\"\n                )\n\n    def on_train_batch_end(self, batch, logs=None):\n        if self.on_batch:\n            self._monitor(batch)\n        super(MonitorCallback, self).on_train_batch_end(batch, logs)\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.epochs += 1\n        if self.on_epoch:\n            self._monitor(epoch)\n        super(MonitorCallback, self).on_epoch_end(epoch, logs)\n\n    def get_config(self):\n        config = {\n            \"on_epoch\": self.on_epoch,\n            \"on_batch\": self.on_batch,\n            \"monitored_layers\": self.monitored_layers,\n        }\n        base_config = super(MonitorCallback, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/callbacks/#deel.lip.callbacks.MonitorCallback.__init__","title":"<code>__init__(monitored_layers, logdir, target='kernel', what='max', on_epoch=True, on_batch=False)</code>","text":"<p>Allow to monitor the singular values of specified layers during training. This analyze the singular values of the original kernel (before reparametrization). Two modes can be chosen: \"max\" plots the largest singular value over training, while \"all\" plots the distribution of the singular values over training (series of distribution).</p> <p>Parameters:</p> Name Type Description Default <code>monitored_layers</code> <code>Iterable[str]</code> <p>list of layer name to monitor.</p> required <code>logdir</code> <code>str</code> <p>path to the logging directory.</p> required <code>target</code> <code>str</code> <p>describe what to monitor, can either \"kernel\" or \"wbar\". Setting to \"kernel\" check values of the unconstrained weights while setting to \"wbar\" check values of the constrained weights (allowing to check if the parameters are correct to ensure lipschitz constraint)</p> <code>'kernel'</code> <code>what</code> <code>str</code> <p>either \"max\", which display the largest singular value over the training process, or \"all\", which plot the distribution of all singular values.</p> <code>'max'</code> <code>on_epoch</code> <code>bool</code> <p>if True apply the constraint between epochs.</p> <code>True</code> <code>on_batch</code> <code>bool</code> <p>if True apply constraints between batches.</p> <code>False</code> Source code in <code>deel/lip/callbacks.py</code> <pre><code>def __init__(\n    self,\n    monitored_layers: Iterable[str],\n    logdir: str,\n    target: str = \"kernel\",\n    what: str = \"max\",\n    on_epoch: bool = True,\n    on_batch: bool = False,\n):\n\"\"\"\n    Allow to monitor the singular values of specified layers during training. This\n    analyze the singular values of the original kernel (before reparametrization).\n    Two modes can be chosen: \"max\" plots the largest singular value over training,\n    while \"all\" plots the distribution of the singular values over training (series\n    of distribution).\n\n    Args:\n        monitored_layers: list of layer name to monitor.\n        logdir: path to the logging directory.\n        target: describe what to monitor, can either \"kernel\" or \"wbar\". Setting\n            to \"kernel\" check values of the unconstrained weights while setting to\n            \"wbar\" check values of the constrained weights (allowing to check if\n            the parameters are correct to ensure lipschitz constraint)\n        what: either \"max\", which display the largest singular value over the\n            training process, or \"all\", which plot the distribution of all singular\n            values.\n        on_epoch: if True apply the constraint between epochs.\n        on_batch: if True apply constraints between batches.\n    \"\"\"\n    self.on_epoch = on_epoch\n    self.on_batch = on_batch\n    assert target in {\"kernel\", \"wbar\"}\n    self.target = target\n    assert what in {\"max\", \"all\"}\n    self.what = what\n    self.logdir = logdir\n    self.file_writer = tf.summary.create_file_writer(\n        os.path.join(logdir, \"metrics\")\n    )\n    self.monitored_layers = monitored_layers\n    if on_batch and on_epoch:\n        self.on_epoch = False  # avoid display bug (inconsistent steps)\n    self.epochs = 0\n    super().__init__()\n</code></pre>"},{"location":"api/constraints/","title":"deel.lip.constraints","text":"<p>This module contains extra constraint objects. These object can be added as params to regular layers.</p>"},{"location":"api/constraints/#deel.lip.constraints.AutoWeightClipConstraint","title":"<code>AutoWeightClipConstraint</code>","text":"<p>         Bases: <code>Constraint</code></p> Source code in <code>deel/lip/constraints.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"AutoWeightClipConstraint\")\nclass AutoWeightClipConstraint(Constraint):\n    def __init__(self, scale=1):\n\"\"\"\n        Clips the weights incident to each hidden unit to be inside the range `[-c,+c]`.\n        With c = 1/sqrt(size(kernel)).\n\n        Args:\n            scale (float): scaling factor to increase/decrease clipping value.\n        \"\"\"\n        self.scale = scale\n\n    def __call__(self, w):\n        c = 1 / (tf.sqrt(tf.cast(tf.size(w), dtype=w.dtype)) * self.scale)\n        return tf.clip_by_value(w, -c, c)\n\n    def get_config(self):\n        return {\"scale\": self.scale}\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.AutoWeightClipConstraint.__init__","title":"<code>__init__(scale=1)</code>","text":"<p>Clips the weights incident to each hidden unit to be inside the range <code>[-c,+c]</code>. With c = 1/sqrt(size(kernel)).</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scaling factor to increase/decrease clipping value.</p> <code>1</code> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(self, scale=1):\n\"\"\"\n    Clips the weights incident to each hidden unit to be inside the range `[-c,+c]`.\n    With c = 1/sqrt(size(kernel)).\n\n    Args:\n        scale (float): scaling factor to increase/decrease clipping value.\n    \"\"\"\n    self.scale = scale\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.FrobeniusConstraint","title":"<code>FrobeniusConstraint</code>","text":"<p>         Bases: <code>Constraint</code></p> Source code in <code>deel/lip/constraints.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"FrobeniusConstraint\")\nclass FrobeniusConstraint(Constraint):\n    # todo: duplicate of keras/constraints/UnitNorm ?\n\n    def __init__(self, eps=1e-7):\n\"\"\"\n        Constrain the weights by dividing the weight matrix by it's L2 norm.\n        \"\"\"\n        self.eps = eps\n\n    def __call__(self, w):\n        return w / (tf.sqrt(tf.reduce_sum(tf.square(w), keepdims=False)) + self.eps)\n\n    def get_config(self):\n        return {\"eps\": self.eps}\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.FrobeniusConstraint.__init__","title":"<code>__init__(eps=1e-07)</code>","text":"<p>Constrain the weights by dividing the weight matrix by it's L2 norm.</p> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(self, eps=1e-7):\n\"\"\"\n    Constrain the weights by dividing the weight matrix by it's L2 norm.\n    \"\"\"\n    self.eps = eps\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.SpectralConstraint","title":"<code>SpectralConstraint</code>","text":"<p>         Bases: <code>Constraint</code></p> Source code in <code>deel/lip/constraints.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"SpectralConstraint\")\nclass SpectralConstraint(Constraint):\n    def __init__(\n        self,\n        k_coef_lip=1.0,\n        eps_spectral=DEFAULT_EPS_SPECTRAL,\n        eps_bjorck=DEFAULT_EPS_BJORCK,\n        beta_bjorck=DEFAULT_BETA_BJORCK,\n        u=None,\n    ) -&gt; None:\n\"\"\"\n        Ensure that *all* singular values of the weight matrix equals to 1. Computation\n        based on Bjorck algorithm. The computation is done in two steps:\n\n        1. reduce the larget singular value to k_coef_lip, using iterate power method.\n        2. increase other singular values to k_coef_lip, using bjorck algorithm.\n\n        Args:\n            k_coef_lip (float): lipschitz coefficient of the weight matrix\n            eps_spectral (float): stopping criterion for the iterative power algorithm.\n            eps_bjorck (float): stopping criterion Bjorck algorithm.\n            beta_bjorck (float): beta parameter in bjorck algorithm.\n            u (tf.Tensor): vector used for iterated power method, can be set to None\n                (used for serialization/deserialization purposes).\n        \"\"\"\n        self.eps_spectral = eps_spectral\n        self.eps_bjorck = eps_bjorck\n        self.beta_bjorck = beta_bjorck\n        self.k_coef_lip = k_coef_lip\n        if not (isinstance(u, tf.Tensor) or (u is None)):\n            u = tf.convert_to_tensor(u)\n        self.u = u\n        super(SpectralConstraint, self).__init__()\n\n    def __call__(self, w):\n        wbar, u, sigma = reshaped_kernel_orthogonalization(\n            w,\n            self.u,\n            self.k_coef_lip,\n            self.eps_spectral,\n            self.eps_bjorck,\n            self.beta_bjorck,\n        )\n        return wbar\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n            \"eps_spectral\": self.eps_spectral,\n            \"eps_bjorck\": self.eps_bjorck,\n            \"beta_bjorck\": self.beta_bjorck,\n            \"u\": None if self.u is None else self.u.numpy(),\n        }\n        base_config = super(SpectralConstraint, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.SpectralConstraint.__init__","title":"<code>__init__(k_coef_lip=1.0, eps_spectral=DEFAULT_EPS_SPECTRAL, eps_bjorck=DEFAULT_EPS_BJORCK, beta_bjorck=DEFAULT_BETA_BJORCK, u=None)</code>","text":"<p>Ensure that all singular values of the weight matrix equals to 1. Computation based on Bjorck algorithm. The computation is done in two steps:</p> <ol> <li>reduce the larget singular value to k_coef_lip, using iterate power method.</li> <li>increase other singular values to k_coef_lip, using bjorck algorithm.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>k_coef_lip</code> <code>float</code> <p>lipschitz coefficient of the weight matrix</p> <code>1.0</code> <code>eps_spectral</code> <code>float</code> <p>stopping criterion for the iterative power algorithm.</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>eps_bjorck</code> <code>float</code> <p>stopping criterion Bjorck algorithm.</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta_bjorck</code> <code>float</code> <p>beta parameter in bjorck algorithm.</p> <code>DEFAULT_BETA_BJORCK</code> <code>u</code> <code>tf.Tensor</code> <p>vector used for iterated power method, can be set to None (used for serialization/deserialization purposes).</p> <code>None</code> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(\n    self,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    u=None,\n) -&gt; None:\n\"\"\"\n    Ensure that *all* singular values of the weight matrix equals to 1. Computation\n    based on Bjorck algorithm. The computation is done in two steps:\n\n    1. reduce the larget singular value to k_coef_lip, using iterate power method.\n    2. increase other singular values to k_coef_lip, using bjorck algorithm.\n\n    Args:\n        k_coef_lip (float): lipschitz coefficient of the weight matrix\n        eps_spectral (float): stopping criterion for the iterative power algorithm.\n        eps_bjorck (float): stopping criterion Bjorck algorithm.\n        beta_bjorck (float): beta parameter in bjorck algorithm.\n        u (tf.Tensor): vector used for iterated power method, can be set to None\n            (used for serialization/deserialization purposes).\n    \"\"\"\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.k_coef_lip = k_coef_lip\n    if not (isinstance(u, tf.Tensor) or (u is None)):\n        u = tf.convert_to_tensor(u)\n    self.u = u\n    super(SpectralConstraint, self).__init__()\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.WeightClipConstraint","title":"<code>WeightClipConstraint</code>","text":"<p>         Bases: <code>Constraint</code></p> Source code in <code>deel/lip/constraints.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"WeightClipConstraint\")\nclass WeightClipConstraint(Constraint):\n    def __init__(self, c=2):\n\"\"\"\n        Clips the weights incident to each hidden unit to be inside the range `[-c,+c]`.\n\n        Args:\n            c (float): clipping parameter.\n        \"\"\"\n        self.c = c\n\n    def __call__(self, p):\n        return K.clip(p, -self.c, self.c)\n\n    def get_config(self):\n        return {\"c\": self.c}\n</code></pre>"},{"location":"api/constraints/#deel.lip.constraints.WeightClipConstraint.__init__","title":"<code>__init__(c=2)</code>","text":"<p>Clips the weights incident to each hidden unit to be inside the range <code>[-c,+c]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>float</code> <p>clipping parameter.</p> <code>2</code> Source code in <code>deel/lip/constraints.py</code> <pre><code>def __init__(self, c=2):\n\"\"\"\n    Clips the weights incident to each hidden unit to be inside the range `[-c,+c]`.\n\n    Args:\n        c (float): clipping parameter.\n    \"\"\"\n    self.c = c\n</code></pre>"},{"location":"api/initializers/","title":"deel.lip.initializers","text":""},{"location":"api/initializers/#deel.lip.initializers.SpectralInitializer","title":"<code>SpectralInitializer</code>","text":"<p>         Bases: <code>Initializer</code></p> Source code in <code>deel/lip/initializers.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"SpectralInitializer\")\nclass SpectralInitializer(Initializer):\n    def __init__(\n        self,\n        eps_spectral=DEFAULT_EPS_SPECTRAL,\n        eps_bjorck=DEFAULT_EPS_BJORCK,\n        beta_bjorck=DEFAULT_BETA_BJORCK,\n        k_coef_lip=1.0,\n        base_initializer=\"orthogonal\",\n    ) -&gt; None:\n\"\"\"\n        Initialize a kernel to be 1-lipschitz orthogonal using bjorck\n        normalization.\n\n        Args:\n            eps_spectral (float): stopping criterion of iterative power method\n            eps_bjorck (float): float greater than 0, stopping criterion of\n                bjorck algorithm, setting it to None disable orthogonalization\n            beta_bjorck (float): beta parameter of bjorck algorithm\n            base_initializer (str): method used to generate weights before applying the\n                orthonormalization\n        \"\"\"\n        self.eps_spectral = eps_spectral\n        self.eps_bjorck = eps_bjorck\n        self.beta_bjorck = beta_bjorck\n        self.k_coef_lip = k_coef_lip\n        self.base_initializer = initializers.get(base_initializer)\n        super(SpectralInitializer, self).__init__()\n\n    def __call__(self, shape, dtype=None, partition_info=None):\n        w = self.base_initializer(shape=shape, dtype=dtype)\n        wbar, u, sigma = reshaped_kernel_orthogonalization(\n            w,\n            None,\n            self.k_coef_lip,\n            self.eps_spectral,\n            self.eps_bjorck,\n            self.beta_bjorck,\n        )\n        return wbar\n\n    def get_config(self):\n        return {\n            \"eps_spectral\": self.eps_spectral,\n            \"eps_bjorck\": self.eps_bjorck,\n            \"beta_bjorck\": self.beta_bjorck,\n            \"k_coef_lip\": self.k_coef_lip,\n            \"base_initializer\": initializers.serialize(self.base_initializer),\n        }\n</code></pre>"},{"location":"api/initializers/#deel.lip.initializers.SpectralInitializer.__init__","title":"<code>__init__(eps_spectral=DEFAULT_EPS_SPECTRAL, eps_bjorck=DEFAULT_EPS_BJORCK, beta_bjorck=DEFAULT_BETA_BJORCK, k_coef_lip=1.0, base_initializer='orthogonal')</code>","text":"<p>Initialize a kernel to be 1-lipschitz orthogonal using bjorck normalization.</p> <p>Parameters:</p> Name Type Description Default <code>eps_spectral</code> <code>float</code> <p>stopping criterion of iterative power method</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>eps_bjorck</code> <code>float</code> <p>float greater than 0, stopping criterion of bjorck algorithm, setting it to None disable orthogonalization</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta_bjorck</code> <code>float</code> <p>beta parameter of bjorck algorithm</p> <code>DEFAULT_BETA_BJORCK</code> <code>base_initializer</code> <code>str</code> <p>method used to generate weights before applying the orthonormalization</p> <code>'orthogonal'</code> Source code in <code>deel/lip/initializers.py</code> <pre><code>def __init__(\n    self,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    k_coef_lip=1.0,\n    base_initializer=\"orthogonal\",\n) -&gt; None:\n\"\"\"\n    Initialize a kernel to be 1-lipschitz orthogonal using bjorck\n    normalization.\n\n    Args:\n        eps_spectral (float): stopping criterion of iterative power method\n        eps_bjorck (float): float greater than 0, stopping criterion of\n            bjorck algorithm, setting it to None disable orthogonalization\n        beta_bjorck (float): beta parameter of bjorck algorithm\n        base_initializer (str): method used to generate weights before applying the\n            orthonormalization\n    \"\"\"\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.k_coef_lip = k_coef_lip\n    self.base_initializer = initializers.get(base_initializer)\n    super(SpectralInitializer, self).__init__()\n</code></pre>"},{"location":"api/layers/","title":"deel.lip.layers","text":""},{"location":"api/layers/#deel.lip.layers.activations","title":"<code>activations</code>","text":"<p>This module contains extra activation functions which respect the Lipschitz constant. It can be added as a layer, or it can be used in the \"activation\" params for other layers.</p>"},{"location":"api/layers/#deel.lip.layers.activations.FullSort","title":"<code>FullSort</code>","text":"<p>         Bases: <code>GroupSort</code></p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"FullSort\")\nclass FullSort(GroupSort):\n    def __init__(self, **kwargs):\n\"\"\"\n        FullSort activation. Special case of GroupSort where the entire input is sorted.\n\n        Input shape:\n            Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n            not include the samples axis) when using this layer as the first layer in a\n            model.\n\n        Output shape:\n            Same size as input.\n\n        \"\"\"\n        kwargs[\"n\"] = None\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.FullSort.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>FullSort activation. Special case of GroupSort where the entire input is sorted.</p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, **kwargs):\n\"\"\"\n    FullSort activation. Special case of GroupSort where the entire input is sorted.\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    kwargs[\"n\"] = None\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.GroupSort","title":"<code>GroupSort</code>","text":"<p>         Bases: <code>Layer</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"GroupSort\")\nclass GroupSort(Layer, LipschitzLayer):\n    def __init__(\n        self, n=None, data_format=\"channels_last\", k_coef_lip=1.0, *args, **kwargs\n    ):\n\"\"\"\n        GroupSort activation\n\n        Args:\n            n (int): group size used when sorting. When None group size is set to input\n                size (fullSort behavior)\n            data_format (str): either channels_first or channels_last\n            k_coef_lip (float): the lipschitz coefficient to be enforced\n            *args: params passed to Layers\n            **kwargs: params passed to layers (named fashion)\n\n        Input shape:\n            Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n            not include the samples axis) when using this layer as the first layer in a\n            model.\n\n        Output shape:\n            Same size as input.\n\n        \"\"\"\n        self.set_klip_factor(k_coef_lip)\n        super(GroupSort, self).__init__(*args, **kwargs)\n        if data_format == \"channels_last\":\n            self.channel_axis = -1\n        elif data_format == \"channels_first\":\n            raise RuntimeError(\n                \"channels_first not implemented for GroupSort activation\"\n            )\n            self.channel_axis = 1\n        else:\n            raise RuntimeError(\"data format not understood\")\n        self.n = n\n        self.data_format = data_format\n\n    def build(self, input_shape):\n        input_shape = tf.TensorShape(input_shape)\n        super(GroupSort, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        if (self.n is None) or (self.n &gt; input_shape[self.channel_axis]):\n            self.n = input_shape[self.channel_axis]\n        if (input_shape[self.channel_axis] % self.n) != 0:\n            raise RuntimeError(\"self.n has to be a divisor of the number of channels\")\n        input_shape = tuple(input_shape.as_list())\n        self.flat_shape = (\n            (-1,) + input_shape[1:-1] + (input_shape[-1] // self.n, self.n)\n        )\n        self.out_shape = (-1,) + input_shape[1:]\n\n    def _compute_lip_coef(self, input_shape=None):\n        return 1.0\n\n    @tf.function\n    def call(self, x, **kwargs):\n        fv = tf.reshape(x, self.flat_shape)\n        if self.n == 2:\n            b, c = tf.split(fv, 2, -1)\n            newv = tf.concat([tf.minimum(b, c), tf.maximum(b, c)], axis=-1)\n            newv = tf.reshape(newv, self.out_shape)\n            return newv * self._get_coef()\n\n        newv = tf.sort(fv)\n        newv = tf.reshape(newv, self.out_shape)\n        return newv * self._get_coef()\n\n    def get_config(self):\n        config = {\n            \"n\": self.n,\n            \"k_coef_lip\": self.k_coef_lip,\n            \"data_format\": self.data_format,\n        }\n        base_config = super(GroupSort, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.GroupSort.__init__","title":"<code>__init__(n=None, data_format='channels_last', k_coef_lip=1.0, *args, **kwargs)</code>","text":"<p>GroupSort activation</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>group size used when sorting. When None group size is set to input size (fullSort behavior)</p> <code>None</code> <code>data_format</code> <code>str</code> <p>either channels_first or channels_last</p> <code>'channels_last'</code> <code>k_coef_lip</code> <code>float</code> <p>the lipschitz coefficient to be enforced</p> <code>1.0</code> <code>*args</code> <p>params passed to Layers</p> <code>()</code> <code>**kwargs</code> <p>params passed to layers (named fashion)</p> <code>{}</code> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(\n    self, n=None, data_format=\"channels_last\", k_coef_lip=1.0, *args, **kwargs\n):\n\"\"\"\n    GroupSort activation\n\n    Args:\n        n (int): group size used when sorting. When None group size is set to input\n            size (fullSort behavior)\n        data_format (str): either channels_first or channels_last\n        k_coef_lip (float): the lipschitz coefficient to be enforced\n        *args: params passed to Layers\n        **kwargs: params passed to layers (named fashion)\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    self.set_klip_factor(k_coef_lip)\n    super(GroupSort, self).__init__(*args, **kwargs)\n    if data_format == \"channels_last\":\n        self.channel_axis = -1\n    elif data_format == \"channels_first\":\n        raise RuntimeError(\n            \"channels_first not implemented for GroupSort activation\"\n        )\n        self.channel_axis = 1\n    else:\n        raise RuntimeError(\"data format not understood\")\n    self.n = n\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.GroupSort2","title":"<code>GroupSort2</code>","text":"<p>         Bases: <code>GroupSort</code></p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"GroupSort2\")\nclass GroupSort2(GroupSort):\n    def __init__(self, **kwargs):\n\"\"\"\n        GroupSort2 activation. Special case of GroupSort with group of size 2.\n\n        Input shape:\n            Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n            not include the samples axis) when using this layer as the first layer in a\n            model.\n\n        Output shape:\n            Same size as input.\n\n        \"\"\"\n        kwargs[\"n\"] = 2\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.GroupSort2.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>GroupSort2 activation. Special case of GroupSort with group of size 2.</p> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, **kwargs):\n\"\"\"\n    GroupSort2 activation. Special case of GroupSort with group of size 2.\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    kwargs[\"n\"] = 2\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.Householder","title":"<code>Householder</code>","text":"<p>         Bases: <code>Layer</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"Householder\")\nclass Householder(Layer, LipschitzLayer):\n    def __init__(\n        self,\n        data_format=\"channels_last\",\n        k_coef_lip=1.0,\n        theta_initializer=None,\n        **kwargs,\n    ):\n\"\"\"\n        Householder activation:\n        [this review](https://openreview.net/pdf?id=tD7eCtaSkR)\n        From [this repository](https://github.com/singlasahil14/SOC)\n\n        Args:\n            data_format (str): either channels_first or channels_last. Only\n                channels_last is supported.\n            k_coef_lip (str): The lipschitz coefficient to be enforced.\n            theta_initializer: initializer for the angle theta of reflection. Defaults\n                to pi/2, which corresponds to GroupSort2.\n            **kwargs: parameters passed to the `tf.keras.layers.Layer`.\n\n        Input shape:\n            Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n            not include the samples axis) when using this layer as the first layer in a\n            model.\n\n        Output shape:\n            Same size as input.\n\n        \"\"\"\n        if data_format != \"channels_last\":\n            raise RuntimeError(\"Only 'channels_last' data format is supported\")\n\n        self.data_format = data_format\n        self.set_klip_factor(k_coef_lip)\n        self.theta_initializer = theta_initializer\n        super().__init__(**kwargs)\n\n    def build(self, input_shape):\n        super().build(input_shape)\n        self._init_lip_coef(input_shape)\n        if (input_shape[-1] % 2) != 0:\n            raise RuntimeError(\"2 has to be a divisor of the number of channels\")\n\n        self.theta = self.add_weight(\n            \"theta\",\n            shape=[input_shape[-1] // 2],\n            initializer=self.theta_initializer,\n        )\n        if self.theta_initializer is None:\n            self.theta.assign(tf.ones_like(self.theta, dtype=tf.float32) * math.pi / 2)\n\n    def _compute_lip_coef(self, input_shape=None):\n        return 1.0\n\n    def call(self, x):\n        z1, z2 = tf.split(x, 2, axis=-1)\n\n        # selector &gt; 0 if point (z1, z2) is on one side of reflection line, else &lt; 0.\n        # Reflection line is defined by angle theta/2.\n        selector = (z1 * tf.sin(0.5 * self.theta)) - (z2 * tf.cos(0.5 * self.theta))\n\n        cos_theta = tf.cos(self.theta)\n        sin_theta = tf.sin(self.theta)\n        reflected_z1 = z1 * cos_theta + z2 * sin_theta\n        reflected_z2 = z1 * sin_theta - z2 * cos_theta\n\n        a = tf.where(selector &lt;= 0, z1, reflected_z1)\n        b = tf.where(selector &lt;= 0, z2, reflected_z2)\n\n        return tf.concat([a, b], axis=-1)\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n            \"data_format\": self.data_format,\n            \"theta_initializer\": self.theta_initializer,\n        }\n        base_config = super().get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.Householder.__init__","title":"<code>__init__(data_format='channels_last', k_coef_lip=1.0, theta_initializer=None, **kwargs)</code>","text":"<p>Householder activation: this review From this repository</p> <p>Parameters:</p> Name Type Description Default <code>data_format</code> <code>str</code> <p>either channels_first or channels_last. Only channels_last is supported.</p> <code>'channels_last'</code> <code>k_coef_lip</code> <code>str</code> <p>The lipschitz coefficient to be enforced.</p> <code>1.0</code> <code>theta_initializer</code> <p>initializer for the angle theta of reflection. Defaults to pi/2, which corresponds to GroupSort2.</p> <code>None</code> <code>**kwargs</code> <p>parameters passed to the <code>tf.keras.layers.Layer</code>.</p> <code>{}</code> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Same size as input.</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(\n    self,\n    data_format=\"channels_last\",\n    k_coef_lip=1.0,\n    theta_initializer=None,\n    **kwargs,\n):\n\"\"\"\n    Householder activation:\n    [this review](https://openreview.net/pdf?id=tD7eCtaSkR)\n    From [this repository](https://github.com/singlasahil14/SOC)\n\n    Args:\n        data_format (str): either channels_first or channels_last. Only\n            channels_last is supported.\n        k_coef_lip (str): The lipschitz coefficient to be enforced.\n        theta_initializer: initializer for the angle theta of reflection. Defaults\n            to pi/2, which corresponds to GroupSort2.\n        **kwargs: parameters passed to the `tf.keras.layers.Layer`.\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Same size as input.\n\n    \"\"\"\n    if data_format != \"channels_last\":\n        raise RuntimeError(\"Only 'channels_last' data format is supported\")\n\n    self.data_format = data_format\n    self.set_klip_factor(k_coef_lip)\n    self.theta_initializer = theta_initializer\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.MaxMin","title":"<code>MaxMin</code>","text":"<p>         Bases: <code>Layer</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"MaxMin\")\nclass MaxMin(Layer, LipschitzLayer):\n    def __init__(self, data_format=\"channels_last\", k_coef_lip=1.0, *args, **kwargs):\n\"\"\"\n        MaxMin activation [Relu(x),reLU(-x)]\n\n        Args:\n            data_format (str): either channels_first or channels_last\n            k_coef_lip (float): the lipschitz coefficient to be enforced\n            *args: params passed to Layers\n            **kwargs: params passed to layers (named fashion)\n\n        Input shape:\n            Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n            not include the samples axis) when using this layer as the first layer in a\n            model.\n\n        Output shape:\n            Double channel size as input.\n\n        References:\n            ([M. Blot, M. Cord, et N. Thome, \u00ab\u00a0Max-min convolutional neural networks\n            for image classification\u00a0\u00bb, in 2016 IEEE International Conference on Image\n            Processing (ICIP), Phoenix, AZ, USA, 2016, p. 3678\u20113682.)\n\n        \"\"\"\n        self.set_klip_factor(k_coef_lip)\n        super(MaxMin, self).__init__(*args, **kwargs)\n        if data_format == \"channels_last\":\n            self.channel_axis = -1\n        elif data_format == \"channels_first\":\n            self.channel_axis = 1\n        else:\n            raise RuntimeError(\"data format not understood\")\n        self.data_format = data_format\n\n    def build(self, input_shape):\n        self._init_lip_coef(input_shape)\n        return super().build(input_shape)\n\n    def _compute_lip_coef(self, input_shape=None):\n        return 1.0\n\n    def call(self, x, **kwargs):\n        return (\n            K.concatenate(\n                (K.relu(x, alpha=0), K.relu(-x, alpha=0)), axis=self.channel_axis\n            )\n            * self._get_coef()\n        )\n\n    def get_config(self):\n        config = {\n            \"data_format\": self.data_format,\n            \"k_coef_lip\": self.k_coef_lip,\n        }\n        base_config = super(MaxMin, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        new_shape = input_shape\n        new_shape[self.channel_axis] = 2 * new_shape[self.channel_axis]\n        return new_shape\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.MaxMin.__init__","title":"<code>__init__(data_format='channels_last', k_coef_lip=1.0, *args, **kwargs)</code>","text":"<p>MaxMin activation [Relu(x),reLU(-x)]</p> <p>Parameters:</p> Name Type Description Default <code>data_format</code> <code>str</code> <p>either channels_first or channels_last</p> <code>'channels_last'</code> <code>k_coef_lip</code> <code>float</code> <p>the lipschitz coefficient to be enforced</p> <code>1.0</code> <code>*args</code> <p>params passed to Layers</p> <code>()</code> <code>**kwargs</code> <p>params passed to layers (named fashion)</p> <code>{}</code> Input shape <p>Arbitrary. Use the keyword argument <code>input_shape</code> (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.</p> Output shape <p>Double channel size as input.</p> References <p>([M. Blot, M. Cord, et N. Thome, \u00ab\u00a0Max-min convolutional neural networks for image classification\u00a0\u00bb, in 2016 IEEE International Conference on Image Processing (ICIP), Phoenix, AZ, USA, 2016, p. 3678\u20113682.)</p> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>def __init__(self, data_format=\"channels_last\", k_coef_lip=1.0, *args, **kwargs):\n\"\"\"\n    MaxMin activation [Relu(x),reLU(-x)]\n\n    Args:\n        data_format (str): either channels_first or channels_last\n        k_coef_lip (float): the lipschitz coefficient to be enforced\n        *args: params passed to Layers\n        **kwargs: params passed to layers (named fashion)\n\n    Input shape:\n        Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does\n        not include the samples axis) when using this layer as the first layer in a\n        model.\n\n    Output shape:\n        Double channel size as input.\n\n    References:\n        ([M. Blot, M. Cord, et N. Thome, \u00ab\u00a0Max-min convolutional neural networks\n        for image classification\u00a0\u00bb, in 2016 IEEE International Conference on Image\n        Processing (ICIP), Phoenix, AZ, USA, 2016, p. 3678\u20113682.)\n\n    \"\"\"\n    self.set_klip_factor(k_coef_lip)\n    super(MaxMin, self).__init__(*args, **kwargs)\n    if data_format == \"channels_last\":\n        self.channel_axis = -1\n    elif data_format == \"channels_first\":\n        self.channel_axis = 1\n    else:\n        raise RuntimeError(\"data format not understood\")\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.activations.PReLUlip","title":"<code>PReLUlip(k_coef_lip=1.0)</code>","text":"<p>PreLu activation, with Lipschitz constraint.</p> <p>Parameters:</p> Name Type Description Default <code>k_coef_lip</code> <code>float</code> <p>lipschitz coefficient to be enforced</p> <code>1.0</code> Source code in <code>deel/lip/layers/activations.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"PReLUlip\")\ndef PReLUlip(k_coef_lip=1.0):\n\"\"\"\n    PreLu activation, with Lipschitz constraint.\n\n    Args:\n        k_coef_lip (float): lipschitz coefficient to be enforced\n    \"\"\"\n    return PReLU(\n        alpha_constraint=MinMaxNorm(min_value=-k_coef_lip, max_value=k_coef_lip)\n    )\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer","title":"<code>base_layer</code>","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.Condensable","title":"<code>Condensable</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>Some Layers don't optimize directly the kernel, this means that the kernel stored in the layer is not the kernel used to make predictions (called W_bar), To address this, these layers can implement the condense() function that make self.kernel equal to W_bar. This operation also allows to turn the Lipschitz layer to its keras equivalent e.g. The Dense layer that have the same predictions as the trained SpectralDense.</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>class Condensable(abc.ABC):\n\"\"\"\n    Some Layers don't optimize directly the kernel, this means that the kernel stored\n    in the layer is not the kernel used to make predictions (called W_bar), To address\n    this, these layers can implement the condense() function that make self.kernel equal\n    to W_bar.\n    This operation also allows to turn the Lipschitz layer to its keras equivalent e.g.\n    The Dense layer that have the same predictions as the trained SpectralDense.\n    \"\"\"\n\n    @abc.abstractmethod\n    def condense(self):\n\"\"\"\n        The condense operation allows to overwrite the kernel and ensure that other\n        variables are still consistent.\n        Returns:\n            None\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def vanilla_export(self):\n\"\"\"\n        This operation allows to turn this Layer to its super type, easing storage and\n        serving.\n        Returns:\n             self as super type\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer.Condensable.condense","title":"<code>condense()</code>  <code>abstractmethod</code>","text":"<p>The condense operation allows to overwrite the kernel and ensure that other variables are still consistent.</p> <p>Returns:</p> Type Description <p>None</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>@abc.abstractmethod\ndef condense(self):\n\"\"\"\n    The condense operation allows to overwrite the kernel and ensure that other\n    variables are still consistent.\n    Returns:\n        None\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer.Condensable.vanilla_export","title":"<code>vanilla_export()</code>  <code>abstractmethod</code>","text":"<p>This operation allows to turn this Layer to its super type, easing storage and serving.</p> <p>Returns:</p> Type Description <p>self as super type</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>@abc.abstractmethod\ndef vanilla_export(self):\n\"\"\"\n    This operation allows to turn this Layer to its super type, easing storage and\n    serving.\n    Returns:\n         self as super type\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer","title":"<code>LipschitzLayer</code>","text":"<p>         Bases: <code>abc.ABC</code></p> <p>This class allows to set Lipschitz factor of a layer. Lipschitz layer must inherit this class to allow user to set the Lipschitz factor.</p> Warning <p>This class only regroups useful functions when developing new Lipschitz layers. But it does not ensure any property about the layer. This means that inheriting from this class won't ensure anything about the Lipschitz constant.</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>class LipschitzLayer(abc.ABC):\n\"\"\"\n    This class allows to set Lipschitz factor of a layer. Lipschitz layer must inherit\n    this class to allow user to set the Lipschitz factor.\n    Warning:\n         This class only regroups useful functions when developing new Lipschitz layers.\n         But it does not ensure any property about the layer. This means that\n         inheriting from this class won't ensure anything about the Lipschitz constant.\n    \"\"\"\n\n    k_coef_lip = 1.0\n\"\"\"variable used to store the lipschitz factor\"\"\"\n    coef_lip = None\n\"\"\"\n    define correction coefficient (ie. Lipschitz bound ) of the layer\n    ( multiply the output of the layer by this constant )\n    \"\"\"\n\n    def set_klip_factor(self, klip_factor):\n\"\"\"\n        Allow to set the Lipschitz factor of a layer.\n        Args:\n            klip_factor (float): the Lipschitz factor the user want to ensure.\n        Returns:\n            None\n        \"\"\"\n        self.k_coef_lip = klip_factor\n\n    @abc.abstractmethod\n    def _compute_lip_coef(self, input_shape=None):\n\"\"\"\n        Some layers (like convolution) cannot ensure a strict Lipschitz constant (as\n        the Lipschitz factor depends on the input data). Those layers then rely on the\n        computation of a bounding factor. This function allows to compute this factor.\n        Args:\n            input_shape: the shape of the input of the layer.\n        Returns:\n            the bounding factor.\n        \"\"\"\n        pass\n\n    def _init_lip_coef(self, input_shape):\n\"\"\"\n        Initialize the Lipschitz coefficient of a layer.\n        Args:\n            input_shape: the layers input shape\n        Returns:\n            None\n        \"\"\"\n        self.coef_lip = self._compute_lip_coef(input_shape)\n\n    def _get_coef(self):\n\"\"\"\n        Returns:\n            the multiplicative coefficient to be used on the result in order to ensure\n            k-Lipschitzity.\n        \"\"\"\n        if self.coef_lip is None:\n            raise RuntimeError(\"compute_coef must be called before calling get_coef\")\n        return self.coef_lip * self.k_coef_lip\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer.coef_lip","title":"<code>coef_lip = None</code>  <code>class-attribute</code>","text":"<p>define correction coefficient (ie. Lipschitz bound ) of the layer ( multiply the output of the layer by this constant )</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer.k_coef_lip","title":"<code>k_coef_lip = 1.0</code>  <code>class-attribute</code>","text":"<p>variable used to store the lipschitz factor</p>"},{"location":"api/layers/#deel.lip.layers.base_layer.LipschitzLayer.set_klip_factor","title":"<code>set_klip_factor(klip_factor)</code>","text":"<p>Allow to set the Lipschitz factor of a layer.</p> <p>Parameters:</p> Name Type Description Default <code>klip_factor</code> <code>float</code> <p>the Lipschitz factor the user want to ensure.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>deel/lip/layers/base_layer.py</code> <pre><code>def set_klip_factor(self, klip_factor):\n\"\"\"\n    Allow to set the Lipschitz factor of a layer.\n    Args:\n        klip_factor (float): the Lipschitz factor the user want to ensure.\n    Returns:\n        None\n    \"\"\"\n    self.k_coef_lip = klip_factor\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional","title":"<code>convolutional</code>","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.convolutional.FrobeniusConv2D","title":"<code>FrobeniusConv2D</code>","text":"<p>         Bases: <code>Conv2D</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>Same as SpectralConv2D but in the case of a single output.</p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"FrobeniusConv2D\")\nclass FrobeniusConv2D(Conv2D, LipschitzLayer, Condensable):\n\"\"\"\n    Same as SpectralConv2D but in the case of a single output.\n    \"\"\"\n\n    def __init__(\n        self,\n        filters,\n        kernel_size,\n        strides=(1, 1),\n        padding=\"same\",\n        data_format=None,\n        dilation_rate=(1, 1),\n        activation=None,\n        use_bias=True,\n        kernel_initializer=SpectralInitializer(),\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        bias_constraint=None,\n        k_coef_lip=1.0,\n        **kwargs\n    ):\n        if not ((strides == (1, 1)) or (strides == [1, 1]) or (strides == 1)):\n            raise RuntimeError(\"FrobeniusConv2D does not support strides\")\n        if not (\n            (dilation_rate == (1, 1))\n            or (dilation_rate == [1, 1])\n            or (dilation_rate == 1)\n        ):\n            raise RuntimeError(\"FrobeniusConv2D does not support dilation rate\")\n        if padding != \"same\":\n            raise RuntimeError(\"FrobeniusConv2D only supports padding='same'\")\n        if not (\n            (kernel_constraint is None)\n            or isinstance(kernel_constraint, SpectralConstraint)\n        ):\n            raise RuntimeError(\n                \"only deellip constraints are allowed as other constraints could break\"\n                \" 1 lipschitz condition\"\n            )\n        super(FrobeniusConv2D, self).__init__(\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs\n        )\n        self.set_klip_factor(k_coef_lip)\n        self.wbar = None\n        self._kwargs = kwargs\n\n    def build(self, input_shape):\n        super(FrobeniusConv2D, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.wbar = tf.Variable(self.kernel.read_value(), trainable=False)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return _compute_conv_lip_factor(\n            self.kernel_size, self.strides, input_shape, self.data_format\n        )\n\n    def call(self, x, training=True):\n        if training:\n            wbar = (self.kernel / tf.norm(self.kernel)) * self._get_coef()\n            self.wbar.assign(wbar)\n        else:\n            wbar = self.wbar\n        outputs = K.conv2d(\n            x,\n            wbar,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate,\n        )\n        if self.use_bias:\n            outputs = K.bias_add(outputs, self.bias, data_format=self.data_format)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n        }\n        base_config = super(FrobeniusConv2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def condense(self):\n        wbar = self.kernel / tf.norm(self.kernel) * self._get_coef()\n        self.kernel.assign(wbar)\n\n    def vanilla_export(self):\n        self._kwargs[\"name\"] = self.name\n        # call the condense function from SpectralDense as if it was from this class\n        return SpectralConv2D.vanilla_export(self)\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional.SpectralConv2D","title":"<code>SpectralConv2D</code>","text":"<p>         Bases: <code>Conv2D</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"SpectralConv2D\")\nclass SpectralConv2D(Conv2D, LipschitzLayer, Condensable):\n    def __init__(\n        self,\n        filters,\n        kernel_size,\n        strides=(1, 1),\n        padding=\"same\",\n        data_format=None,\n        dilation_rate=(1, 1),\n        activation=None,\n        use_bias=True,\n        kernel_initializer=SpectralInitializer(),\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        bias_constraint=None,\n        k_coef_lip=1.0,\n        eps_spectral=DEFAULT_EPS_SPECTRAL,\n        eps_bjorck=DEFAULT_EPS_BJORCK,\n        beta_bjorck=DEFAULT_BETA_BJORCK,\n        maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n        maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n        **kwargs\n    ):\n\"\"\"\n        This class is a Conv2D Layer constrained such that all singular of it's kernel\n        are 1. The computation based on Bjorck algorithm. As this is not\n        enough to ensure 1 Lipschitzity a coertive coefficient is applied on the\n        output.\n        The computation is done in three steps:\n\n        1. reduce the largest singular value to 1, using iterated power method.\n        2. increase other singular values to 1, using Bjorck algorithm.\n        3. divide the output by the Lipschitz bound to ensure k Lipschitzity.\n\n        Args:\n            filters: Integer, the dimensionality of the output space\n                (i.e. the number of output filters in the convolution).\n            kernel_size: An integer or tuple/list of 2 integers, specifying the\n                height and width of the 2D convolution window.\n                Can be a single integer to specify the same value for\n                all spatial dimensions.\n            strides: An integer or tuple/list of 2 integers,\n                specifying the strides of the convolution along the height and width.\n                Can be a single integer to specify the same value for\n                all spatial dimensions.\n                Specifying any stride value != 1 is incompatible with specifying\n                any `dilation_rate` value != 1.\n            padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n            data_format: A string,\n                one of `channels_last` (default) or `channels_first`.\n                The ordering of the dimensions in the inputs.\n                `channels_last` corresponds to inputs with shape\n                `(batch, height, width, channels)` while `channels_first`\n                corresponds to inputs with shape\n                `(batch, channels, height, width)`.\n                It defaults to the `image_data_format` value found in your\n                Keras config file at `~/.keras/keras.json`.\n                If you never set it, then it will be \"channels_last\".\n            dilation_rate: an integer or tuple/list of 2 integers, specifying\n                the dilation rate to use for dilated convolution.\n                Can be a single integer to specify the same value for\n                all spatial dimensions.\n                Currently, specifying any `dilation_rate` value != 1 is\n                incompatible with specifying any stride value != 1.\n            activation: Activation function to use.\n                If you don't specify anything, no activation is applied\n                (ie. \"linear\" activation: `a(x) = x`).\n            use_bias: Boolean, whether the layer uses a bias vector.\n            kernel_initializer: Initializer for the `kernel` weights matrix.\n            bias_initializer: Initializer for the bias vector.\n            kernel_regularizer: Regularizer function applied to\n                the `kernel` weights matrix.\n            bias_regularizer: Regularizer function applied to the bias vector.\n            activity_regularizer: Regularizer function applied to\n                the output of the layer (its \"activation\")..\n            kernel_constraint: Constraint function applied to the kernel matrix.\n            bias_constraint: Constraint function applied to the bias vector.\n            k_coef_lip: lipschitz constant to ensure\n            eps_spectral: stopping criterion for the iterative power algorithm.\n            eps_bjorck: stopping criterion Bjorck algorithm.\n            beta_bjorck: beta parameter in bjorck algorithm.\n            maxiter_spectral: maximum number of iterations for the power iteration.\n            maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n\n        This documentation reuse the body of the original keras.layers.Conv2D doc.\n        \"\"\"\n        if not (\n            (dilation_rate == (1, 1))\n            or (dilation_rate == [1, 1])\n            or (dilation_rate == 1)\n        ):\n            raise RuntimeError(\"SpectralConv2D does not support dilation rate\")\n        if padding != \"same\":\n            raise RuntimeError(\"SpectralConv2D only supports padding='same'\")\n        super(SpectralConv2D, self).__init__(\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs\n        )\n        self._kwargs = kwargs\n        self.set_klip_factor(k_coef_lip)\n        self.u = None\n        self.sig = None\n        self.wbar = None\n        _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n        self.eps_spectral = eps_spectral\n        self.eps_bjorck = eps_bjorck\n        self.beta_bjorck = beta_bjorck\n        self.maxiter_bjorck = maxiter_bjorck\n        self.maxiter_spectral = maxiter_spectral\n\n    def build(self, input_shape):\n        super(SpectralConv2D, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.u = self.add_weight(\n            shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n            initializer=RandomNormal(0, 1),\n            name=\"sn\",\n            trainable=False,\n            dtype=self.dtype,\n        )\n\n        self.sig = self.add_weight(\n            shape=tuple([1, 1]),  # maximum spectral  value\n            name=\"sigma\",\n            trainable=False,\n            dtype=self.dtype,\n        )\n        self.sig.assign([[1.0]])\n        self.wbar = tf.Variable(self.kernel.read_value(), trainable=False)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return _compute_conv_lip_factor(\n            self.kernel_size, self.strides, input_shape, self.data_format\n        )\n\n    def call(self, x, training=True):\n        if training:\n            wbar, u, sigma = reshaped_kernel_orthogonalization(\n                self.kernel,\n                self.u,\n                self._get_coef(),\n                self.eps_spectral,\n                self.eps_bjorck,\n                self.beta_bjorck,\n                self.maxiter_spectral,\n                self.maxiter_bjorck,\n            )\n            self.wbar.assign(wbar)\n            self.u.assign(u)\n            self.sig.assign(sigma)\n        else:\n            wbar = self.wbar\n        outputs = K.conv2d(\n            x,\n            wbar,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate,\n        )\n        if self.use_bias:\n            outputs = K.bias_add(outputs, self.bias, data_format=self.data_format)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n            \"eps_spectral\": self.eps_spectral,\n            \"eps_bjorck\": self.eps_bjorck,\n            \"beta_bjorck\": self.beta_bjorck,\n            \"maxiter_spectral\": self.maxiter_spectral,\n            \"maxiter_bjorck\": self.maxiter_bjorck,\n        }\n        base_config = super(SpectralConv2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def condense(self):\n        wbar, u, sigma = reshaped_kernel_orthogonalization(\n            self.kernel,\n            self.u,\n            self._get_coef(),\n            self.eps_spectral,\n            self.eps_bjorck,\n            self.beta_bjorck,\n            self.maxiter_spectral,\n            self.maxiter_bjorck,\n        )\n        self.kernel.assign(wbar)\n        self.u.assign(u)\n        self.sig.assign(sigma)\n\n    def vanilla_export(self):\n        self._kwargs[\"name\"] = self.name\n        layer = Conv2D(\n            filters=self.filters,\n            kernel_size=self.kernel_size,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate,\n            activation=self.activation,\n            use_bias=self.use_bias,\n            kernel_initializer=\"glorot_uniform\",\n            bias_initializer=\"zeros\",\n            **self._kwargs\n        )\n        layer.build(self.input_shape)\n        layer.kernel.assign(self.wbar)\n        if self.use_bias:\n            layer.bias.assign(self.bias)\n        return layer\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional.SpectralConv2D.__init__","title":"<code>__init__(filters, kernel_size, strides=(1, 1), padding='same', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer=SpectralInitializer(), bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, k_coef_lip=1.0, eps_spectral=DEFAULT_EPS_SPECTRAL, eps_bjorck=DEFAULT_EPS_BJORCK, beta_bjorck=DEFAULT_BETA_BJORCK, maxiter_spectral=DEFAULT_MAXITER_SPECTRAL, maxiter_bjorck=DEFAULT_MAXITER_BJORCK, **kwargs)</code>","text":"<p>This class is a Conv2D Layer constrained such that all singular of it's kernel are 1. The computation based on Bjorck algorithm. As this is not enough to ensure 1 Lipschitzity a coertive coefficient is applied on the output. The computation is done in three steps:</p> <ol> <li>reduce the largest singular value to 1, using iterated power method.</li> <li>increase other singular values to 1, using Bjorck algorithm.</li> <li>divide the output by the Lipschitz bound to ensure k Lipschitzity.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>filters</code> <p>Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).</p> required <code>kernel_size</code> <p>An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.</p> required <code>strides</code> <p>An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any <code>dilation_rate</code> value != 1.</p> <code>(1, 1)</code> <code>padding</code> <p>one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</p> <code>'same'</code> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <code>None</code> <code>dilation_rate</code> <p>an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any <code>dilation_rate</code> value != 1 is incompatible with specifying any stride value != 1.</p> <code>(1, 1)</code> <code>activation</code> <p>Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: <code>a(x) = x</code>).</p> <code>None</code> <code>use_bias</code> <p>Boolean, whether the layer uses a bias vector.</p> <code>True</code> <code>kernel_initializer</code> <p>Initializer for the <code>kernel</code> weights matrix.</p> <code>SpectralInitializer()</code> <code>bias_initializer</code> <p>Initializer for the bias vector.</p> <code>'zeros'</code> <code>kernel_regularizer</code> <p>Regularizer function applied to the <code>kernel</code> weights matrix.</p> <code>None</code> <code>bias_regularizer</code> <p>Regularizer function applied to the bias vector.</p> <code>None</code> <code>activity_regularizer</code> <p>Regularizer function applied to the output of the layer (its \"activation\")..</p> <code>None</code> <code>kernel_constraint</code> <p>Constraint function applied to the kernel matrix.</p> <code>None</code> <code>bias_constraint</code> <p>Constraint function applied to the bias vector.</p> <code>None</code> <code>k_coef_lip</code> <p>lipschitz constant to ensure</p> <code>1.0</code> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>eps_bjorck</code> <p>stopping criterion Bjorck algorithm.</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta_bjorck</code> <p>beta parameter in bjorck algorithm.</p> <code>DEFAULT_BETA_BJORCK</code> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration.</p> <code>DEFAULT_MAXITER_SPECTRAL</code> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm.</p> <code>DEFAULT_MAXITER_BJORCK</code> <p>This documentation reuse the body of the original keras.layers.Conv2D doc.</p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n):\n\"\"\"\n    This class is a Conv2D Layer constrained such that all singular of it's kernel\n    are 1. The computation based on Bjorck algorithm. As this is not\n    enough to ensure 1 Lipschitzity a coertive coefficient is applied on the\n    output.\n    The computation is done in three steps:\n\n    1. reduce the largest singular value to 1, using iterated power method.\n    2. increase other singular values to 1, using Bjorck algorithm.\n    3. divide the output by the Lipschitz bound to ensure k Lipschitzity.\n\n    Args:\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        dilation_rate: an integer or tuple/list of 2 integers, specifying\n            the dilation rate to use for dilated convolution.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any stride value != 1.\n        activation: Activation function to use.\n            If you don't specify anything, no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix.\n        bias_initializer: Initializer for the bias vector.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix.\n        bias_regularizer: Regularizer function applied to the bias vector.\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \"activation\")..\n        kernel_constraint: Constraint function applied to the kernel matrix.\n        bias_constraint: Constraint function applied to the bias vector.\n        k_coef_lip: lipschitz constant to ensure\n        eps_spectral: stopping criterion for the iterative power algorithm.\n        eps_bjorck: stopping criterion Bjorck algorithm.\n        beta_bjorck: beta parameter in bjorck algorithm.\n        maxiter_spectral: maximum number of iterations for the power iteration.\n        maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n\n    This documentation reuse the body of the original keras.layers.Conv2D doc.\n    \"\"\"\n    if not (\n        (dilation_rate == (1, 1))\n        or (dilation_rate == [1, 1])\n        or (dilation_rate == 1)\n    ):\n        raise RuntimeError(\"SpectralConv2D does not support dilation rate\")\n    if padding != \"same\":\n        raise RuntimeError(\"SpectralConv2D only supports padding='same'\")\n    super(SpectralConv2D, self).__init__(\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs\n    )\n    self._kwargs = kwargs\n    self.set_klip_factor(k_coef_lip)\n    self.u = None\n    self.sig = None\n    self.wbar = None\n    _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.maxiter_bjorck = maxiter_bjorck\n    self.maxiter_spectral = maxiter_spectral\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional.SpectralConv2DTranspose","title":"<code>SpectralConv2DTranspose</code>","text":"<p>         Bases: <code>Conv2DTranspose</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"SpectralConv2DTranspose\")\nclass SpectralConv2DTranspose(Conv2DTranspose, LipschitzLayer, Condensable):\n    def __init__(\n        self,\n        filters,\n        kernel_size,\n        strides=(1, 1),\n        padding=\"same\",\n        output_padding=None,\n        data_format=None,\n        dilation_rate=(1, 1),\n        activation=None,\n        use_bias=True,\n        kernel_initializer=SpectralInitializer(),\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        bias_constraint=None,\n        k_coef_lip=1.0,\n        eps_spectral=DEFAULT_EPS_SPECTRAL,\n        eps_bjorck=DEFAULT_EPS_BJORCK,\n        beta_bjorck=DEFAULT_BETA_BJORCK,\n        maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n        maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n        **kwargs\n    ):\n\"\"\"\n        This class is a Conv2DTranspose layer constrained such that all singular values\n        of its kernel are 1. The computation is based on Bj\u00f6rck orthogonalization\n        algorithm.\n\n        The computation is done in three steps:\n        1. reduce the largest singular value to 1, using iterated power method.\n        2. increase other singular values to 1, using Bj\u00f6rck algorithm.\n        3. divide the output by the Lipschitz target K to ensure K-Lipschitzity.\n\n        This documentation reuses the body of the original\n        `tf.keras.layers.Conv2DTranspose` doc.\n\n        Args:\n            filters: Integer, the dimensionality of the output space\n                (i.e. the number of output filters in the convolution).\n            kernel_size: An integer or tuple/list of 2 integers, specifying the\n                height and width of the 2D convolution window.\n                Can be a single integer to specify the same value for\n                all spatial dimensions.\n            strides: An integer or tuple/list of 2 integers,\n                specifying the strides of the convolution along the height and width.\n                Can be a single integer to specify the same value for\n                all spatial dimensions.\n            padding: only `\"same\"` padding is supported in this Lipschitz layer\n                (case-insensitive).\n            output_padding: if set to `None` (default), the output shape is inferred.\n                Only `None` value is supported in this Lipschitz layer.\n            data_format: A string,\n                one of `channels_last` (default) or `channels_first`.\n                The ordering of the dimensions in the inputs.\n                `channels_last` corresponds to inputs with shape\n                `(batch, height, width, channels)` while `channels_first`\n                corresponds to inputs with shape\n                `(batch, channels, height, width)`.\n                It defaults to the `image_data_format` value found in your\n                Keras config file at `~/.keras/keras.json`.\n                If you never set it, then it will be \"channels_last\".\n            dilation_rate: an integer, specifying the dilation rate for all spatial\n                dimensions for dilated convolution. This Lipschitz layer does not\n                support dilation rate != 1.\n            activation: Activation function to use.\n                If you don't specify anything, no activation is applied\n                (see `keras.activations`).\n            use_bias: Boolean, whether the layer uses a bias vector.\n            kernel_initializer: Initializer for the `kernel` weights matrix\n                (see `keras.initializers`). Defaults to `SpectralInitializer`.\n            bias_initializer: Initializer for the bias vector\n                (see `keras.initializers`). Defaults to 'zeros'.\n            kernel_regularizer: Regularizer function applied to\n                the `kernel` weights matrix (see `keras.regularizers`).\n            bias_regularizer: Regularizer function applied to the bias vector\n                (see `keras.regularizers`).\n            activity_regularizer: Regularizer function applied to\n                the output of the layer (its \"activation\") (see `keras.regularizers`).\n            kernel_constraint: Constraint function applied to the kernel matrix\n                (see `keras.constraints`).\n            bias_constraint: Constraint function applied to the bias vector\n                (see `keras.constraints`).\n            k_coef_lip: Lipschitz constant to ensure\n            eps_spectral: stopping criterion for the iterative power algorithm.\n            eps_bjorck: stopping criterion Bj\u00f6rck algorithm.\n            beta_bjorck: beta parameter in Bj\u00f6rck algorithm.\n            maxiter_spectral: maximum number of iterations for the power iteration.\n            maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n        \"\"\"\n        super().__init__(\n            filters,\n            kernel_size,\n            strides,\n            padding,\n            output_padding,\n            data_format,\n            dilation_rate,\n            activation,\n            use_bias,\n            kernel_initializer,\n            bias_initializer,\n            kernel_regularizer,\n            bias_regularizer,\n            activity_regularizer,\n            kernel_constraint,\n            bias_constraint,\n            **kwargs\n        )\n\n        if self.dilation_rate != (1, 1):\n            raise ValueError(\"SpectralConv2DTranspose does not support dilation rate\")\n        if self.padding != \"same\":\n            raise ValueError(\"SpectralConv2DTranspose only supports padding='same'\")\n        if self.output_padding is not None:\n            raise ValueError(\n                \"SpectralConv2DTranspose only supports output_padding=None\"\n            )\n        self.set_klip_factor(k_coef_lip)\n        self.u = None\n        self.sig = None\n        self.wbar = None\n        _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n        self.eps_spectral = eps_spectral\n        self.eps_bjorck = eps_bjorck\n        self.beta_bjorck = beta_bjorck\n        self.maxiter_bjorck = maxiter_bjorck\n        self.maxiter_spectral = maxiter_spectral\n        self._kwargs = kwargs\n\n    def build(self, input_shape):\n        super().build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.u = self.add_weight(\n            shape=tuple([1, self.kernel.shape.as_list()[2]]),\n            initializer=RandomNormal(0, 1),\n            name=\"sn\",\n            trainable=False,\n            dtype=self.dtype,\n        )\n\n        self.sig = self.add_weight(\n            shape=tuple([1, 1]),  # maximum spectral  value\n            name=\"sigma\",\n            trainable=False,\n            dtype=self.dtype,\n        )\n        self.sig.assign([[1.0]])\n        self.wbar = tf.Variable(self.kernel.read_value(), trainable=False)\n\n    def _compute_lip_coef(self, input_shape=None):\n        return _compute_conv_lip_factor(\n            self.kernel_size, self.strides, input_shape, self.data_format\n        )\n\n    def call(self, inputs, training=True):\n        if training:\n            kernel_reshaped = tf.transpose(self.kernel, [0, 1, 3, 2])\n            wbar, u, sigma = reshaped_kernel_orthogonalization(\n                kernel_reshaped,\n                self.u,\n                self._get_coef(),\n                self.eps_spectral,\n                self.eps_bjorck,\n                self.beta_bjorck,\n                self.maxiter_spectral,\n                self.maxiter_bjorck,\n            )\n            wbar = tf.transpose(wbar, [0, 1, 3, 2])\n            self.wbar.assign(wbar)\n            self.u.assign(u)\n            self.sig.assign(sigma)\n        else:\n            wbar = self.wbar\n\n        # Apply conv2D_transpose operation on constrained weights\n        # (code from TF/Keras 2.9.1)\n        inputs_shape = tf.shape(inputs)\n        batch_size = inputs_shape[0]\n        if self.data_format == \"channels_first\":\n            h_axis, w_axis = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height, width = None, None\n        if inputs.shape.rank is not None:\n            dims = inputs.shape.as_list()\n            height = dims[h_axis]\n            width = dims[w_axis]\n        height = height if height is not None else inputs_shape[h_axis]\n        width = width if width is not None else inputs_shape[w_axis]\n\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n\n        if self.output_padding is None:\n            out_pad_h = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic output shape:\n        out_height = conv_utils.deconv_output_length(\n            height,\n            kernel_h,\n            padding=self.padding,\n            output_padding=out_pad_h,\n            stride=stride_h,\n            dilation=self.dilation_rate[0],\n        )\n        out_width = conv_utils.deconv_output_length(\n            width,\n            kernel_w,\n            padding=self.padding,\n            output_padding=out_pad_w,\n            stride=stride_w,\n            dilation=self.dilation_rate[1],\n        )\n        if self.data_format == \"channels_first\":\n            output_shape = (batch_size, self.filters, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_height, out_width, self.filters)\n        output_shape_tensor = tf.stack(output_shape)\n\n        outputs = K.conv2d_transpose(\n            inputs,\n            wbar,\n            output_shape_tensor,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate,\n        )\n\n        if not tf.executing_eagerly():\n            # Infer the static output shape:\n            out_shape = self.compute_output_shape(inputs.shape)\n            outputs.set_shape(out_shape)\n\n        if self.use_bias:\n            outputs = tf.nn.bias_add(\n                outputs,\n                self.bias,\n                data_format=conv_utils.convert_data_format(self.data_format, ndim=4),\n            )\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n            \"eps_spectral\": self.eps_spectral,\n            \"eps_bjorck\": self.eps_bjorck,\n            \"beta_bjorck\": self.beta_bjorck,\n            \"maxiter_spectral\": self.maxiter_spectral,\n            \"maxiter_bjorck\": self.maxiter_bjorck,\n        }\n        base_config = super().get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def condense(self):\n        wbar, u, sigma = reshaped_kernel_orthogonalization(\n            self.kernel,\n            self.u,\n            self._get_coef(),\n            self.eps_spectral,\n            self.eps_bjorck,\n            self.beta_bjorck,\n            self.maxiter_spectral,\n            self.maxiter_bjorck,\n        )\n        self.kernel.assign(wbar)\n        self.u.assign(u)\n        self.sig.assign(sigma)\n\n    def vanilla_export(self):\n        self._kwargs[\"name\"] = self.name\n        layer = Conv2DTranspose(\n            filters=self.filters,\n            kernel_size=self.kernel_size,\n            strides=self.strides,\n            padding=self.padding,\n            data_format=self.data_format,\n            activation=self.activation,\n            use_bias=self.use_bias,\n            **self._kwargs\n        )\n        layer.build(self.input_shape)\n        layer.kernel.assign(self.wbar)\n        if layer.use_bias:\n            layer.bias.assign(self.bias)\n        return layer\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.convolutional.SpectralConv2DTranspose.__init__","title":"<code>__init__(filters, kernel_size, strides=(1, 1), padding='same', output_padding=None, data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer=SpectralInitializer(), bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, k_coef_lip=1.0, eps_spectral=DEFAULT_EPS_SPECTRAL, eps_bjorck=DEFAULT_EPS_BJORCK, beta_bjorck=DEFAULT_BETA_BJORCK, maxiter_spectral=DEFAULT_MAXITER_SPECTRAL, maxiter_bjorck=DEFAULT_MAXITER_BJORCK, **kwargs)</code>","text":"<p>This class is a Conv2DTranspose layer constrained such that all singular values of its kernel are 1. The computation is based on Bj\u00f6rck orthogonalization algorithm.</p> <p>The computation is done in three steps: 1. reduce the largest singular value to 1, using iterated power method. 2. increase other singular values to 1, using Bj\u00f6rck algorithm. 3. divide the output by the Lipschitz target K to ensure K-Lipschitzity.</p> <p>This documentation reuses the body of the original <code>tf.keras.layers.Conv2DTranspose</code> doc.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <p>Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).</p> required <code>kernel_size</code> <p>An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.</p> required <code>strides</code> <p>An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions.</p> <code>(1, 1)</code> <code>padding</code> <p>only <code>\"same\"</code> padding is supported in this Lipschitz layer (case-insensitive).</p> <code>'same'</code> <code>output_padding</code> <p>if set to <code>None</code> (default), the output shape is inferred. Only <code>None</code> value is supported in this Lipschitz layer.</p> <code>None</code> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <code>None</code> <code>dilation_rate</code> <p>an integer, specifying the dilation rate for all spatial dimensions for dilated convolution. This Lipschitz layer does not support dilation rate != 1.</p> <code>(1, 1)</code> <code>activation</code> <p>Activation function to use. If you don't specify anything, no activation is applied (see <code>keras.activations</code>).</p> <code>None</code> <code>use_bias</code> <p>Boolean, whether the layer uses a bias vector.</p> <code>True</code> <code>kernel_initializer</code> <p>Initializer for the <code>kernel</code> weights matrix (see <code>keras.initializers</code>). Defaults to <code>SpectralInitializer</code>.</p> <code>SpectralInitializer()</code> <code>bias_initializer</code> <p>Initializer for the bias vector (see <code>keras.initializers</code>). Defaults to 'zeros'.</p> <code>'zeros'</code> <code>kernel_regularizer</code> <p>Regularizer function applied to the <code>kernel</code> weights matrix (see <code>keras.regularizers</code>).</p> <code>None</code> <code>bias_regularizer</code> <p>Regularizer function applied to the bias vector (see <code>keras.regularizers</code>).</p> <code>None</code> <code>activity_regularizer</code> <p>Regularizer function applied to the output of the layer (its \"activation\") (see <code>keras.regularizers</code>).</p> <code>None</code> <code>kernel_constraint</code> <p>Constraint function applied to the kernel matrix (see <code>keras.constraints</code>).</p> <code>None</code> <code>bias_constraint</code> <p>Constraint function applied to the bias vector (see <code>keras.constraints</code>).</p> <code>None</code> <code>k_coef_lip</code> <p>Lipschitz constant to ensure</p> <code>1.0</code> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>eps_bjorck</code> <p>stopping criterion Bj\u00f6rck algorithm.</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta_bjorck</code> <p>beta parameter in Bj\u00f6rck algorithm.</p> <code>DEFAULT_BETA_BJORCK</code> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration.</p> <code>DEFAULT_MAXITER_SPECTRAL</code> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm.</p> <code>DEFAULT_MAXITER_BJORCK</code> Source code in <code>deel/lip/layers/convolutional.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    output_padding=None,\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n):\n\"\"\"\n    This class is a Conv2DTranspose layer constrained such that all singular values\n    of its kernel are 1. The computation is based on Bj\u00f6rck orthogonalization\n    algorithm.\n\n    The computation is done in three steps:\n    1. reduce the largest singular value to 1, using iterated power method.\n    2. increase other singular values to 1, using Bj\u00f6rck algorithm.\n    3. divide the output by the Lipschitz target K to ensure K-Lipschitzity.\n\n    This documentation reuses the body of the original\n    `tf.keras.layers.Conv2DTranspose` doc.\n\n    Args:\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number of output filters in the convolution).\n        kernel_size: An integer or tuple/list of 2 integers, specifying the\n            height and width of the 2D convolution window.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        strides: An integer or tuple/list of 2 integers,\n            specifying the strides of the convolution along the height and width.\n            Can be a single integer to specify the same value for\n            all spatial dimensions.\n        padding: only `\"same\"` padding is supported in this Lipschitz layer\n            (case-insensitive).\n        output_padding: if set to `None` (default), the output shape is inferred.\n            Only `None` value is supported in this Lipschitz layer.\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        dilation_rate: an integer, specifying the dilation rate for all spatial\n            dimensions for dilated convolution. This Lipschitz layer does not\n            support dilation rate != 1.\n        activation: Activation function to use.\n            If you don't specify anything, no activation is applied\n            (see `keras.activations`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see `keras.initializers`). Defaults to `SpectralInitializer`.\n        bias_initializer: Initializer for the bias vector\n            (see `keras.initializers`). Defaults to 'zeros'.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix (see `keras.regularizers`).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see `keras.regularizers`).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \"activation\") (see `keras.regularizers`).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see `keras.constraints`).\n        bias_constraint: Constraint function applied to the bias vector\n            (see `keras.constraints`).\n        k_coef_lip: Lipschitz constant to ensure\n        eps_spectral: stopping criterion for the iterative power algorithm.\n        eps_bjorck: stopping criterion Bj\u00f6rck algorithm.\n        beta_bjorck: beta parameter in Bj\u00f6rck algorithm.\n        maxiter_spectral: maximum number of iterations for the power iteration.\n        maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n    \"\"\"\n    super().__init__(\n        filters,\n        kernel_size,\n        strides,\n        padding,\n        output_padding,\n        data_format,\n        dilation_rate,\n        activation,\n        use_bias,\n        kernel_initializer,\n        bias_initializer,\n        kernel_regularizer,\n        bias_regularizer,\n        activity_regularizer,\n        kernel_constraint,\n        bias_constraint,\n        **kwargs\n    )\n\n    if self.dilation_rate != (1, 1):\n        raise ValueError(\"SpectralConv2DTranspose does not support dilation rate\")\n    if self.padding != \"same\":\n        raise ValueError(\"SpectralConv2DTranspose only supports padding='same'\")\n    if self.output_padding is not None:\n        raise ValueError(\n            \"SpectralConv2DTranspose only supports output_padding=None\"\n        )\n    self.set_klip_factor(k_coef_lip)\n    self.u = None\n    self.sig = None\n    self.wbar = None\n    _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.maxiter_bjorck = maxiter_bjorck\n    self.maxiter_spectral = maxiter_spectral\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.dense","title":"<code>dense</code>","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.dense.FrobeniusDense","title":"<code>FrobeniusDense</code>","text":"<p>         Bases: <code>Dense</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> <p>Identical and faster than a SpectralDense in the case of a single output. In the multi-neurons setting, this layer can be used: - as a classical Frobenius Dense normalization (disjoint_neurons=False) - as a stacking of 1 lipschitz independent neurons (each output is 1-lipschitz, but the no orthogonality is enforced between outputs )  (disjoint_neurons=True).</p> Warning <p>default is disjoint_neurons = True</p> Source code in <code>deel/lip/layers/dense.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"FrobeniusDense\")\nclass FrobeniusDense(Dense, LipschitzLayer, Condensable):\n\"\"\"\n    Identical and faster than a SpectralDense in the case of a single output. In the\n    multi-neurons setting, this layer can be used:\n    - as a classical Frobenius Dense normalization (disjoint_neurons=False)\n    - as a stacking of 1 lipschitz independent neurons (each output is 1-lipschitz,\n    but the no orthogonality is enforced between outputs )  (disjoint_neurons=True).\n\n    Warning :\n        default is disjoint_neurons = True\n    \"\"\"\n\n    def __init__(\n        self,\n        units,\n        activation=None,\n        use_bias=True,\n        kernel_initializer=SpectralInitializer(),\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        bias_constraint=None,\n        disjoint_neurons=True,\n        k_coef_lip=1.0,\n        **kwargs\n    ):\n        super().__init__(\n            units=units,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs\n        )\n        self.set_klip_factor(k_coef_lip)\n        self.disjoint_neurons = disjoint_neurons\n        self.axis_norm = None\n        self.wbar = None\n        if self.disjoint_neurons:\n            self.axis_norm = 0\n        self._kwargs = kwargs\n\n    def build(self, input_shape):\n        super(FrobeniusDense, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.wbar = tf.Variable(self.kernel.read_value(), trainable=False)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return 1.0\n\n    def call(self, x, training=True):\n        if training:\n            wbar = (\n                self.kernel\n                / tf.norm(self.kernel, axis=self.axis_norm)\n                * self._get_coef()\n            )\n            self.wbar.assign(wbar)\n        else:\n            wbar = self.wbar\n        outputs = tf.matmul(x, wbar)\n        if self.use_bias:\n            outputs = tf.nn.bias_add(outputs, self.bias)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n            \"disjoint_neurons\": self.disjoint_neurons,\n        }\n        base_config = super(FrobeniusDense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def condense(self):\n        wbar = (\n            self.kernel / tf.norm(self.kernel, axis=self.axis_norm) * self._get_coef()\n        )\n        self.kernel.assign(wbar)\n\n    def vanilla_export(self):\n        self._kwargs[\"name\"] = self.name\n        layer = Dense(\n            units=self.units,\n            activation=self.activation,\n            use_bias=self.use_bias,\n            kernel_initializer=\"glorot_uniform\",\n            bias_initializer=\"zeros\",\n            **self._kwargs\n        )\n        layer.build(self.input_shape)\n        layer.kernel.assign(self.wbar)\n        if self.use_bias:\n            layer.bias.assign(self.bias)\n        return layer\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.dense.SpectralDense","title":"<code>SpectralDense</code>","text":"<p>         Bases: <code>Dense</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> Source code in <code>deel/lip/layers/dense.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"SpectralDense\")\nclass SpectralDense(Dense, LipschitzLayer, Condensable):\n    def __init__(\n        self,\n        units,\n        activation=None,\n        use_bias=True,\n        kernel_initializer=SpectralInitializer(),\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        bias_constraint=None,\n        k_coef_lip=1.0,\n        eps_spectral=DEFAULT_EPS_SPECTRAL,\n        eps_bjorck=DEFAULT_EPS_BJORCK,\n        beta_bjorck=DEFAULT_BETA_BJORCK,\n        maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n        maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n        **kwargs\n    ):\n\"\"\"\n        This class is a Dense Layer constrained such that all singular of it's kernel\n        are 1. The computation based on Bjorck algorithm.\n        The computation is done in two steps:\n\n        1. reduce the larget singular value to 1, using iterated power method.\n        2. increase other singular values to 1, using Bjorck algorithm.\n\n        Args:\n            units: Positive integer, dimensionality of the output space.\n            activation: Activation function to use.\n                If you don't specify anything, no activation is applied\n                (ie. \"linear\" activation: `a(x) = x`).\n            use_bias: Boolean, whether the layer uses a bias vector.\n            kernel_initializer: Initializer for the `kernel` weights matrix.\n            bias_initializer: Initializer for the bias vector.\n            kernel_regularizer: Regularizer function applied to\n                the `kernel` weights matrix.\n            bias_regularizer: Regularizer function applied to the bias vector.\n            activity_regularizer: Regularizer function applied to\n                the output of the layer (its \"activation\")..\n            kernel_constraint: Constraint function applied to\n                the `kernel` weights matrix.\n            bias_constraint: Constraint function applied to the bias vector.\n            k_coef_lip: lipschitz constant to ensure\n            eps_spectral: stopping criterion for the iterative power algorithm.\n            eps_bjorck: stopping criterion Bjorck algorithm.\n            beta_bjorck: beta parameter in bjorck algorithm.\n            maxiter_spectral: maximum number of iterations for the power iteration.\n            maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n\n        Input shape:\n            N-D tensor with shape: `(batch_size, ..., input_dim)`.\n            The most common situation would be\n            a 2D input with shape `(batch_size, input_dim)`.\n\n        Output shape:\n            N-D tensor with shape: `(batch_size, ..., units)`.\n            For instance, for a 2D input with shape `(batch_size, input_dim)`,\n            the output would have shape `(batch_size, units)`.\n\n        This documentation reuse the body of the original keras.layers.Dense doc.\n        \"\"\"\n        super(SpectralDense, self).__init__(\n            units=units,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs\n        )\n        self._kwargs = kwargs\n        self.set_klip_factor(k_coef_lip)\n        _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n        self.eps_spectral = eps_spectral\n        self.eps_bjorck = eps_bjorck\n        self.beta_bjorck = beta_bjorck\n        self.maxiter_bjorck = maxiter_bjorck\n        self.maxiter_spectral = maxiter_spectral\n        self.u = None\n        self.sig = None\n        self.wbar = None\n        self.built = False\n\n    def build(self, input_shape):\n        super(SpectralDense, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.u = self.add_weight(\n            shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n            initializer=RandomNormal(0, 1),\n            name=\"sn\",\n            trainable=False,\n            dtype=self.dtype,\n        )\n        self.sig = self.add_weight(\n            shape=tuple([1, 1]),  # maximum spectral  value\n            initializer=tf.keras.initializers.ones,\n            name=\"sigma\",\n            trainable=False,\n            dtype=self.dtype,\n        )\n        self.sig.assign([[1.0]])\n        self.wbar = tf.Variable(self.kernel.read_value(), trainable=False)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return 1.0  # this layer don't require a corrective factor\n\n    @tf.function\n    def call(self, x, training=True):\n        if training:\n            wbar, u, sigma = reshaped_kernel_orthogonalization(\n                self.kernel,\n                self.u,\n                self._get_coef(),\n                self.eps_spectral,\n                self.eps_bjorck,\n                self.beta_bjorck,\n                self.maxiter_spectral,\n                self.maxiter_bjorck,\n            )\n            self.wbar.assign(wbar)\n            self.u.assign(u)\n            self.sig.assign(sigma)\n        else:\n            wbar = self.wbar\n        outputs = tf.matmul(x, wbar)\n        if self.use_bias:\n            outputs = tf.nn.bias_add(outputs, self.bias)\n        if self.activation is not None:\n            outputs = self.activation(outputs)\n        return outputs\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n            \"eps_spectral\": self.eps_spectral,\n            \"eps_bjorck\": self.eps_bjorck,\n            \"beta_bjorck\": self.beta_bjorck,\n            \"maxiter_spectral\": self.maxiter_spectral,\n            \"maxiter_bjorck\": self.maxiter_bjorck,\n        }\n        base_config = super(SpectralDense, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def condense(self):\n        wbar, u, sigma = reshaped_kernel_orthogonalization(\n            self.kernel,\n            self.u,\n            self._get_coef(),\n            self.eps_spectral,\n            self.eps_bjorck,\n            self.beta_bjorck,\n            self.maxiter_spectral,\n            self.maxiter_bjorck,\n        )\n        self.kernel.assign(wbar)\n        self.u.assign(u)\n        self.sig.assign(sigma)\n\n    def vanilla_export(self):\n        self._kwargs[\"name\"] = self.name\n        layer = Dense(\n            units=self.units,\n            activation=self.activation,\n            use_bias=self.use_bias,\n            kernel_initializer=\"glorot_uniform\",\n            bias_initializer=\"zeros\",\n            **self._kwargs\n        )\n        layer.build(self.input_shape)\n        layer.kernel.assign(self.wbar)\n        if self.use_bias:\n            layer.bias.assign(self.bias)\n        return layer\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.dense.SpectralDense.__init__","title":"<code>__init__(units, activation=None, use_bias=True, kernel_initializer=SpectralInitializer(), bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, k_coef_lip=1.0, eps_spectral=DEFAULT_EPS_SPECTRAL, eps_bjorck=DEFAULT_EPS_BJORCK, beta_bjorck=DEFAULT_BETA_BJORCK, maxiter_spectral=DEFAULT_MAXITER_SPECTRAL, maxiter_bjorck=DEFAULT_MAXITER_BJORCK, **kwargs)</code>","text":"<p>This class is a Dense Layer constrained such that all singular of it's kernel are 1. The computation based on Bjorck algorithm. The computation is done in two steps:</p> <ol> <li>reduce the larget singular value to 1, using iterated power method.</li> <li>increase other singular values to 1, using Bjorck algorithm.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>units</code> <p>Positive integer, dimensionality of the output space.</p> required <code>activation</code> <p>Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: <code>a(x) = x</code>).</p> <code>None</code> <code>use_bias</code> <p>Boolean, whether the layer uses a bias vector.</p> <code>True</code> <code>kernel_initializer</code> <p>Initializer for the <code>kernel</code> weights matrix.</p> <code>SpectralInitializer()</code> <code>bias_initializer</code> <p>Initializer for the bias vector.</p> <code>'zeros'</code> <code>kernel_regularizer</code> <p>Regularizer function applied to the <code>kernel</code> weights matrix.</p> <code>None</code> <code>bias_regularizer</code> <p>Regularizer function applied to the bias vector.</p> <code>None</code> <code>activity_regularizer</code> <p>Regularizer function applied to the output of the layer (its \"activation\")..</p> <code>None</code> <code>kernel_constraint</code> <p>Constraint function applied to the <code>kernel</code> weights matrix.</p> <code>None</code> <code>bias_constraint</code> <p>Constraint function applied to the bias vector.</p> <code>None</code> <code>k_coef_lip</code> <p>lipschitz constant to ensure</p> <code>1.0</code> <code>eps_spectral</code> <p>stopping criterion for the iterative power algorithm.</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>eps_bjorck</code> <p>stopping criterion Bjorck algorithm.</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta_bjorck</code> <p>beta parameter in bjorck algorithm.</p> <code>DEFAULT_BETA_BJORCK</code> <code>maxiter_spectral</code> <p>maximum number of iterations for the power iteration.</p> <code>DEFAULT_MAXITER_SPECTRAL</code> <code>maxiter_bjorck</code> <p>maximum number of iterations for bjorck algorithm.</p> <code>DEFAULT_MAXITER_BJORCK</code> Input shape <p>N-D tensor with shape: <code>(batch_size, ..., input_dim)</code>. The most common situation would be a 2D input with shape <code>(batch_size, input_dim)</code>.</p> Output shape <p>N-D tensor with shape: <code>(batch_size, ..., units)</code>. For instance, for a 2D input with shape <code>(batch_size, input_dim)</code>, the output would have shape <code>(batch_size, units)</code>.</p> <p>This documentation reuse the body of the original keras.layers.Dense doc.</p> Source code in <code>deel/lip/layers/dense.py</code> <pre><code>def __init__(\n    self,\n    units,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=SpectralInitializer(),\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    k_coef_lip=1.0,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta_bjorck=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n    **kwargs\n):\n\"\"\"\n    This class is a Dense Layer constrained such that all singular of it's kernel\n    are 1. The computation based on Bjorck algorithm.\n    The computation is done in two steps:\n\n    1. reduce the larget singular value to 1, using iterated power method.\n    2. increase other singular values to 1, using Bjorck algorithm.\n\n    Args:\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use.\n            If you don't specify anything, no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix.\n        bias_initializer: Initializer for the bias vector.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix.\n        bias_regularizer: Regularizer function applied to the bias vector.\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its \"activation\")..\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix.\n        bias_constraint: Constraint function applied to the bias vector.\n        k_coef_lip: lipschitz constant to ensure\n        eps_spectral: stopping criterion for the iterative power algorithm.\n        eps_bjorck: stopping criterion Bjorck algorithm.\n        beta_bjorck: beta parameter in bjorck algorithm.\n        maxiter_spectral: maximum number of iterations for the power iteration.\n        maxiter_bjorck: maximum number of iterations for bjorck algorithm.\n\n    Input shape:\n        N-D tensor with shape: `(batch_size, ..., input_dim)`.\n        The most common situation would be\n        a 2D input with shape `(batch_size, input_dim)`.\n\n    Output shape:\n        N-D tensor with shape: `(batch_size, ..., units)`.\n        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n        the output would have shape `(batch_size, units)`.\n\n    This documentation reuse the body of the original keras.layers.Dense doc.\n    \"\"\"\n    super(SpectralDense, self).__init__(\n        units=units,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs\n    )\n    self._kwargs = kwargs\n    self.set_klip_factor(k_coef_lip)\n    _check_RKO_params(eps_spectral, eps_bjorck, beta_bjorck)\n    self.eps_spectral = eps_spectral\n    self.eps_bjorck = eps_bjorck\n    self.beta_bjorck = beta_bjorck\n    self.maxiter_bjorck = maxiter_bjorck\n    self.maxiter_spectral = maxiter_spectral\n    self.u = None\n    self.sig = None\n    self.wbar = None\n    self.built = False\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling","title":"<code>pooling</code>","text":"<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization. Currently, are implemented: * Dense layer:     as SpectralDense (and as FrobeniusDense when the layer has a single     output) * Conv2D layer:     as SpectralConv2D (and as FrobeniusConv2D when the layer has a single     output) * AveragePooling:     as ScaledAveragePooling * GlobalAveragePooling2D:     as ScaledGlobalAveragePooling2D By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However for other problems (such as adversarial robustness) the user may want to use layers that are at most 1 lipschitz, this can be done by setting the param <code>eps_bjorck=None</code>.</p>"},{"location":"api/layers/#deel.lip.layers.pooling.InvertibleDownSampling","title":"<code>InvertibleDownSampling</code>","text":"<p>         Bases: <code>keraslayers.Layer</code></p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"InvertibleDownSampling\")\nclass InvertibleDownSampling(keraslayers.Layer):\n    def __init__(\n        self, pool_size, data_format=\"channels_last\", name=None, dtype=None, **kwargs\n    ):\n\"\"\"\n\n        This pooling layer perform a reshape on the spacial dimensions: it take a\n        (bs, h, w, c) ( if channels_last ) and reshape it to a\n        (bs, h/p_h, w/p_w, c*p_w*p_h ), where p_w and p_h are the shape of the pool.\n        By doing this the image size is reduced while the number of channels is\n        increased.\n\n        References:\n            Anil et al. [paper](https://arxiv.org/abs/1911.00937)\n\n        Note:\n            The image shape must be divisible by the pool shape.\n\n        Args:\n            pool_size: tuple describing the pool shape\n            data_format: can either be `channels_last` or `channels_first`\n            name: name of the layer\n            dtype: dtype of the layer\n            **kwargs: params passed to the Layers constructor\n        \"\"\"\n        super(InvertibleDownSampling, self).__init__(name=name, dtype=dtype, **kwargs)\n        self.pool_size = pool_size\n        self.data_format = data_format\n\n    def build(self, input_shape):\n        return super(InvertibleDownSampling, self).build(input_shape)\n\n    def call(self, inputs, **kwargs):\n        # inputs = super(InvertibleDownSampling, self).call(inputs, **kwargs)\n        if self.data_format == \"channels_last\":\n            return tf.concat(\n                [\n                    inputs[\n                        :, i :: self.pool_size[0], j :: self.pool_size[1], :\n                    ]  # for now we handle only channels last\n                    for i in range(self.pool_size[0])\n                    for j in range(self.pool_size[1])\n                ],\n                axis=-1,\n            )\n        else:\n            return tf.concat(\n                [\n                    inputs[\n                        :, :, i :: self.pool_size[0], j :: self.pool_size[1]\n                    ]  # for now we handle only channels last\n                    for i in range(self.pool_size[0])\n                    for j in range(self.pool_size[1])\n                ],\n                axis=1,\n            )\n\n    def get_config(self):\n        config = {\n            \"data_format\": self.data_format,\n            \"pool_size\": self.pool_size,\n        }\n        base_config = super(InvertibleDownSampling, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.InvertibleDownSampling.__init__","title":"<code>__init__(pool_size, data_format='channels_last', name=None, dtype=None, **kwargs)</code>","text":"<p>This pooling layer perform a reshape on the spacial dimensions: it take a (bs, h, w, c) ( if channels_last ) and reshape it to a (bs, h/p_h, w/p_w, cp_wp_h ), where p_w and p_h are the shape of the pool. By doing this the image size is reduced while the number of channels is increased.</p> References <p>Anil et al. paper</p> Note <p>The image shape must be divisible by the pool shape.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <p>tuple describing the pool shape</p> required <code>data_format</code> <p>can either be <code>channels_last</code> or <code>channels_first</code></p> <code>'channels_last'</code> <code>name</code> <p>name of the layer</p> <code>None</code> <code>dtype</code> <p>dtype of the layer</p> <code>None</code> <code>**kwargs</code> <p>params passed to the Layers constructor</p> <code>{}</code> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self, pool_size, data_format=\"channels_last\", name=None, dtype=None, **kwargs\n):\n\"\"\"\n\n    This pooling layer perform a reshape on the spacial dimensions: it take a\n    (bs, h, w, c) ( if channels_last ) and reshape it to a\n    (bs, h/p_h, w/p_w, c*p_w*p_h ), where p_w and p_h are the shape of the pool.\n    By doing this the image size is reduced while the number of channels is\n    increased.\n\n    References:\n        Anil et al. [paper](https://arxiv.org/abs/1911.00937)\n\n    Note:\n        The image shape must be divisible by the pool shape.\n\n    Args:\n        pool_size: tuple describing the pool shape\n        data_format: can either be `channels_last` or `channels_first`\n        name: name of the layer\n        dtype: dtype of the layer\n        **kwargs: params passed to the Layers constructor\n    \"\"\"\n    super(InvertibleDownSampling, self).__init__(name=name, dtype=dtype, **kwargs)\n    self.pool_size = pool_size\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.InvertibleUpSampling","title":"<code>InvertibleUpSampling</code>","text":"<p>         Bases: <code>keraslayers.Layer</code></p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"InvertibleUpSampling\")\nclass InvertibleUpSampling(keraslayers.Layer):\n    def __init__(\n        self, pool_size, data_format=\"channels_last\", name=None, dtype=None, **kwargs\n    ):\n\"\"\"\n\n        This Layer is the inverse of the InvertibleDownSampling layer. It take a\n        (bs, h, w, c) ( if channels_last ) and reshape it to a\n        (bs, h/p_h, w/p_w, c*p_w*p_h ), where p_w and p_h are the shape of the\n        pool. By doing this the image size is reduced while the number of\n        channels is increased.\n\n        References:\n            Anil et al. [paper](https://arxiv.org/abs/1911.00937)\n\n        Note:\n            The input number of channels must be divisible by the `p_w*p_h`.\n\n\n        Args:\n            pool_size: tuple describing the pool shape (p_h, p_w)\n            data_format: can either be `channels_last` or `channels_first`\n            name: name of the layer\n            dtype: dtype of the layer\n            **kwargs: params passed to the Layers constructor\n        \"\"\"\n        super(InvertibleUpSampling, self).__init__(name=name, dtype=dtype, **kwargs)\n        self.pool_size = pool_size\n        self.data_format = data_format\n\n    def build(self, input_shape):\n        return super(InvertibleUpSampling, self).build(input_shape)\n\n    def call(self, inputs, **kwargs):\n        if self.data_format == \"channels_first\":\n            # convert to channels_first\n            inputs = tf.transpose(inputs, [0, 2, 3, 1])\n        # from shape (bs, w, h, c*pw*ph) to (bs, w, h, pw, ph, c)\n        bs, w, h = inputs.shape[:-1]\n        (\n            pw,\n            ph,\n        ) = self.pool_size\n        c = inputs.shape[-1] // (pw * ph)\n        print(c)\n        inputs = tf.reshape(inputs, (-1, w, h, pw, ph, c))\n        inputs = tf.transpose(\n            tf.reshape(\n                tf.transpose(\n                    inputs, [0, 5, 2, 4, 1, 3]\n                ),  # (bs, w, h, pw, ph, c) -&gt; (bs, c, w, pw, h, ph)\n                (-1, c, w, pw, h * ph),\n            ),  # (bs, c, w, pw, h, ph) -&gt; (bs, c, w, pw, h*ph) merge last axes\n            [\n                0,\n                1,\n                4,\n                2,\n                3,\n            ],  # (bs, c, w, pw, h*ph) -&gt; (bs, c, h*ph, w, pw)\n            # put each axis back in place\n        )\n        inputs = tf.reshape(\n            inputs, (-1, c, h * ph, w * pw)\n        )  # (bs, c, h*ph, w, pw) -&gt; (bs, c, h*ph, w*pw)\n        if self.data_format == \"channels_last\":\n            inputs = tf.transpose(\n                inputs, [0, 2, 3, 1]  # (bs, c, h*ph, w*pw) -&gt; (bs, w*pw, h*ph, c)\n            )\n        return inputs\n\n    def get_config(self):\n        config = {\n            \"data_format\": self.data_format,\n            \"pool_size\": self.pool_size,\n        }\n        base_config = super(InvertibleUpSampling, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.InvertibleUpSampling.__init__","title":"<code>__init__(pool_size, data_format='channels_last', name=None, dtype=None, **kwargs)</code>","text":"<p>This Layer is the inverse of the InvertibleDownSampling layer. It take a (bs, h, w, c) ( if channels_last ) and reshape it to a (bs, h/p_h, w/p_w, cp_wp_h ), where p_w and p_h are the shape of the pool. By doing this the image size is reduced while the number of channels is increased.</p> References <p>Anil et al. paper</p> Note <p>The input number of channels must be divisible by the <code>p_w*p_h</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <p>tuple describing the pool shape (p_h, p_w)</p> required <code>data_format</code> <p>can either be <code>channels_last</code> or <code>channels_first</code></p> <code>'channels_last'</code> <code>name</code> <p>name of the layer</p> <code>None</code> <code>dtype</code> <p>dtype of the layer</p> <code>None</code> <code>**kwargs</code> <p>params passed to the Layers constructor</p> <code>{}</code> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self, pool_size, data_format=\"channels_last\", name=None, dtype=None, **kwargs\n):\n\"\"\"\n\n    This Layer is the inverse of the InvertibleDownSampling layer. It take a\n    (bs, h, w, c) ( if channels_last ) and reshape it to a\n    (bs, h/p_h, w/p_w, c*p_w*p_h ), where p_w and p_h are the shape of the\n    pool. By doing this the image size is reduced while the number of\n    channels is increased.\n\n    References:\n        Anil et al. [paper](https://arxiv.org/abs/1911.00937)\n\n    Note:\n        The input number of channels must be divisible by the `p_w*p_h`.\n\n\n    Args:\n        pool_size: tuple describing the pool shape (p_h, p_w)\n        data_format: can either be `channels_last` or `channels_first`\n        name: name of the layer\n        dtype: dtype of the layer\n        **kwargs: params passed to the Layers constructor\n    \"\"\"\n    super(InvertibleUpSampling, self).__init__(name=name, dtype=dtype, **kwargs)\n    self.pool_size = pool_size\n    self.data_format = data_format\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledAveragePooling2D","title":"<code>ScaledAveragePooling2D</code>","text":"<p>         Bases: <code>keraslayers.AveragePooling2D</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"ScaledAveragePooling2D\")\nclass ScaledAveragePooling2D(keraslayers.AveragePooling2D, LipschitzLayer):\n    def __init__(\n        self,\n        pool_size=(2, 2),\n        strides=None,\n        padding=\"valid\",\n        data_format=None,\n        k_coef_lip=1.0,\n        **kwargs\n    ):\n\"\"\"\n        Average pooling operation for spatial data, but with a lipschitz bound.\n\n        Arguments:\n            pool_size: integer or tuple of 2 integers,\n                factors by which to downscale (vertical, horizontal).\n                `(2, 2)` will halve the input in both spatial dimension.\n                If only one integer is specified, the same window length\n                will be used for both dimensions.\n            strides: Integer, tuple of 2 integers, or None.\n                Strides values.\n                If None, it will default to `pool_size`.\n            padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n            data_format: A string,\n                one of `channels_last` (default) or `channels_first`.\n                The ordering of the dimensions in the inputs.\n                `channels_last` corresponds to inputs with shape\n                `(batch, height, width, channels)` while `channels_first`\n                corresponds to inputs with shape\n                `(batch, channels, height, width)`.\n                It defaults to the `image_data_format` value found in your\n                Keras config file at `~/.keras/keras.json`.\n                If you never set it, then it will be \"channels_last\".\n            k_coef_lip: the lipschitz factor to ensure\n\n        Input shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, rows, cols, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n        Output shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n\n        This documentation reuse the body of the original keras.layers.AveragePooling2D\n        doc.\n        \"\"\"\n        if not ((strides == pool_size) or (strides is None)):\n            raise RuntimeError(\"stride must be equal to pool_size\")\n        if padding != \"valid\":\n            raise RuntimeError(\"ScaledAveragePooling2D only supports padding='valid'\")\n        super(ScaledAveragePooling2D, self).__init__(\n            pool_size=pool_size,\n            strides=pool_size,\n            padding=padding,\n            data_format=data_format,\n            **kwargs\n        )\n        self.set_klip_factor(k_coef_lip)\n        self._kwargs = kwargs\n\n    def build(self, input_shape):\n        super(ScaledAveragePooling2D, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return np.sqrt(np.prod(np.asarray(self.pool_size)))\n\n    def call(self, x, training=True):\n        return super(keraslayers.AveragePooling2D, self).call(x) * self._get_coef()\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n        }\n        base_config = super(ScaledAveragePooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledAveragePooling2D.__init__","title":"<code>__init__(pool_size=(2, 2), strides=None, padding='valid', data_format=None, k_coef_lip=1.0, **kwargs)</code>","text":"<p>Average pooling operation for spatial data, but with a lipschitz bound.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <p>integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). <code>(2, 2)</code> will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.</p> <code>(2, 2)</code> <code>strides</code> <p>Integer, tuple of 2 integers, or None. Strides values. If None, it will default to <code>pool_size</code>.</p> <code>None</code> <code>padding</code> <p>One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</p> <code>'valid'</code> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <code>None</code> <code>k_coef_lip</code> <p>the lipschitz factor to ensure</p> <code>1.0</code> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> Output shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, pooled_rows, pooled_cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, pooled_rows, pooled_cols)</code>.</li> </ul> <p>This documentation reuse the body of the original keras.layers.AveragePooling2D doc.</p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self,\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None,\n    k_coef_lip=1.0,\n    **kwargs\n):\n\"\"\"\n    Average pooling operation for spatial data, but with a lipschitz bound.\n\n    Arguments:\n        pool_size: integer or tuple of 2 integers,\n            factors by which to downscale (vertical, horizontal).\n            `(2, 2)` will halve the input in both spatial dimension.\n            If only one integer is specified, the same window length\n            will be used for both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n            Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        k_coef_lip: the lipschitz factor to ensure\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n\n    This documentation reuse the body of the original keras.layers.AveragePooling2D\n    doc.\n    \"\"\"\n    if not ((strides == pool_size) or (strides is None)):\n        raise RuntimeError(\"stride must be equal to pool_size\")\n    if padding != \"valid\":\n        raise RuntimeError(\"ScaledAveragePooling2D only supports padding='valid'\")\n    super(ScaledAveragePooling2D, self).__init__(\n        pool_size=pool_size,\n        strides=pool_size,\n        padding=padding,\n        data_format=data_format,\n        **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledGlobalAveragePooling2D","title":"<code>ScaledGlobalAveragePooling2D</code>","text":"<p>         Bases: <code>keraslayers.GlobalAveragePooling2D</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"ScaledGlobalAveragePooling2D\")\nclass ScaledGlobalAveragePooling2D(keraslayers.GlobalAveragePooling2D, LipschitzLayer):\n    def __init__(self, data_format=None, k_coef_lip=1.0, **kwargs):\n\"\"\"Global average pooling operation for spatial data with Lipschitz bound.\n\n        Arguments:\n            data_format: A string,\n                one of `channels_last` (default) or `channels_first`.\n                The ordering of the dimensions in the inputs.\n                `channels_last` corresponds to inputs with shape\n                `(batch, height, width, channels)` while `channels_first`\n                corresponds to inputs with shape\n                `(batch, channels, height, width)`.\n                It defaults to the `image_data_format` value found in your\n                Keras config file at `~/.keras/keras.json`.\n                If you never set it, then it will be \"channels_last\".\n\n        Input shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, rows, cols, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n        Output shape:\n        2D tensor with shape `(batch_size, channels)`.\n\n        This documentation reuse the body of the original\n        keras.layers.GlobalAveragePooling doc.\n        \"\"\"\n        super(ScaledGlobalAveragePooling2D, self).__init__(\n            data_format=data_format, **kwargs\n        )\n        self.set_klip_factor(k_coef_lip)\n        self._kwargs = kwargs\n\n    def build(self, input_shape):\n        super(ScaledGlobalAveragePooling2D, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        if self.data_format == \"channels_last\":\n            lip_coef = np.sqrt(input_shape[-3] * input_shape[-2])\n        elif self.data_format == \"channels_first\":\n            lip_coef = np.sqrt(input_shape[-2] * input_shape[-1])\n        else:\n            raise RuntimeError(\"data format not understood: %s\" % self.data_format)\n        return lip_coef\n\n    def call(self, x, training=True):\n        return super(ScaledGlobalAveragePooling2D, self).call(x) * self._get_coef()\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n        }\n        base_config = super(ScaledGlobalAveragePooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledGlobalAveragePooling2D.__init__","title":"<code>__init__(data_format=None, k_coef_lip=1.0, **kwargs)</code>","text":"<p>Global average pooling operation for spatial data with Lipschitz bound.</p> <p>Parameters:</p> Name Type Description Default <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <code>None</code> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> <p>Output shape: 2D tensor with shape <code>(batch_size, channels)</code>.</p> <p>This documentation reuse the body of the original keras.layers.GlobalAveragePooling doc.</p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(self, data_format=None, k_coef_lip=1.0, **kwargs):\n\"\"\"Global average pooling operation for spatial data with Lipschitz bound.\n\n    Arguments:\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n    2D tensor with shape `(batch_size, channels)`.\n\n    This documentation reuse the body of the original\n    keras.layers.GlobalAveragePooling doc.\n    \"\"\"\n    super(ScaledGlobalAveragePooling2D, self).__init__(\n        data_format=data_format, **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledGlobalL2NormPooling2D","title":"<code>ScaledGlobalL2NormPooling2D</code>","text":"<p>         Bases: <code>keraslayers.GlobalAveragePooling2D</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"ScaledGlobalL2NormPooling2D\")\nclass ScaledGlobalL2NormPooling2D(keraslayers.GlobalAveragePooling2D, LipschitzLayer):\n    def __init__(self, data_format=None, k_coef_lip=1.0, eps_grad_sqrt=1e-6, **kwargs):\n\"\"\"\n        Average pooling operation for spatial data, with a lipschitz bound. This\n        pooling operation is norm preserving (aka gradient=1 almost everywhere).\n\n        [1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature\n        Pooling in Visual Recognition \u00bb,p.8.\n\n        Arguments:\n            data_format: A string,\n                one of `channels_last` (default) or `channels_first`.\n                The ordering of the dimensions in the inputs.\n                `channels_last` corresponds to inputs with shape\n                `(batch, height, width, channels)` while `channels_first`\n                corresponds to inputs with shape\n                `(batch, channels, height, width)`.\n                It defaults to the `image_data_format` value found in your\n                Keras config file at `~/.keras/keras.json`.\n                If you never set it, then it will be \"channels_last\".\n            k_coef_lip: the lipschitz factor to ensure\n            eps_grad_sqrt: Epsilon value to avoid numerical instability\n                due to non-defined gradient at 0 in the sqrt function\n\n        Input shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, rows, cols, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n        Output shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, pooled_cols)`.\n        \"\"\"\n        if eps_grad_sqrt &lt; 0.0:\n            raise RuntimeError(\"eps_grad_sqrt must be positive\")\n        super(ScaledGlobalL2NormPooling2D, self).__init__(\n            data_format=data_format, **kwargs\n        )\n        self.set_klip_factor(k_coef_lip)\n        self.eps_grad_sqrt = eps_grad_sqrt\n        self._kwargs = kwargs\n        if self.data_format == \"channels_last\":\n            self.axes = [1, 2]\n        else:\n            self.axes = [2, 3]\n\n    def build(self, input_shape):\n        super(ScaledGlobalL2NormPooling2D, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return 1.0\n\n    @staticmethod\n    def _sqrt(eps_grad_sqrt):\n        @tf.custom_gradient\n        def sqrt_op(x):\n            sqrtx = tf.sqrt(x)\n\n            def grad(dy):\n                return dy / (2 * (sqrtx + eps_grad_sqrt))\n\n            return sqrtx, grad\n\n        return sqrt_op\n\n    def call(self, x, training=True):\n        return (\n            ScaledL2NormPooling2D._sqrt(self.eps_grad_sqrt)(\n                tf.reduce_sum(tf.square(x), axis=self.axes)\n            )\n            * self._get_coef()\n        )\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n        }\n        base_config = super(ScaledGlobalL2NormPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledGlobalL2NormPooling2D.__init__","title":"<code>__init__(data_format=None, k_coef_lip=1.0, eps_grad_sqrt=1e-06, **kwargs)</code>","text":"<p>Average pooling operation for spatial data, with a lipschitz bound. This pooling operation is norm preserving (aka gradient=1 almost everywhere).</p> <p>[1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature Pooling in Visual Recognition \u00bb,p.8.</p> <p>Parameters:</p> Name Type Description Default <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <code>None</code> <code>k_coef_lip</code> <p>the lipschitz factor to ensure</p> <code>1.0</code> <code>eps_grad_sqrt</code> <p>Epsilon value to avoid numerical instability due to non-defined gradient at 0 in the sqrt function</p> <code>1e-06</code> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> Output shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, pooled_cols)</code>.</li> </ul> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(self, data_format=None, k_coef_lip=1.0, eps_grad_sqrt=1e-6, **kwargs):\n\"\"\"\n    Average pooling operation for spatial data, with a lipschitz bound. This\n    pooling operation is norm preserving (aka gradient=1 almost everywhere).\n\n    [1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature\n    Pooling in Visual Recognition \u00bb,p.8.\n\n    Arguments:\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        k_coef_lip: the lipschitz factor to ensure\n        eps_grad_sqrt: Epsilon value to avoid numerical instability\n            due to non-defined gradient at 0 in the sqrt function\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, pooled_cols)`.\n    \"\"\"\n    if eps_grad_sqrt &lt; 0.0:\n        raise RuntimeError(\"eps_grad_sqrt must be positive\")\n    super(ScaledGlobalL2NormPooling2D, self).__init__(\n        data_format=data_format, **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self.eps_grad_sqrt = eps_grad_sqrt\n    self._kwargs = kwargs\n    if self.data_format == \"channels_last\":\n        self.axes = [1, 2]\n    else:\n        self.axes = [2, 3]\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledL2NormPooling2D","title":"<code>ScaledL2NormPooling2D</code>","text":"<p>         Bases: <code>keraslayers.AveragePooling2D</code>, <code>LipschitzLayer</code></p> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"ScaledL2NormPooling2D\")\nclass ScaledL2NormPooling2D(keraslayers.AveragePooling2D, LipschitzLayer):\n    def __init__(\n        self,\n        pool_size=(2, 2),\n        strides=None,\n        padding=\"valid\",\n        data_format=None,\n        k_coef_lip=1.0,\n        eps_grad_sqrt=1e-6,\n        **kwargs\n    ):\n\"\"\"\n        Average pooling operation for spatial data, with a lipschitz bound. This\n        pooling operation is norm preserving (aka gradient=1 almost everywhere).\n\n        [1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature\n        Pooling in Visual Recognition \u00bb,p.8.\n\n        Arguments:\n            pool_size: integer or tuple of 2 integers,\n                factors by which to downscale (vertical, horizontal).\n                `(2, 2)` will halve the input in both spatial dimension.\n                If only one integer is specified, the same window length\n                will be used for both dimensions.\n            strides: Integer, tuple of 2 integers, or None.\n                Strides values.\n                If None, it will default to `pool_size`.\n            padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n            data_format: A string,\n                one of `channels_last` (default) or `channels_first`.\n                The ordering of the dimensions in the inputs.\n                `channels_last` corresponds to inputs with shape\n                `(batch, height, width, channels)` while `channels_first`\n                corresponds to inputs with shape\n                `(batch, channels, height, width)`.\n                It defaults to the `image_data_format` value found in your\n                Keras config file at `~/.keras/keras.json`.\n                If you never set it, then it will be \"channels_last\".\n            k_coef_lip: the lipschitz factor to ensure\n            eps_grad_sqrt: Epsilon value to avoid numerical instability\n                due to non-defined gradient at 0 in the sqrt function\n\n        Input shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, rows, cols, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n        Output shape:\n            - If `data_format='channels_last'`:\n                4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n            - If `data_format='channels_first'`:\n                4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n        \"\"\"\n        if not ((strides == pool_size) or (strides is None)):\n            raise RuntimeError(\"stride must be equal to pool_size\")\n        if padding != \"valid\":\n            raise RuntimeError(\"ScaledL2NormPooling2D only supports padding='valid'\")\n        if eps_grad_sqrt &lt; 0.0:\n            raise RuntimeError(\"eps_grad_sqrt must be positive\")\n        super(ScaledL2NormPooling2D, self).__init__(\n            pool_size=pool_size,\n            strides=pool_size,\n            padding=padding,\n            data_format=data_format,\n            **kwargs\n        )\n        self.set_klip_factor(k_coef_lip)\n        self.eps_grad_sqrt = eps_grad_sqrt\n        self._kwargs = kwargs\n\n    def build(self, input_shape):\n        super(ScaledL2NormPooling2D, self).build(input_shape)\n        self._init_lip_coef(input_shape)\n        self.built = True\n\n    def _compute_lip_coef(self, input_shape=None):\n        return np.sqrt(np.prod(np.asarray(self.pool_size)))\n\n    @staticmethod\n    def _sqrt(eps_grad_sqrt):\n        @tf.custom_gradient\n        def sqrt_op(x):\n            sqrtx = tf.sqrt(x)\n\n            def grad(dy):\n                return dy / (2 * (sqrtx + eps_grad_sqrt))\n\n            return sqrtx, grad\n\n        return sqrt_op\n\n    def call(self, x, training=True):\n        return (\n            ScaledL2NormPooling2D._sqrt(self.eps_grad_sqrt)(\n                super(ScaledL2NormPooling2D, self).call(tf.square(x))\n            )\n            * self._get_coef()\n        )\n\n    def get_config(self):\n        config = {\n            \"k_coef_lip\": self.k_coef_lip,\n        }\n        base_config = super(ScaledL2NormPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.pooling.ScaledL2NormPooling2D.__init__","title":"<code>__init__(pool_size=(2, 2), strides=None, padding='valid', data_format=None, k_coef_lip=1.0, eps_grad_sqrt=1e-06, **kwargs)</code>","text":"<p>Average pooling operation for spatial data, with a lipschitz bound. This pooling operation is norm preserving (aka gradient=1 almost everywhere).</p> <p>[1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature Pooling in Visual Recognition \u00bb,p.8.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <p>integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). <code>(2, 2)</code> will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.</p> <code>(2, 2)</code> <code>strides</code> <p>Integer, tuple of 2 integers, or None. Strides values. If None, it will default to <code>pool_size</code>.</p> <code>None</code> <code>padding</code> <p>One of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</p> <code>'valid'</code> <code>data_format</code> <p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>. The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds to inputs with shape <code>(batch, height, width, channels)</code> while <code>channels_first</code> corresponds to inputs with shape <code>(batch, channels, height, width)</code>. It defaults to the <code>image_data_format</code> value found in your Keras config file at <code>~/.keras/keras.json</code>. If you never set it, then it will be \"channels_last\".</p> <code>None</code> <code>k_coef_lip</code> <p>the lipschitz factor to ensure</p> <code>1.0</code> <code>eps_grad_sqrt</code> <p>Epsilon value to avoid numerical instability due to non-defined gradient at 0 in the sqrt function</p> <code>1e-06</code> Input shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, rows, cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, rows, cols)</code>.</li> </ul> Output shape <ul> <li>If <code>data_format='channels_last'</code>:     4D tensor with shape <code>(batch_size, pooled_rows, pooled_cols, channels)</code>.</li> <li>If <code>data_format='channels_first'</code>:     4D tensor with shape <code>(batch_size, channels, pooled_rows, pooled_cols)</code>.</li> </ul> Source code in <code>deel/lip/layers/pooling.py</code> <pre><code>def __init__(\n    self,\n    pool_size=(2, 2),\n    strides=None,\n    padding=\"valid\",\n    data_format=None,\n    k_coef_lip=1.0,\n    eps_grad_sqrt=1e-6,\n    **kwargs\n):\n\"\"\"\n    Average pooling operation for spatial data, with a lipschitz bound. This\n    pooling operation is norm preserving (aka gradient=1 almost everywhere).\n\n    [1]Y.-L.Boureau, J.Ponce, et Y.LeCun, \u00ab A Theoretical Analysis of Feature\n    Pooling in Visual Recognition \u00bb,p.8.\n\n    Arguments:\n        pool_size: integer or tuple of 2 integers,\n            factors by which to downscale (vertical, horizontal).\n            `(2, 2)` will halve the input in both spatial dimension.\n            If only one integer is specified, the same window length\n            will be used for both dimensions.\n        strides: Integer, tuple of 2 integers, or None.\n            Strides values.\n            If None, it will default to `pool_size`.\n        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, height, width, channels)` while `channels_first`\n            corresponds to inputs with shape\n            `(batch, channels, height, width)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be \"channels_last\".\n        k_coef_lip: the lipschitz factor to ensure\n        eps_grad_sqrt: Epsilon value to avoid numerical instability\n            due to non-defined gradient at 0 in the sqrt function\n\n    Input shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, rows, cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, rows, cols)`.\n\n    Output shape:\n        - If `data_format='channels_last'`:\n            4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n        - If `data_format='channels_first'`:\n            4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n    \"\"\"\n    if not ((strides == pool_size) or (strides is None)):\n        raise RuntimeError(\"stride must be equal to pool_size\")\n    if padding != \"valid\":\n        raise RuntimeError(\"ScaledL2NormPooling2D only supports padding='valid'\")\n    if eps_grad_sqrt &lt; 0.0:\n        raise RuntimeError(\"eps_grad_sqrt must be positive\")\n    super(ScaledL2NormPooling2D, self).__init__(\n        pool_size=pool_size,\n        strides=pool_size,\n        padding=padding,\n        data_format=data_format,\n        **kwargs\n    )\n    self.set_klip_factor(k_coef_lip)\n    self.eps_grad_sqrt = eps_grad_sqrt\n    self._kwargs = kwargs\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.unconstrained","title":"<code>unconstrained</code>","text":""},{"location":"api/layers/#deel.lip.layers.unconstrained.PadConv2D","title":"<code>PadConv2D</code>","text":"<p>         Bases: <code>tf.keras.layers.Conv2D</code>, <code>Condensable</code></p> Source code in <code>deel/lip/layers/unconstrained.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"PadConv2D\")\nclass PadConv2D(tf.keras.layers.Conv2D, Condensable):\n    def __init__(\n        self,\n        filters,\n        kernel_size,\n        strides=(1, 1),\n        padding=\"same\",\n        data_format=None,\n        dilation_rate=(1, 1),\n        activation=None,\n        use_bias=True,\n        kernel_initializer=\"glorot_uniform\",\n        bias_initializer=\"zeros\",\n        kernel_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        bias_constraint=None,\n        **kwargs\n    ):\n\"\"\"\n        This class is a Conv2D Layer with parameterized padding.\n        Since Conv2D layer only supports `\"same\"` and `\"valid\"` padding, this layer will\n        enable other type of padding, such as `\"constant\"`, `\"symmetric\"`, `\"reflect\"`\n        or `\"circular\"`.\n\n        Warning:\n            The PadConv2D is not a Lipschitz layer and must not be directly used. This\n            must be used as a base class to create a Lipschitz layer with padding.\n\n        All arguments are the same as the original `Conv2D` except the `padding`\n        which is defined as following:\n\n        Args:\n            padding: one of `\"same\"`, `\"valid\"` `\"constant\"`, `\"symmetric\"`,\n                `\"reflect\"` or `\"circular\"` (case-insensitive).\n        \"\"\"\n        self.pad = lambda x: x\n        self.old_padding = padding\n        self.internal_input_shape = None\n        if padding.lower() != \"same\":  # same is directly processed in Conv2D\n            padding = \"valid\"\n        super(PadConv2D, self).__init__(\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs\n        )\n        self._kwargs = kwargs\n        if self.old_padding.lower() in [\"same\", \"valid\"]:\n            self.pad = lambda x: x\n            self.padding_size = [0, 0]\n        if self.old_padding.lower() in [\"constant\", \"reflect\", \"symmetric\"]:\n            self.padding_size = [self.kernel_size[0] // 2, self.kernel_size[1] // 2]\n            paddings = [\n                [0, 0],\n                [self.padding_size[0], self.padding_size[0]],\n                [self.padding_size[1], self.padding_size[1]],\n                [0, 0],\n            ]\n            self.pad = lambda t: tf.pad(t, paddings, self.old_padding)\n        if self.old_padding.lower() == \"circular\":\n            self.padding_size = [self.kernel_size[0] // 2, self.kernel_size[1] // 2]\n            self.pad = lambda t: _padding_circular(t, self.padding_size)\n\n    def compute_padded_shape(self, input_shape, padding_size):\n        if isinstance(input_shape, tf.TensorShape):\n            internal_input_shape = input_shape.as_list()\n        else:\n            internal_input_shape = list(input_shape)\n\n        first_spatial_dim = 1 if self.data_format == \"channels_last\" else 2\n        for index, pad in enumerate(padding_size):\n            internal_input_shape[first_spatial_dim + index] += 2 * pad\n        return tf.TensorShape(internal_input_shape)\n\n    def build(self, input_shape):\n        self.internal_input_shape = self.compute_padded_shape(\n            input_shape, self.padding_size\n        )\n        super(PadConv2D, self).build(self.internal_input_shape)\n\n    def compute_output_shape(self, input_shape):\n        return super(PadConv2D, self).compute_output_shape(self.internal_input_shape)\n\n    def call(self, x):\n        x = self.pad(x)\n        return super(PadConv2D, self).call(x)\n\n    def get_config(self):\n        base_config = super(PadConv2D, self).get_config()\n        base_config[\"padding\"] = self.old_padding\n        return base_config\n\n    def condense(self):\n        return\n\n    def vanilla_export(self):\n        self._kwargs[\"name\"] = self.name\n        if self.old_padding.lower() in [\"same\", \"valid\"]:\n            layer_type = tf.keras.layers.Conv2D\n        else:\n            layer_type = PadConv2D\n        layer = layer_type(\n            filters=self.filters,\n            kernel_size=self.kernel_size,\n            strides=self.strides,\n            padding=self.old_padding,\n            data_format=self.data_format,\n            dilation_rate=self.dilation_rate,\n            activation=self.activation,\n            use_bias=self.use_bias,\n            kernel_initializer=\"glorot_uniform\",\n            bias_initializer=\"zeros\",\n            **self._kwargs\n        )\n        layer.build(self.input_shape)\n        layer.kernel.assign(self.kernel)\n        if self.use_bias:\n            layer.bias.assign(self.bias)\n        return layer\n</code></pre>"},{"location":"api/layers/#deel.lip.layers.unconstrained.PadConv2D.__init__","title":"<code>__init__(filters, kernel_size, strides=(1, 1), padding='same', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)</code>","text":"<p>This class is a Conv2D Layer with parameterized padding. Since Conv2D layer only supports <code>\"same\"</code> and <code>\"valid\"</code> padding, this layer will enable other type of padding, such as <code>\"constant\"</code>, <code>\"symmetric\"</code>, <code>\"reflect\"</code> or <code>\"circular\"</code>.</p> Warning <p>The PadConv2D is not a Lipschitz layer and must not be directly used. This must be used as a base class to create a Lipschitz layer with padding.</p> <p>All arguments are the same as the original <code>Conv2D</code> except the <code>padding</code> which is defined as following:</p> <p>Parameters:</p> Name Type Description Default <code>padding</code> <p>one of <code>\"same\"</code>, <code>\"valid\"</code> <code>\"constant\"</code>, <code>\"symmetric\"</code>, <code>\"reflect\"</code> or <code>\"circular\"</code> (case-insensitive).</p> <code>'same'</code> Source code in <code>deel/lip/layers/unconstrained.py</code> <pre><code>def __init__(\n    self,\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"same\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n):\n\"\"\"\n    This class is a Conv2D Layer with parameterized padding.\n    Since Conv2D layer only supports `\"same\"` and `\"valid\"` padding, this layer will\n    enable other type of padding, such as `\"constant\"`, `\"symmetric\"`, `\"reflect\"`\n    or `\"circular\"`.\n\n    Warning:\n        The PadConv2D is not a Lipschitz layer and must not be directly used. This\n        must be used as a base class to create a Lipschitz layer with padding.\n\n    All arguments are the same as the original `Conv2D` except the `padding`\n    which is defined as following:\n\n    Args:\n        padding: one of `\"same\"`, `\"valid\"` `\"constant\"`, `\"symmetric\"`,\n            `\"reflect\"` or `\"circular\"` (case-insensitive).\n    \"\"\"\n    self.pad = lambda x: x\n    self.old_padding = padding\n    self.internal_input_shape = None\n    if padding.lower() != \"same\":  # same is directly processed in Conv2D\n        padding = \"valid\"\n    super(PadConv2D, self).__init__(\n        filters=filters,\n        kernel_size=kernel_size,\n        strides=strides,\n        padding=padding,\n        data_format=data_format,\n        dilation_rate=dilation_rate,\n        activation=activation,\n        use_bias=use_bias,\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer,\n        kernel_regularizer=kernel_regularizer,\n        bias_regularizer=bias_regularizer,\n        activity_regularizer=activity_regularizer,\n        kernel_constraint=kernel_constraint,\n        bias_constraint=bias_constraint,\n        **kwargs\n    )\n    self._kwargs = kwargs\n    if self.old_padding.lower() in [\"same\", \"valid\"]:\n        self.pad = lambda x: x\n        self.padding_size = [0, 0]\n    if self.old_padding.lower() in [\"constant\", \"reflect\", \"symmetric\"]:\n        self.padding_size = [self.kernel_size[0] // 2, self.kernel_size[1] // 2]\n        paddings = [\n            [0, 0],\n            [self.padding_size[0], self.padding_size[0]],\n            [self.padding_size[1], self.padding_size[1]],\n            [0, 0],\n        ]\n        self.pad = lambda t: tf.pad(t, paddings, self.old_padding)\n    if self.old_padding.lower() == \"circular\":\n        self.padding_size = [self.kernel_size[0] // 2, self.kernel_size[1] // 2]\n        self.pad = lambda t: _padding_circular(t, self.padding_size)\n</code></pre>"},{"location":"api/losses/","title":"deel.lip.losses","text":"<p>This module contains losses used in Wasserstein distance estimation. See this paper for more information.</p>"},{"location":"api/losses/#deel.lip.losses.CategoricalHinge","title":"<code>CategoricalHinge</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"CategoricalHinge\")\nclass CategoricalHinge(Loss):\n    def __init__(self, min_margin, reduction=Reduction.AUTO, name=\"CategoricalHinge\"):\n\"\"\"\n        Similar to original categorical hinge, but with a settable margin parameter.\n        This implementation is sligthly different from the Keras one.\n\n        `y_true` and `y_pred` must be of shape (batch_size, # classes).\n        Note that `y_true` should be one-hot encoded or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            min_margin (float): margin parameter.\n            reduction: reduction of the loss, passed to original loss.\n            name (str): name of the loss\n        \"\"\"\n        self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n        super(CategoricalHinge, self).__init__(name=name, reduction=reduction)\n\n    def call(self, y_true, y_pred):\n        mask = tf.where(y_true &gt; 0, 1, 0)\n        mask = tf.cast(mask, y_pred.dtype)\n        pos = tf.reduce_sum(mask * y_pred, axis=-1)\n        neg = tf.reduce_max(tf.where(mask &gt; 0, tf.float32.min, y_pred), axis=-1)\n        return tf.nn.relu(self.min_margin - (pos - neg))\n\n    def get_config(self):\n        config = {\"min_margin\": self.min_margin.numpy()}\n        base_config = super(CategoricalHinge, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.CategoricalHinge.__init__","title":"<code>__init__(min_margin, reduction=Reduction.AUTO, name='CategoricalHinge')</code>","text":"<p>Similar to original categorical hinge, but with a settable margin parameter. This implementation is sligthly different from the Keras one.</p> <p><code>y_true</code> and <code>y_pred</code> must be of shape (batch_size, # classes). Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>min_margin</code> <code>float</code> <p>margin parameter.</p> required <code>reduction</code> <p>reduction of the loss, passed to original loss.</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>name of the loss</p> <code>'CategoricalHinge'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, min_margin, reduction=Reduction.AUTO, name=\"CategoricalHinge\"):\n\"\"\"\n    Similar to original categorical hinge, but with a settable margin parameter.\n    This implementation is sligthly different from the Keras one.\n\n    `y_true` and `y_pred` must be of shape (batch_size, # classes).\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin parameter.\n        reduction: reduction of the loss, passed to original loss.\n        name (str): name of the loss\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(CategoricalHinge, self).__init__(name=name, reduction=reduction)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.HKR","title":"<code>HKR</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"HKR\")\nclass HKR(Loss):\n    def __init__(\n        self,\n        alpha,\n        min_margin=1.0,\n        multi_gpu=False,\n        reduction=Reduction.AUTO,\n        name=\"HKR\",\n    ):\nr\"\"\"\n        Wasserstein loss with a regularization parameter based on the hinge margin loss.\n\n        $$\n        \\inf_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim P_-}{\\mathbb{E}}\n        \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim P_+}\n        {\\mathbb{E}} \\left[f(\\textbf{x} )\\right] + \\alpha\n        \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin}\n        -Yf(\\textbf{x})\\right)_+\n        $$\n\n        Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n        (batch_size, C) for multilabel classification (with C categories).\n        `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n        pre-process the labels `y_true` with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            alpha (float): regularization factor\n            min_margin (float): minimal margin ( see hinge_margin_loss )\n                Kantorovich-Rubinstein term of the loss. In order to be consistent\n                between hinge and KR, the first label must yield the positive class\n                while the second yields negative class.\n            multi_gpu (bool): set to True when running on multi-GPU/TPU\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.alpha = tf.Variable(alpha, dtype=tf.float32)\n        self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n        self.multi_gpu = multi_gpu\n        self.KRloss = KR(multi_gpu=multi_gpu)\n        if alpha == np.inf:  # alpha = inf =&gt; hinge only\n            self.fct = partial(hinge_margin, min_margin=self.min_margin)\n        else:\n            self.fct = self.hkr\n        super(HKR, self).__init__(reduction=reduction, name=name)\n\n    @tf.function\n    def hkr(self, y_true, y_pred):\n        a = -self.KRloss.call(y_true, y_pred)\n        b = hinge_margin(y_true, y_pred, self.min_margin)\n        return a + self.alpha * b\n\n    def call(self, y_true, y_pred):\n        return self.fct(y_true, y_pred)\n\n    def get_config(self):\n        config = {\n            \"alpha\": self.alpha.numpy(),\n            \"min_margin\": self.min_margin.numpy(),\n            \"multi_gpu\": self.multi_gpu,\n        }\n        base_config = super(HKR, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.HKR.__init__","title":"<code>__init__(alpha, min_margin=1.0, multi_gpu=False, reduction=Reduction.AUTO, name='HKR')</code>","text":"<p>Wasserstein loss with a regularization parameter based on the hinge margin loss.</p> \\[ \\inf_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim P_-}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim P_+} {\\mathbb{E}} \\left[f(\\textbf{x} )\\right] + \\alpha \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin} -Yf(\\textbf{x})\\right)_+ \\] <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>regularization factor</p> required <code>min_margin</code> <code>float</code> <p>minimal margin ( see hinge_margin_loss ) Kantorovich-Rubinstein term of the loss. In order to be consistent between hinge and KR, the first label must yield the positive class while the second yields negative class.</p> <code>1.0</code> <code>multi_gpu</code> <code>bool</code> <p>set to True when running on multi-GPU/TPU</p> <code>False</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'HKR'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self,\n    alpha,\n    min_margin=1.0,\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"HKR\",\n):\nr\"\"\"\n    Wasserstein loss with a regularization parameter based on the hinge margin loss.\n\n    $$\n    \\inf_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim P_-}{\\mathbb{E}}\n    \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim P_+}\n    {\\mathbb{E}} \\left[f(\\textbf{x} )\\right] + \\alpha\n    \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin}\n    -Yf(\\textbf{x})\\right)_+\n    $$\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        alpha (float): regularization factor\n        min_margin (float): minimal margin ( see hinge_margin_loss )\n            Kantorovich-Rubinstein term of the loss. In order to be consistent\n            between hinge and KR, the first label must yield the positive class\n            while the second yields negative class.\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.alpha = tf.Variable(alpha, dtype=tf.float32)\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    self.multi_gpu = multi_gpu\n    self.KRloss = KR(multi_gpu=multi_gpu)\n    if alpha == np.inf:  # alpha = inf =&gt; hinge only\n        self.fct = partial(hinge_margin, min_margin=self.min_margin)\n    else:\n        self.fct = self.hkr\n    super(HKR, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.HingeMargin","title":"<code>HingeMargin</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"HingeMargin\")\nclass HingeMargin(Loss):\n    def __init__(self, min_margin=1.0, reduction=Reduction.AUTO, name=\"HingeMargin\"):\nr\"\"\"\n        Compute the hinge margin loss.\n\n        $$\n        \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin}\n        -Yf(\\textbf{x})\\right)_+\n        $$\n\n        Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n        (batch_size, C) for multilabel classification (with C categories).\n        `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            min_margin (float): margin to enforce.\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n        super(HingeMargin, self).__init__(reduction=reduction, name=name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return hinge_margin(y_true, y_pred, self.min_margin)\n\n    def get_config(self):\n        config = {\n            \"min_margin\": self.min_margin.numpy(),\n        }\n        base_config = super(HingeMargin, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.HingeMargin.__init__","title":"<code>__init__(min_margin=1.0, reduction=Reduction.AUTO, name='HingeMargin')</code>","text":"<p>Compute the hinge margin loss.</p> \\[ \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin} -Yf(\\textbf{x})\\right)_+ \\] <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>min_margin</code> <code>float</code> <p>margin to enforce.</p> <code>1.0</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'HingeMargin'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, min_margin=1.0, reduction=Reduction.AUTO, name=\"HingeMargin\"):\nr\"\"\"\n    Compute the hinge margin loss.\n\n    $$\n    \\underset{\\textbf{x}}{\\mathbb{E}} \\left(\\text{min_margin}\n    -Yf(\\textbf{x})\\right)_+\n    $$\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(HingeMargin, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.KR","title":"<code>KR</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"KR\")\nclass KR(Loss):\n    def __init__(self, multi_gpu=False, reduction=Reduction.AUTO, name=\"KR\"):\nr\"\"\"\n        Loss to estimate Wasserstein-1 distance using Kantorovich-Rubinstein duality.\n        The Kantorovich-Rubinstein duality is formulated as following:\n\n        $$\n        W_1(\\mu, \\nu) =\n        \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}}\n        \\left[f(\\textbf{x} )\\right] -\n        \\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right]\n        $$\n\n        Where mu and nu stands for the two distributions, the distribution where the\n        label is 1 and the rest.\n\n        Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n        (batch_size, C) for multilabel classification (with C categories).\n        `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n        pre-process the labels `y_true` with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            multi_gpu (bool): set to True when running on multi-GPU/TPU\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.eps = 1e-7\n        self.multi_gpu = multi_gpu\n        super(KR, self).__init__(reduction=reduction, name=name)\n        if multi_gpu:\n            self.kr_function = _kr_multi_gpu\n        else:\n            self.kr_function = partial(_kr, epsilon=self.eps)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return self.kr_function(y_true, y_pred)\n\n    def get_config(self):\n        config = {\"multi_gpu\": self.multi_gpu}\n        base_config = super(KR, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.KR.__init__","title":"<code>__init__(multi_gpu=False, reduction=Reduction.AUTO, name='KR')</code>","text":"<p>Loss to estimate Wasserstein-1 distance using Kantorovich-Rubinstein duality. The Kantorovich-Rubinstein duality is formulated as following:</p> \\[ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] - \\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] \\] <p>Where mu and nu stands for the two distributions, the distribution where the label is 1 and the rest.</p> <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>multi_gpu</code> <code>bool</code> <p>set to True when running on multi-GPU/TPU</p> <code>False</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'KR'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, multi_gpu=False, reduction=Reduction.AUTO, name=\"KR\"):\nr\"\"\"\n    Loss to estimate Wasserstein-1 distance using Kantorovich-Rubinstein duality.\n    The Kantorovich-Rubinstein duality is formulated as following:\n\n    $$\n    W_1(\\mu, \\nu) =\n    \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}}\n    \\left[f(\\textbf{x} )\\right] -\n    \\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right]\n    $$\n\n    Where mu and nu stands for the two distributions, the distribution where the\n    label is 1 and the rest.\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.eps = 1e-7\n    self.multi_gpu = multi_gpu\n    super(KR, self).__init__(reduction=reduction, name=name)\n    if multi_gpu:\n        self.kr_function = _kr_multi_gpu\n    else:\n        self.kr_function = partial(_kr, epsilon=self.eps)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MultiMargin","title":"<code>MultiMargin</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"MultiMargin\")\nclass MultiMargin(Loss):\n    def __init__(self, min_margin=1.0, reduction=Reduction.AUTO, name=\"MultiMargin\"):\n\"\"\"\n        Compute the hinge margin loss for multiclass (equivalent to Pytorch\n        multi_margin_loss)\n\n        Note that `y_true` should be one-hot encoded or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            min_margin (float): margin to enforce.\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n        super(MultiMargin, self).__init__(reduction=reduction, name=name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        mask = tf.where(y_true &gt; 0, 1, 0)\n        mask = tf.cast(mask, y_pred.dtype)\n        # get the y_pred[target_class]\n        # (zeroing out all elements of y_pred where y_true=0)\n        vYtrue = tf.reduce_sum(y_pred * mask, axis=-1, keepdims=True)\n        # computing elementwise margin term : margin + y_pred[i]-y_pred[target_class]\n        margin = tf.nn.relu(self.min_margin - vYtrue + y_pred)\n        # averaging on all outputs and batch\n        final_loss = tf.reduce_mean((1.0 - mask) * margin, axis=-1)\n        return final_loss\n\n    def get_config(self):\n        config = {\n            \"min_margin\": self.min_margin.numpy(),\n        }\n        base_config = super(MultiMargin, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MultiMargin.__init__","title":"<code>__init__(min_margin=1.0, reduction=Reduction.AUTO, name='MultiMargin')</code>","text":"<p>Compute the hinge margin loss for multiclass (equivalent to Pytorch multi_margin_loss)</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>min_margin</code> <code>float</code> <p>margin to enforce.</p> <code>1.0</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'MultiMargin'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, min_margin=1.0, reduction=Reduction.AUTO, name=\"MultiMargin\"):\n\"\"\"\n    Compute the hinge margin loss for multiclass (equivalent to Pytorch\n    multi_margin_loss)\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(MultiMargin, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassHKR","title":"<code>MulticlassHKR</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"MulticlassHKR\")\nclass MulticlassHKR(Loss):\n    def __init__(\n        self,\n        alpha=10.0,\n        min_margin=1.0,\n        multi_gpu=False,\n        reduction=Reduction.AUTO,\n        name=\"MulticlassHKR\",\n    ):\n\"\"\"\n        The multiclass version of HKR. This is done by computing the HKR term over each\n        class and averaging the results.\n\n        Note that `y_true` should be one-hot encoded or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n        pre-process the labels `y_true` with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            alpha (float): regularization factor\n            min_margin (float): margin to enforce.\n            multi_gpu (bool): set to True when running on multi-GPU/TPU\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.alpha = tf.Variable(alpha, dtype=tf.float32)\n        self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n        self.multi_gpu = multi_gpu\n        self.KRloss = MulticlassKR(multi_gpu=multi_gpu, reduction=reduction, name=name)\n        if alpha == np.inf:  # alpha = inf =&gt; hinge only\n            self.fct = partial(multiclass_hinge, min_margin=self.min_margin)\n        else:\n            self.fct = self.hkr\n        super(MulticlassHKR, self).__init__(reduction=reduction, name=name)\n\n    @tf.function\n    def hkr(self, y_true, y_pred):\n        a = -self.KRloss.call(y_true, y_pred)\n        b = multiclass_hinge(y_true, y_pred, self.min_margin)\n        return a + self.alpha * b\n\n    def call(self, y_true, y_pred):\n        return self.fct(y_true, y_pred)\n\n    def get_config(self):\n        config = {\n            \"alpha\": self.alpha.numpy(),\n            \"min_margin\": self.min_margin.numpy(),\n            \"multi_gpu\": self.multi_gpu,\n        }\n        base_config = super(MulticlassHKR, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassHKR.__init__","title":"<code>__init__(alpha=10.0, min_margin=1.0, multi_gpu=False, reduction=Reduction.AUTO, name='MulticlassHKR')</code>","text":"<p>The multiclass version of HKR. This is done by computing the HKR term over each class and averaging the results.</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>regularization factor</p> <code>10.0</code> <code>min_margin</code> <code>float</code> <p>margin to enforce.</p> <code>1.0</code> <code>multi_gpu</code> <code>bool</code> <p>set to True when running on multi-GPU/TPU</p> <code>False</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'MulticlassHKR'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self,\n    alpha=10.0,\n    min_margin=1.0,\n    multi_gpu=False,\n    reduction=Reduction.AUTO,\n    name=\"MulticlassHKR\",\n):\n\"\"\"\n    The multiclass version of HKR. This is done by computing the HKR term over each\n    class and averaging the results.\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        alpha (float): regularization factor\n        min_margin (float): margin to enforce.\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.alpha = tf.Variable(alpha, dtype=tf.float32)\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    self.multi_gpu = multi_gpu\n    self.KRloss = MulticlassKR(multi_gpu=multi_gpu, reduction=reduction, name=name)\n    if alpha == np.inf:  # alpha = inf =&gt; hinge only\n        self.fct = partial(multiclass_hinge, min_margin=self.min_margin)\n    else:\n        self.fct = self.hkr\n    super(MulticlassHKR, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassHinge","title":"<code>MulticlassHinge</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"MulticlassHinge\")\nclass MulticlassHinge(Loss):\n    def __init__(\n        self, min_margin=1.0, reduction=Reduction.AUTO, name=\"MulticlassHinge\"\n    ):\n\"\"\"\n        Loss to estimate the Hinge loss in a multiclass setup. It computes the\n        element-wise Hinge term. Note that this formulation differs from the one\n        commonly found in tensorflow/pytorch (which maximises the difference between\n        the two largest logits). This formulation is consistent with the binary\n        classification loss used in a multiclass fashion.\n\n        Note that `y_true` should be one-hot encoded or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            min_margin (float): margin to enforce.\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n        super(MulticlassHinge, self).__init__(reduction=reduction, name=name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return multiclass_hinge(y_true, y_pred, self.min_margin)\n\n    def get_config(self):\n        config = {\n            \"min_margin\": self.min_margin.numpy(),\n        }\n        base_config = super(MulticlassHinge, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassHinge.__init__","title":"<code>__init__(min_margin=1.0, reduction=Reduction.AUTO, name='MulticlassHinge')</code>","text":"<p>Loss to estimate the Hinge loss in a multiclass setup. It computes the element-wise Hinge term. Note that this formulation differs from the one commonly found in tensorflow/pytorch (which maximises the difference between the two largest logits). This formulation is consistent with the binary classification loss used in a multiclass fashion.</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>min_margin</code> <code>float</code> <p>margin to enforce.</p> <code>1.0</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'MulticlassHinge'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self, min_margin=1.0, reduction=Reduction.AUTO, name=\"MulticlassHinge\"\n):\n\"\"\"\n    Loss to estimate the Hinge loss in a multiclass setup. It computes the\n    element-wise Hinge term. Note that this formulation differs from the one\n    commonly found in tensorflow/pytorch (which maximises the difference between\n    the two largest logits). This formulation is consistent with the binary\n    classification loss used in a multiclass fashion.\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.min_margin = tf.Variable(min_margin, dtype=tf.float32)\n    super(MulticlassHinge, self).__init__(reduction=reduction, name=name)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassKR","title":"<code>MulticlassKR</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"MulticlassKR\")\nclass MulticlassKR(Loss):\n    def __init__(self, multi_gpu=False, reduction=Reduction.AUTO, name=\"MulticlassKR\"):\nr\"\"\"\n        Loss to estimate average of Wasserstein-1 distance using Kantorovich-Rubinstein\n        duality over outputs. In this multiclass setup, the KR term is computed for each\n        class and then averaged.\n\n        Note that `y_true` should be one-hot encoded or pre-processed with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n        pre-process the labels `y_true` with the\n        `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n        Args:\n            multi_gpu (bool): set to True when running on multi-GPU/TPU\n            reduction: passed to tf.keras.Loss constructor\n            name (str): passed to tf.keras.Loss constructor\n\n        \"\"\"\n        self.eps = 1e-7\n        self.multi_gpu = multi_gpu\n        super(MulticlassKR, self).__init__(reduction=reduction, name=name)\n        if multi_gpu:\n            self.kr_function = _kr_multi_gpu\n        else:\n            self.kr_function = partial(_kr, epsilon=self.eps)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return self.kr_function(y_true, y_pred)\n\n    def get_config(self):\n        config = {\"multi_gpu\": self.multi_gpu}\n        base_config = super(MulticlassKR, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.MulticlassKR.__init__","title":"<code>__init__(multi_gpu=False, reduction=Reduction.AUTO, name='MulticlassKR')</code>","text":"<p>Loss to estimate average of Wasserstein-1 distance using Kantorovich-Rubinstein duality over outputs. In this multiclass setup, the KR term is computed for each class and then averaged.</p> <p>Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Using a multi-GPU/TPU strategy requires to set <code>multi_gpu</code> to True and to pre-process the labels <code>y_true</code> with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>multi_gpu</code> <code>bool</code> <p>set to True when running on multi-GPU/TPU</p> <code>False</code> <code>reduction</code> <p>passed to tf.keras.Loss constructor</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>passed to tf.keras.Loss constructor</p> <code>'MulticlassKR'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(self, multi_gpu=False, reduction=Reduction.AUTO, name=\"MulticlassKR\"):\nr\"\"\"\n    Loss to estimate average of Wasserstein-1 distance using Kantorovich-Rubinstein\n    duality over outputs. In this multiclass setup, the KR term is computed for each\n    class and then averaged.\n\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Using a multi-GPU/TPU strategy requires to set `multi_gpu` to True and to\n    pre-process the labels `y_true` with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        multi_gpu (bool): set to True when running on multi-GPU/TPU\n        reduction: passed to tf.keras.Loss constructor\n        name (str): passed to tf.keras.Loss constructor\n\n    \"\"\"\n    self.eps = 1e-7\n    self.multi_gpu = multi_gpu\n    super(MulticlassKR, self).__init__(reduction=reduction, name=name)\n    if multi_gpu:\n        self.kr_function = _kr_multi_gpu\n    else:\n        self.kr_function = partial(_kr, epsilon=self.eps)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.TauCategoricalCrossentropy","title":"<code>TauCategoricalCrossentropy</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/losses.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"TauCategoricalCrossentropy\")\nclass TauCategoricalCrossentropy(Loss):\n    def __init__(\n        self, tau, reduction=Reduction.AUTO, name=\"TauCategoricalCrossentropy\"\n    ):\n\"\"\"\n        Similar to original categorical crossentropy, but with a settable temperature\n        parameter.\n\n        Args:\n            tau (float): temperature parameter.\n            reduction: reduction of the loss, passed to original loss.\n            name (str): name of the loss\n        \"\"\"\n        self.tau = tf.Variable(tau, dtype=tf.float32)\n        super(TauCategoricalCrossentropy, self).__init__(name=name, reduction=reduction)\n\n    def call(self, y_true, y_pred, *args, **kwargs):\n        return (\n            categorical_crossentropy(\n                y_true, self.tau * y_pred, from_logits=True, *args, **kwargs\n            )\n            / self.tau\n        )\n\n    def get_config(self):\n        config = {\"tau\": self.tau.numpy()}\n        base_config = super(TauCategoricalCrossentropy, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.TauCategoricalCrossentropy.__init__","title":"<code>__init__(tau, reduction=Reduction.AUTO, name='TauCategoricalCrossentropy')</code>","text":"<p>Similar to original categorical crossentropy, but with a settable temperature parameter.</p> <p>Parameters:</p> Name Type Description Default <code>tau</code> <code>float</code> <p>temperature parameter.</p> required <code>reduction</code> <p>reduction of the loss, passed to original loss.</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>name of the loss</p> <code>'TauCategoricalCrossentropy'</code> Source code in <code>deel/lip/losses.py</code> <pre><code>def __init__(\n    self, tau, reduction=Reduction.AUTO, name=\"TauCategoricalCrossentropy\"\n):\n\"\"\"\n    Similar to original categorical crossentropy, but with a settable temperature\n    parameter.\n\n    Args:\n        tau (float): temperature parameter.\n        reduction: reduction of the loss, passed to original loss.\n        name (str): name of the loss\n    \"\"\"\n    self.tau = tf.Variable(tau, dtype=tf.float32)\n    super(TauCategoricalCrossentropy, self).__init__(name=name, reduction=reduction)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.hinge_margin","title":"<code>hinge_margin(y_true, y_pred, min_margin)</code>","text":"<p>Compute the element-wise binary hinge margin loss.</p> <p>Note that <code>y_true</code> and <code>y_pred</code> must be of rank 2: (batch_size, 1) or (batch_size, C) for multilabel classification (with C categories). <code>y_true</code> accepts label values in (0, 1), (-1, 1), or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>min_margin</code> <code>float</code> <p>margin to enforce.</p> required <p>Returns:</p> Type Description <p>tf.Tensor: Element-wise hinge margin loss value.</p> Source code in <code>deel/lip/losses.py</code> <pre><code>def hinge_margin(y_true, y_pred, min_margin):\n\"\"\"Compute the element-wise binary hinge margin loss.\n\n    Note that `y_true` and `y_pred` must be of rank 2: (batch_size, 1) or\n    (batch_size, C) for multilabel classification (with C categories).\n    `y_true` accepts label values in (0, 1), (-1, 1), or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        min_margin (float): margin to enforce.\n\n    Returns:\n        tf.Tensor: Element-wise hinge margin loss value.\n\n    \"\"\"\n    sign = tf.where(y_true &gt; 0, 1, -1)\n    sign = tf.cast(sign, y_pred.dtype)\n    hinge = tf.nn.relu(min_margin / 2.0 - sign * y_pred)\n    # In binary case (`y_true` of shape (batch_size, 1)), `tf.reduce_mean(axis=-1)`\n    # behaves like `tf.squeeze` to return element-wise loss of shape (batch_size, ).\n    return tf.reduce_mean(hinge, axis=-1)\n</code></pre>"},{"location":"api/losses/#deel.lip.losses.multiclass_hinge","title":"<code>multiclass_hinge(y_true, y_pred, min_margin)</code>","text":"<p>Compute the multi-class hinge margin loss.</p> <p><code>y_true</code> and <code>y_pred</code> must be of shape (batch_size, # classes). Note that <code>y_true</code> should be one-hot encoded or pre-processed with the <code>deel.lip.utils.process_labels_for_multi_gpu()</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>tf.Tensor</code> <p>tensor of true targets of shape (batch_size, # classes)</p> required <code>y_pred</code> <code>tf.Tensor</code> <p>tensor of predicted targets of shape (batch_size, # classes)</p> required <code>min_margin</code> <code>float</code> <p>margin to enforce.</p> required <p>Returns:</p> Type Description <p>tf.Tensor: Element-wise multi-class hinge margin loss value.</p> Source code in <code>deel/lip/losses.py</code> <pre><code>def multiclass_hinge(y_true, y_pred, min_margin):\n\"\"\"Compute the multi-class hinge margin loss.\n\n    `y_true` and `y_pred` must be of shape (batch_size, # classes).\n    Note that `y_true` should be one-hot encoded or pre-processed with the\n    `deel.lip.utils.process_labels_for_multi_gpu()` function.\n\n    Args:\n        y_true (tf.Tensor): tensor of true targets of shape (batch_size, # classes)\n        y_pred (tf.Tensor): tensor of predicted targets of shape (batch_size, # classes)\n        min_margin (float): margin to enforce.\n\n    Returns:\n        tf.Tensor: Element-wise multi-class hinge margin loss value.\n    \"\"\"\n    sign = tf.where(y_true &gt; 0, 1, -1)\n    sign = tf.cast(sign, y_pred.dtype)\n    # compute the elementwise hinge term\n    hinge = tf.nn.relu(min_margin / 2.0 - sign * y_pred)\n    # reweight positive elements\n    factor = y_pred.shape[-1] - 1.0\n    hinge = tf.where(sign &gt; 0, hinge * factor, hinge)\n    return tf.reduce_mean(hinge, axis=-1)\n</code></pre>"},{"location":"api/metrics/","title":"deel.lip.metrics","text":"<p>This module contains metrics applicable in provable robustness. See https://arxiv.org/abs/2006.06520 and https://arxiv.org/abs/2108.04062 for more information.</p>"},{"location":"api/metrics/#deel.lip.metrics.BinaryProvableAvgRobustness","title":"<code>BinaryProvableAvgRobustness</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/metrics.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"BinaryProvableAvgRobustness\")\nclass BinaryProvableAvgRobustness(Loss):\n    def __init__(\n        self,\n        lip_const=1.0,\n        negative_robustness=False,\n        reduction=Reduction.AUTO,\n        name=\"BinaryProvableAvgRobustness\",\n    ):\nr\"\"\"\n\n        Compute the average provable robustness radius on the dataset.\n\n        $$\n        \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right]\n        $$\n\n        $\\mathcal{M}_f(x)$ is a term that: is positive when x is correctly\n        classified and negative otherwise. In both case the value give the robustness\n        radius around x.\n\n        In the binary classification setup we have:\n\n        $$\n        \\mathcal{M}_f(x) = f(x) \\text{ if } l=1, -f(x) \\text{otherwise}\n        $$\n\n        Where $D$ is the dataset, $l$ is the correct label for x and\n        $L_f$ is the lipschitz constant of the network..\n\n        When `negative_robustness` is set to `True` misclassified elements count as\n        negative robustness ($\\phi$ act as identity function), when set to\n        `False`,\n        misclassified elements yield a robustness radius of 0 ( $\\phi(x)=relu(\n        x)$ ). The elements are not ignored when computing the mean in both cases.\n\n        This metric works for labels both in {1,0} and {1,-1}.\n\n        Args:\n            lip_const (float): lipschitz constant of the network\n            reduction: the recution method when training in a multi-gpu / TPU system\n            name (str): metrics name.\n        \"\"\"\n        self.lip_const = lip_const\n        self.negative_robustness = negative_robustness\n        if self.negative_robustness:\n            self.delta_correction = lambda delta: delta\n        else:\n            self.delta_correction = tf.nn.relu\n        super(BinaryProvableAvgRobustness, self).__init__(reduction, name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return self.delta_correction(_delta_binary(y_true, y_pred)) / self.lip_const\n\n    def get_config(self):\n        config = {\n            \"lip_const\": self.lip_const,\n            \"negative_robustness\": self.negative_robustness,\n        }\n        base_config = super(BinaryProvableAvgRobustness, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.BinaryProvableAvgRobustness.__init__","title":"<code>__init__(lip_const=1.0, negative_robustness=False, reduction=Reduction.AUTO, name='BinaryProvableAvgRobustness')</code>","text":"<p>Compute the average provable robustness radius on the dataset.</p> \\[ \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right] \\] <p>\\(\\mathcal{M}_f(x)\\) is a term that: is positive when x is correctly classified and negative otherwise. In both case the value give the robustness radius around x.</p> <p>In the binary classification setup we have:</p> \\[ \\mathcal{M}_f(x) = f(x) \\text{ if } l=1, -f(x) \\text{otherwise} \\] <p>Where \\(D\\) is the dataset, \\(l\\) is the correct label for x and \\(L_f\\) is the lipschitz constant of the network..</p> <p>When <code>negative_robustness</code> is set to <code>True</code> misclassified elements count as negative robustness (\\(\\phi\\) act as identity function), when set to <code>False</code>, misclassified elements yield a robustness radius of 0 ( \\(\\phi(x)=relu( x)\\) ). The elements are not ignored when computing the mean in both cases.</p> <p>This metric works for labels both in {1,0} and {1,-1}.</p> <p>Parameters:</p> Name Type Description Default <code>lip_const</code> <code>float</code> <p>lipschitz constant of the network</p> <code>1.0</code> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>metrics name.</p> <code>'BinaryProvableAvgRobustness'</code> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    lip_const=1.0,\n    negative_robustness=False,\n    reduction=Reduction.AUTO,\n    name=\"BinaryProvableAvgRobustness\",\n):\nr\"\"\"\n\n    Compute the average provable robustness radius on the dataset.\n\n    $$\n    \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right]\n    $$\n\n    $\\mathcal{M}_f(x)$ is a term that: is positive when x is correctly\n    classified and negative otherwise. In both case the value give the robustness\n    radius around x.\n\n    In the binary classification setup we have:\n\n    $$\n    \\mathcal{M}_f(x) = f(x) \\text{ if } l=1, -f(x) \\text{otherwise}\n    $$\n\n    Where $D$ is the dataset, $l$ is the correct label for x and\n    $L_f$ is the lipschitz constant of the network..\n\n    When `negative_robustness` is set to `True` misclassified elements count as\n    negative robustness ($\\phi$ act as identity function), when set to\n    `False`,\n    misclassified elements yield a robustness radius of 0 ( $\\phi(x)=relu(\n    x)$ ). The elements are not ignored when computing the mean in both cases.\n\n    This metric works for labels both in {1,0} and {1,-1}.\n\n    Args:\n        lip_const (float): lipschitz constant of the network\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.negative_robustness = negative_robustness\n    if self.negative_robustness:\n        self.delta_correction = lambda delta: delta\n    else:\n        self.delta_correction = tf.nn.relu\n    super(BinaryProvableAvgRobustness, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.BinaryProvableRobustAccuracy","title":"<code>BinaryProvableRobustAccuracy</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/metrics.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"BinaryProvableRobustAccuracy\")\nclass BinaryProvableRobustAccuracy(Loss):\n    def __init__(\n        self,\n        epsilon=36 / 255,\n        lip_const=1.0,\n        reduction=Reduction.AUTO,\n        name=\"BinaryProvableRobustAccuracy\",\n    ):\nr\"\"\"\n\n        The accuracy that can be proved at a given epsilon.\n\n        Args:\n            epsilon (float): the metric will return the guaranteed accuracy for the\n                radius epsilon.\n            lip_const (float): lipschitz constant of the network\n            reduction: the recution method when training in a multi-gpu / TPU system\n            name (str): metrics name.\n        \"\"\"\n        self.lip_const = lip_const\n        self.epsilon = epsilon\n        super(BinaryProvableRobustAccuracy, self).__init__(reduction, name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return tf.cast(\n            (_delta_binary(y_true, y_pred) / self.lip_const) &gt; self.epsilon,\n            y_pred.dtype,\n        )\n\n    def get_config(self):\n        config = {\n            \"epsilon\": self.epsilon,\n            \"lip_const\": self.lip_const,\n        }\n        base_config = super(BinaryProvableRobustAccuracy, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.BinaryProvableRobustAccuracy.__init__","title":"<code>__init__(epsilon=36 / 255, lip_const=1.0, reduction=Reduction.AUTO, name='BinaryProvableRobustAccuracy')</code>","text":"<p>The accuracy that can be proved at a given epsilon.</p> <p>Parameters:</p> Name Type Description Default <code>epsilon</code> <code>float</code> <p>the metric will return the guaranteed accuracy for the radius epsilon.</p> <code>36 / 255</code> <code>lip_const</code> <code>float</code> <p>lipschitz constant of the network</p> <code>1.0</code> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>metrics name.</p> <code>'BinaryProvableRobustAccuracy'</code> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    epsilon=36 / 255,\n    lip_const=1.0,\n    reduction=Reduction.AUTO,\n    name=\"BinaryProvableRobustAccuracy\",\n):\nr\"\"\"\n\n    The accuracy that can be proved at a given epsilon.\n\n    Args:\n        epsilon (float): the metric will return the guaranteed accuracy for the\n            radius epsilon.\n        lip_const (float): lipschitz constant of the network\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.epsilon = epsilon\n    super(BinaryProvableRobustAccuracy, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.CategoricalProvableAvgRobustness","title":"<code>CategoricalProvableAvgRobustness</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/metrics.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"CategoricalProvableAvgRobustness\")\nclass CategoricalProvableAvgRobustness(Loss):\n    def __init__(\n        self,\n        lip_const=1.0,\n        disjoint_neurons=True,\n        negative_robustness=False,\n        reduction=Reduction.AUTO,\n        name=\"CategoricalProvableAvgRobustness\",\n    ):\nr\"\"\"\n\n        Compute the average provable robustness radius on the dataset.\n\n        $$\n        \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right]\n        $$\n\n        $\\mathcal{M}_f(x)$ is a term that: is positive when x is correctly\n        classified and negative otherwise. In both case the value give the robustness\n        radius around x.\n\n        In the multiclass setup we have:\n\n        $$\n        \\mathcal{M}_f(x) =f_l(x) - \\max_{i \\neq l} f_i(x)\n        $$\n\n        Where $D$ is the dataset, $l$ is the correct label for x and\n        $L_f$ is the lipschitz constant of the network ($L = 2 \\times\n        \\text{lip_const}$ when `disjoint_neurons=True`, $L = \\sqrt{2} \\times\n        \\text{lip_const}$ otherwise).\n\n        When `negative_robustness` is set to `True` misclassified elements count as\n        negative robustness ($\\phi$ act as identity function), when set to\n        `False`,\n        misclassified elements yield a robustness radius of 0 ( $\\phi(x)=relu(\n        x)$ ). The elements are not ignored when computing the mean in both cases.\n\n        This metric works for labels both in {1,0} and {1,-1}.\n\n        Args:\n            lip_const (float): lipschitz constant of the network\n            disjoint_neurons (bool): must be set to True is your model ends with a\n                FrobeniusDense layer with `disjoint_neurons` set to True. Set to False\n                otherwise\n            reduction: the recution method when training in a multi-gpu / TPU system\n            name (str): metrics name.\n        \"\"\"\n        self.lip_const = lip_const\n        self.disjoint_neurons = disjoint_neurons\n        self.negative_robustness = negative_robustness\n        if disjoint_neurons:\n            self.certificate_factor = 2 * lip_const\n        else:\n            self.certificate_factor = math.sqrt(2) * lip_const\n        if self.negative_robustness:\n            self.delta_correction = lambda delta: delta\n        else:\n            self.delta_correction = tf.nn.relu\n        super(CategoricalProvableAvgRobustness, self).__init__(reduction, name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return (\n            self.delta_correction(_delta_multiclass(y_true, y_pred))\n            / self.certificate_factor\n        )\n\n    def get_config(self):\n        config = {\n            \"lip_const\": self.lip_const,\n            \"disjoint_neurons\": self.disjoint_neurons,\n            \"negative_robustness\": self.negative_robustness,\n        }\n        base_config = super(CategoricalProvableAvgRobustness, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.CategoricalProvableAvgRobustness.__init__","title":"<code>__init__(lip_const=1.0, disjoint_neurons=True, negative_robustness=False, reduction=Reduction.AUTO, name='CategoricalProvableAvgRobustness')</code>","text":"<p>Compute the average provable robustness radius on the dataset.</p> \\[ \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right] \\] <p>\\(\\mathcal{M}_f(x)\\) is a term that: is positive when x is correctly classified and negative otherwise. In both case the value give the robustness radius around x.</p> <p>In the multiclass setup we have:</p> \\[ \\mathcal{M}_f(x) =f_l(x) - \\max_{i \\neq l} f_i(x) \\] <p>Where \\(D\\) is the dataset, \\(l\\) is the correct label for x and \\(L_f\\) is the lipschitz constant of the network (\\(L = 2 \\times \\text{lip_const}\\) when <code>disjoint_neurons=True</code>, \\(L = \\sqrt{2} \\times \\text{lip_const}\\) otherwise).</p> <p>When <code>negative_robustness</code> is set to <code>True</code> misclassified elements count as negative robustness (\\(\\phi\\) act as identity function), when set to <code>False</code>, misclassified elements yield a robustness radius of 0 ( \\(\\phi(x)=relu( x)\\) ). The elements are not ignored when computing the mean in both cases.</p> <p>This metric works for labels both in {1,0} and {1,-1}.</p> <p>Parameters:</p> Name Type Description Default <code>lip_const</code> <code>float</code> <p>lipschitz constant of the network</p> <code>1.0</code> <code>disjoint_neurons</code> <code>bool</code> <p>must be set to True is your model ends with a FrobeniusDense layer with <code>disjoint_neurons</code> set to True. Set to False otherwise</p> <code>True</code> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>metrics name.</p> <code>'CategoricalProvableAvgRobustness'</code> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    lip_const=1.0,\n    disjoint_neurons=True,\n    negative_robustness=False,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalProvableAvgRobustness\",\n):\nr\"\"\"\n\n    Compute the average provable robustness radius on the dataset.\n\n    $$\n    \\mathbb{E}_{x \\in D}\\left[ \\frac{\\phi\\left(\\mathcal{M}_f(x)\\right)}{L_f}\\right]\n    $$\n\n    $\\mathcal{M}_f(x)$ is a term that: is positive when x is correctly\n    classified and negative otherwise. In both case the value give the robustness\n    radius around x.\n\n    In the multiclass setup we have:\n\n    $$\n    \\mathcal{M}_f(x) =f_l(x) - \\max_{i \\neq l} f_i(x)\n    $$\n\n    Where $D$ is the dataset, $l$ is the correct label for x and\n    $L_f$ is the lipschitz constant of the network ($L = 2 \\times\n    \\text{lip_const}$ when `disjoint_neurons=True`, $L = \\sqrt{2} \\times\n    \\text{lip_const}$ otherwise).\n\n    When `negative_robustness` is set to `True` misclassified elements count as\n    negative robustness ($\\phi$ act as identity function), when set to\n    `False`,\n    misclassified elements yield a robustness radius of 0 ( $\\phi(x)=relu(\n    x)$ ). The elements are not ignored when computing the mean in both cases.\n\n    This metric works for labels both in {1,0} and {1,-1}.\n\n    Args:\n        lip_const (float): lipschitz constant of the network\n        disjoint_neurons (bool): must be set to True is your model ends with a\n            FrobeniusDense layer with `disjoint_neurons` set to True. Set to False\n            otherwise\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.disjoint_neurons = disjoint_neurons\n    self.negative_robustness = negative_robustness\n    if disjoint_neurons:\n        self.certificate_factor = 2 * lip_const\n    else:\n        self.certificate_factor = math.sqrt(2) * lip_const\n    if self.negative_robustness:\n        self.delta_correction = lambda delta: delta\n    else:\n        self.delta_correction = tf.nn.relu\n    super(CategoricalProvableAvgRobustness, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.CategoricalProvableRobustAccuracy","title":"<code>CategoricalProvableRobustAccuracy</code>","text":"<p>         Bases: <code>Loss</code></p> Source code in <code>deel/lip/metrics.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"CategoricalProvableRobustAccuracy\")\nclass CategoricalProvableRobustAccuracy(Loss):\n    def __init__(\n        self,\n        epsilon=36 / 255,\n        lip_const=1.0,\n        disjoint_neurons=True,\n        reduction=Reduction.AUTO,\n        name=\"CategoricalProvableRobustAccuracy\",\n    ):\nr\"\"\"\n\n        The accuracy that can be proved at a given epsilon.\n\n        Args:\n            epsilon (float): the metric will return the guaranteed accuracy for the\n                radius epsilon.\n            lip_const (float): lipschitz constant of the network\n            disjoint_neurons (bool): must be set to True if your model ends with a\n                FrobeniusDense layer with `disjoint_neurons` set to True. Set to False\n                otherwise\n            reduction: the recution method when training in a multi-gpu / TPU system\n            name (str): metrics name.\n        \"\"\"\n        self.lip_const = lip_const\n        self.epsilon = epsilon\n        self.disjoint_neurons = disjoint_neurons\n        if disjoint_neurons:\n            self.certificate_factor = 2 * lip_const\n        else:\n            self.certificate_factor = math.sqrt(2) * lip_const\n        super(CategoricalProvableRobustAccuracy, self).__init__(reduction, name)\n\n    @tf.function\n    def call(self, y_true, y_pred):\n        return tf.cast(\n            (_delta_multiclass(y_true, y_pred) / self.certificate_factor)\n            &gt; self.epsilon,\n            y_pred.dtype,\n        )\n\n    def get_config(self):\n        config = {\n            \"epsilon\": self.epsilon,\n            \"lip_const\": self.lip_const,\n            \"disjoint_neurons\": self.disjoint_neurons,\n        }\n        base_config = super(CategoricalProvableRobustAccuracy, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/metrics/#deel.lip.metrics.CategoricalProvableRobustAccuracy.__init__","title":"<code>__init__(epsilon=36 / 255, lip_const=1.0, disjoint_neurons=True, reduction=Reduction.AUTO, name='CategoricalProvableRobustAccuracy')</code>","text":"<p>The accuracy that can be proved at a given epsilon.</p> <p>Parameters:</p> Name Type Description Default <code>epsilon</code> <code>float</code> <p>the metric will return the guaranteed accuracy for the radius epsilon.</p> <code>36 / 255</code> <code>lip_const</code> <code>float</code> <p>lipschitz constant of the network</p> <code>1.0</code> <code>disjoint_neurons</code> <code>bool</code> <p>must be set to True if your model ends with a FrobeniusDense layer with <code>disjoint_neurons</code> set to True. Set to False otherwise</p> <code>True</code> <code>reduction</code> <p>the recution method when training in a multi-gpu / TPU system</p> <code>Reduction.AUTO</code> <code>name</code> <code>str</code> <p>metrics name.</p> <code>'CategoricalProvableRobustAccuracy'</code> Source code in <code>deel/lip/metrics.py</code> <pre><code>def __init__(\n    self,\n    epsilon=36 / 255,\n    lip_const=1.0,\n    disjoint_neurons=True,\n    reduction=Reduction.AUTO,\n    name=\"CategoricalProvableRobustAccuracy\",\n):\nr\"\"\"\n\n    The accuracy that can be proved at a given epsilon.\n\n    Args:\n        epsilon (float): the metric will return the guaranteed accuracy for the\n            radius epsilon.\n        lip_const (float): lipschitz constant of the network\n        disjoint_neurons (bool): must be set to True if your model ends with a\n            FrobeniusDense layer with `disjoint_neurons` set to True. Set to False\n            otherwise\n        reduction: the recution method when training in a multi-gpu / TPU system\n        name (str): metrics name.\n    \"\"\"\n    self.lip_const = lip_const\n    self.epsilon = epsilon\n    self.disjoint_neurons = disjoint_neurons\n    if disjoint_neurons:\n        self.certificate_factor = 2 * lip_const\n    else:\n        self.certificate_factor = math.sqrt(2) * lip_const\n    super(CategoricalProvableRobustAccuracy, self).__init__(reduction, name)\n</code></pre>"},{"location":"api/model/","title":"deel.lip.model","text":"<p>This module contains equivalents for Model and Sequential. These classes add support for condensation and vanilla exportation.</p>"},{"location":"api/model/#deel.lip.model.Model","title":"<code>Model</code>","text":"<p>         Bases: <code>KerasModel</code></p> <p>Equivalent of keras.Model but support condensation and vanilla exportation.</p> Warning <p>As lipschitz constant are multiplicative along layer, the Model class cannot set a global Lipschitz constant (problem with branching inside a model).</p> Source code in <code>deel/lip/model.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"Model\")\nclass Model(KerasModel):\n\"\"\"\n    Equivalent of keras.Model but support condensation and vanilla exportation.\n\n    Warning:\n         As lipschitz constant are multiplicative along layer, the Model class\n         cannot set a global Lipschitz constant (problem with branching inside a\n         model).\n    \"\"\"\n\n    def condense(self):\n        for layer in self.layers:\n            if isinstance(layer, Condensable):\n                layer.condense()\n\n    def vanilla_export(self) -&gt; KerasModel:\n\"\"\"\n        Export this model to a \"Vanilla\" model, i.e. a model without Condensable\n        layers.\n\n        Returns:\n            A Keras model, identical to this model, but where condensable layers have\n                been replaced with their vanilla equivalent (e.g. SpectralConv2D with\n                Conv2D).\n        \"\"\"\n        return vanillaModel(self)\n</code></pre>"},{"location":"api/model/#deel.lip.model.Model.vanilla_export","title":"<code>vanilla_export()</code>","text":"<p>Export this model to a \"Vanilla\" model, i.e. a model without Condensable layers.</p> <p>Returns:</p> Type Description <code>KerasModel</code> <p>A Keras model, identical to this model, but where condensable layers have been replaced with their vanilla equivalent (e.g. SpectralConv2D with Conv2D).</p> Source code in <code>deel/lip/model.py</code> <pre><code>def vanilla_export(self) -&gt; KerasModel:\n\"\"\"\n    Export this model to a \"Vanilla\" model, i.e. a model without Condensable\n    layers.\n\n    Returns:\n        A Keras model, identical to this model, but where condensable layers have\n            been replaced with their vanilla equivalent (e.g. SpectralConv2D with\n            Conv2D).\n    \"\"\"\n    return vanillaModel(self)\n</code></pre>"},{"location":"api/model/#deel.lip.model.Sequential","title":"<code>Sequential</code>","text":"<p>         Bases: <code>KerasSequential</code>, <code>LipschitzLayer</code>, <code>Condensable</code></p> Source code in <code>deel/lip/model.py</code> <pre><code>@register_keras_serializable(\"deel-lip\", \"Sequential\")\nclass Sequential(KerasSequential, LipschitzLayer, Condensable):\n    def __init__(\n        self,\n        layers=None,\n        name=None,\n        k_coef_lip=1.0,\n    ):\n\"\"\"\n        Equivalent of keras.Sequential but allow to set k-lip factor globally. Also\n        support condensation and vanilla exportation.\n        For now constant repartition is implemented (each layer\n        get n_sqrt(k_lip_factor), where n is the number of layers)\n        But in the future other repartition function may be implemented.\n\n        Args:\n            layers (list): list of layers to add to the model.\n            name (str): name of the model, can be None\n            k_coef_lip (float): the Lipschitz coefficient to ensure globally on the\n                model.\n        \"\"\"\n        super(Sequential, self).__init__(layers, name)\n        self.set_klip_factor(k_coef_lip)\n\n    def build(self, input_shape=None):\n        self._init_lip_coef(input_shape)\n        return super(Sequential, self).build(input_shape)\n\n    def set_klip_factor(self, klip_factor):\n        super(Sequential, self).set_klip_factor(klip_factor)\n        nb_layers = np.sum([isinstance(layer, LipschitzLayer) for layer in self.layers])\n        for layer in self.layers:\n            if isinstance(layer, LipschitzLayer):\n                layer.set_klip_factor(math.pow(klip_factor, 1 / nb_layers))\n            elif _is_supported_1lip_layer(layer) is not True:\n                warn(_msg_not_lip.format(layer.name))\n\n    def _compute_lip_coef(self, input_shape=None):\n        for layer in self.layers:\n            if isinstance(layer, LipschitzLayer):\n                layer._compute_lip_coef(input_shape)\n            elif _is_supported_1lip_layer(layer) is not True:\n                warn(_msg_not_lip.format(layer.name))\n\n    def _init_lip_coef(self, input_shape):\n        for layer in self.layers:\n            if isinstance(layer, LipschitzLayer):\n                layer._init_lip_coef(input_shape)\n            elif _is_supported_1lip_layer(layer) is not True:\n                warn(_msg_not_lip.format(layer.name))\n\n    def _get_coef(self):\n        global_coef = 1.0\n        for layer in self.layers:\n            if isinstance(layer, LipschitzLayer) and (global_coef is not None):\n                global_coef *= layer._get_coef()\n            elif _is_supported_1lip_layer(layer) is not True:\n                warn(_msg_not_lip.format(layer.name))\n                global_coef = None\n        return global_coef\n\n    def condense(self):\n        for layer in self.layers:\n            if isinstance(layer, Condensable):\n                layer.condense()\n\n    def vanilla_export(self):\n        return vanillaModel(self)\n\n    def get_config(self):\n        config = {\"k_coef_lip\": self.k_coef_lip}\n        base_config = super(Sequential, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>"},{"location":"api/model/#deel.lip.model.Sequential.__init__","title":"<code>__init__(layers=None, name=None, k_coef_lip=1.0)</code>","text":"<p>Equivalent of keras.Sequential but allow to set k-lip factor globally. Also support condensation and vanilla exportation. For now constant repartition is implemented (each layer get n_sqrt(k_lip_factor), where n is the number of layers) But in the future other repartition function may be implemented.</p> <p>Parameters:</p> Name Type Description Default <code>layers</code> <code>list</code> <p>list of layers to add to the model.</p> <code>None</code> <code>name</code> <code>str</code> <p>name of the model, can be None</p> <code>None</code> <code>k_coef_lip</code> <code>float</code> <p>the Lipschitz coefficient to ensure globally on the model.</p> <code>1.0</code> Source code in <code>deel/lip/model.py</code> <pre><code>def __init__(\n    self,\n    layers=None,\n    name=None,\n    k_coef_lip=1.0,\n):\n\"\"\"\n    Equivalent of keras.Sequential but allow to set k-lip factor globally. Also\n    support condensation and vanilla exportation.\n    For now constant repartition is implemented (each layer\n    get n_sqrt(k_lip_factor), where n is the number of layers)\n    But in the future other repartition function may be implemented.\n\n    Args:\n        layers (list): list of layers to add to the model.\n        name (str): name of the model, can be None\n        k_coef_lip (float): the Lipschitz coefficient to ensure globally on the\n            model.\n    \"\"\"\n    super(Sequential, self).__init__(layers, name)\n    self.set_klip_factor(k_coef_lip)\n</code></pre>"},{"location":"api/model/#deel.lip.model.vanillaModel","title":"<code>vanillaModel(model)</code>","text":"<p>Transform a model to its equivalent \"vanilla\" model, i.e. a model where <code>Condensable</code> layers are replaced with their vanilla equivalent. For example, <code>SpectralConv2D</code> layers are converted to tf.keras <code>Conv2D</code> layers.</p> <p>The input model can be a tf.keras Sequential/Model or a deel.lip Sequential/Model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>a tf.keras or deel.lip model with Condensable layers.</p> required <p>Returns:</p> Type Description <p>A Keras model, identical to the input model where <code>Condensable</code> layers are replaced with their vanilla counterparts.</p> Source code in <code>deel/lip/model.py</code> <pre><code>def vanillaModel(model):\n\"\"\"\n    Transform a model to its equivalent \"vanilla\" model, i.e. a model where\n    `Condensable` layers are replaced with their vanilla equivalent. For example,\n    `SpectralConv2D` layers are converted to tf.keras `Conv2D` layers.\n\n    The input model can be a tf.keras Sequential/Model or a deel.lip Sequential/Model.\n\n    Args:\n        model: a tf.keras or deel.lip model with Condensable layers.\n\n    Returns:\n        A Keras model, identical to the input model where `Condensable` layers are\n            replaced with their vanilla counterparts.\n    \"\"\"\n\n    def _replace_condensable_layer(layer):\n        # Return a vanilla layer if Condensable, else return a copy of the layer\n        if isinstance(layer, Condensable):\n            return layer.vanilla_export()\n        new_layer = layer.__class__.from_config(layer.get_config())\n        new_layer.build(layer.input_shape)\n        new_layer.set_weights(layer.get_weights())\n        return new_layer\n\n    return clone_model(model, clone_function=_replace_condensable_layer)\n</code></pre>"},{"location":"api/normalizers/","title":"deel.lip.normalizers","text":"<p>This module contains computation function, for Bjorck and spectral normalization. This is done for internal use only.</p>"},{"location":"api/normalizers/#deel.lip.normalizers.bjorck_normalization","title":"<code>bjorck_normalization(w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK)</code>","text":"<p>apply Bjorck normalization on w.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>tf.Tensor</code> <p>weight to normalize, in order to work properly, we must have max_eigenval(w) ~= 1</p> required <code>eps</code> <code>float</code> <p>epsilon stopping criterion: norm(wt - wt-1) must be less than eps</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta</code> <code>float</code> <p>beta used in each iteration, must be in the interval ]0, 0.5]</p> <code>DEFAULT_BETA_BJORCK</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations for the algorithm</p> <code>DEFAULT_MAXITER_BJORCK</code> <p>Returns:</p> Type Description <p>tf.Tensor: the orthonormal weights</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def bjorck_normalization(\n    w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK\n):\n\"\"\"\n    apply Bjorck normalization on w.\n\n    Args:\n        w (tf.Tensor): weight to normalize, in order to work properly, we must have\n            max_eigenval(w) ~= 1\n        eps (float): epsilon stopping criterion: norm(wt - wt-1) must be less than eps\n        beta (float): beta used in each iteration, must be in the interval ]0, 0.5]\n        maxiter (int): maximum number of iterations for the algorithm\n\n    Returns:\n        tf.Tensor: the orthonormal weights\n\n    \"\"\"\n    # create a fake old_w that does'nt pass the loop condition\n    # it won't affect computation as the first action done in the loop overwrite it.\n    old_w = 10 * w\n    # define the loop condition\n\n    def cond(w, old_w):\n        return tf.linalg.norm(w - old_w) &gt;= eps\n\n    # define the loop body\n    def body(w, old_w):\n        old_w = w\n        w = (1 + beta) * w - beta * _wwtw(w)\n        return w, old_w\n\n    # apply the loop\n    w, old_w = tf.while_loop(\n        cond,\n        body,\n        (w, old_w),\n        parallel_iterations=30,\n        maximum_iterations=maxiter,\n        swap_memory=SWAP_MEMORY,\n    )\n    return w\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.reshaped_kernel_orthogonalization","title":"<code>reshaped_kernel_orthogonalization(kernel, u, adjustment_coef, eps_spectral=DEFAULT_EPS_SPECTRAL, eps_bjorck=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter_spectral=DEFAULT_MAXITER_SPECTRAL, maxiter_bjorck=DEFAULT_MAXITER_BJORCK)</code>","text":"<p>Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It apply the power method to find the largest singular value and apply the Bjorck algorithm to the rescaled kernel. This greatly improve the stability and and speed convergence of the bjorck algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>tf.Tensor</code> <p>the kernel to orthogonalize</p> required <code>u</code> <code>tf.Tensor</code> <p>the vector used to do the power iteration method</p> required <code>adjustment_coef</code> <code>float</code> <p>the adjustment coefficient as used in convolution</p> required <code>eps_spectral</code> <code>float</code> <p>stopping criterion in spectral algorithm</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>eps_bjorck</code> <code>float</code> <p>stopping criterion in bjorck algorithm</p> <code>DEFAULT_EPS_BJORCK</code> <code>beta</code> <code>float</code> <p>the beta used in the bjorck algorithm</p> <code>DEFAULT_BETA_BJORCK</code> <code>maxiter_spectral</code> <code>int</code> <p>maximum number of iterations for the power iteration</p> <code>DEFAULT_MAXITER_SPECTRAL</code> <code>maxiter_bjorck</code> <code>int</code> <p>maximum number of iterations for bjorck algorithm</p> <code>DEFAULT_MAXITER_BJORCK</code> <p>Returns:</p> Type Description <p>tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest singular value</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def reshaped_kernel_orthogonalization(\n    kernel,\n    u,\n    adjustment_coef,\n    eps_spectral=DEFAULT_EPS_SPECTRAL,\n    eps_bjorck=DEFAULT_EPS_BJORCK,\n    beta=DEFAULT_BETA_BJORCK,\n    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n):\n\"\"\"\n    Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It\n    apply the power method to find the largest singular value and apply the Bjorck\n    algorithm to the rescaled kernel. This greatly improve the stability and and\n    speed convergence of the bjorck algorithm.\n\n    Args:\n        kernel (tf.Tensor): the kernel to orthogonalize\n        u (tf.Tensor): the vector used to do the power iteration method\n        adjustment_coef (float): the adjustment coefficient as used in convolution\n        eps_spectral (float): stopping criterion in spectral algorithm\n        eps_bjorck (float): stopping criterion in bjorck algorithm\n        beta (float): the beta used in the bjorck algorithm\n        maxiter_spectral (int): maximum number of iterations for the power iteration\n        maxiter_bjorck (int): maximum number of iterations for bjorck algorithm\n\n    Returns:\n        tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest\n            singular value\n\n    \"\"\"\n    W_shape = kernel.shape\n    # Flatten the Tensor\n    W_reshaped = tf.reshape(kernel, [-1, W_shape[-1]])\n    W_bar, u, sigma = spectral_normalization(\n        W_reshaped, u, eps=eps_spectral, maxiter=maxiter_spectral\n    )\n    if (eps_bjorck is not None) and (beta is not None):\n        W_bar = bjorck_normalization(\n            W_bar, eps=eps_bjorck, beta=beta, maxiter=maxiter_bjorck\n        )\n    W_bar = W_bar * adjustment_coef\n    W_bar = K.reshape(W_bar, kernel.shape)\n    return W_bar, u, sigma\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.set_stop_grad_spectral","title":"<code>set_stop_grad_spectral(value)</code>","text":"<p>Set the global STOP_GRAD_SPECTRAL to values. This function must be called before constructing the model (first call of <code>reshaped_kernel_orthogonalization</code>) in order to be accounted.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>boolean, when set to True, disable back-propagation through the power iteration algorithm. The back-propagation will account how updates affects the maximum singular value but not how it affects the largest singular vector. When set to False, back-propagate through the while loop.</p> required Source code in <code>deel/lip/normalizers.py</code> <pre><code>def set_stop_grad_spectral(value: bool):\n\"\"\"\n    Set the global STOP_GRAD_SPECTRAL to values. This function must be called before\n    constructing the model (first call of `reshaped_kernel_orthogonalization`) in\n    order to be accounted.\n\n    Args:\n        value: boolean, when set to True, disable back-propagation through the power\n            iteration algorithm. The back-propagation will account how updates affects\n            the maximum singular value but not how it affects the largest singular\n            vector. When set to False, back-propagate through the while loop.\n\n    \"\"\"\n    global STOP_GRAD_SPECTRAL\n    STOP_GRAD_SPECTRAL = value\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.set_swap_memory","title":"<code>set_swap_memory(value)</code>","text":"<p>Set the global SWAP_MEMORY to values. This function must be called before constructing the model (first call of <code>reshaped_kernel_orthogonalization</code>) in order to be accounted.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bool</code> <p>boolean that will be used as the swap_memory parameter in while loops in spectral and bjorck algorithms.</p> required Source code in <code>deel/lip/normalizers.py</code> <pre><code>def set_swap_memory(value: bool):\n\"\"\"\n    Set the global SWAP_MEMORY to values. This function must be called before\n    constructing the model (first call of `reshaped_kernel_orthogonalization`) in\n    order to be accounted.\n\n    Args:\n        value: boolean that will be used as the swap_memory parameter in while loops\n            in spectral and bjorck algorithms.\n\n    \"\"\"\n    global SWAP_MEMORY\n    SWAP_MEMORY = value\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.spectral_normalization","title":"<code>spectral_normalization(kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL)</code>","text":"<p>Normalize the kernel to have it's max eigenvalue == 1.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>tf.Tensor</code> <p>the kernel to normalize, assuming a 2D kernel</p> required <code>u</code> <code>tf.Tensor</code> <p>initialization for the max eigen vector</p> required <code>eps</code> <code>float</code> <p>epsilon stopping criterion: norm(ut - ut-1) must be less than eps</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations for the algorithm</p> <code>DEFAULT_MAXITER_SPECTRAL</code> <p>Returns:</p> Type Description <p>the normalized kernel w_bar, the maximum eigen vector, and the maximum singular value.</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def spectral_normalization(\n    kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL\n):\n\"\"\"\n    Normalize the kernel to have it's max eigenvalue == 1.\n\n    Args:\n        kernel (tf.Tensor): the kernel to normalize, assuming a 2D kernel\n        u (tf.Tensor): initialization for the max eigen vector\n        eps (float): epsilon stopping criterion: norm(ut - ut-1) must be less than eps\n        maxiter (int): maximum number of iterations for the algorithm\n\n    Returns:\n        the normalized kernel w_bar, the maximum eigen vector, and the maximum singular\n            value.\n\n    \"\"\"\n    _u, _v = _power_iteration(kernel, u, eps, maxiter)\n    # compute Sigma\n    sigma = _v @ kernel\n    sigma = sigma @ tf.transpose(_u)\n    # normalize it\n    # we assume that in the worst case we converged to sigma + eps (as u and v are\n    # normalized after each iteration)\n    # in order to be sure that operator norm of W_bar is strictly less than one we\n    # use sigma + eps, which ensure stability of the bjorck even when beta=0.5\n    W_bar = kernel / (sigma + eps)\n    return W_bar, _u, sigma\n</code></pre>"},{"location":"api/normalizers/#deel.lip.normalizers.spectral_normalization_conv","title":"<code>spectral_normalization_conv(kernel, u, stride=1.0, conv_first=True, pad_func=None, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL)</code>","text":"<p>Normalize the convolution kernel to have its max eigenvalue == 1.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>tf.Tensor</code> <p>the convolution kernel to normalize</p> required <code>u</code> <code>tf.Tensor</code> <p>initialization for the max eigen vector (as a 4d tensor)</p> required <code>stride</code> <code>int</code> <p>stride parameter of convolutions</p> <code>1.0</code> <code>conv_first</code> <code>bool</code> <p>RO or CO case , should be True in CO case (stride^2*C&lt;M)</p> <code>True</code> <code>pad_func</code> <code>Callable</code> <p>function for applying padding (None is padding same)</p> <code>None</code> <code>eps</code> <code>float</code> <p>epsilon stopping criterion: norm(ut - ut-1) must be less than eps</p> <code>DEFAULT_EPS_SPECTRAL</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations for the power iteration algorithm.</p> <code>DEFAULT_MAXITER_SPECTRAL</code> <p>Returns:</p> Type Description <p>the normalized kernel w_bar, the maximum eigen vector, and the maximum eigen value</p> Source code in <code>deel/lip/normalizers.py</code> <pre><code>def spectral_normalization_conv(\n    kernel,\n    u,\n    stride=1.0,\n    conv_first=True,\n    pad_func=None,\n    eps=DEFAULT_EPS_SPECTRAL,\n    maxiter=DEFAULT_MAXITER_SPECTRAL,\n):\n\"\"\"\n    Normalize the convolution kernel to have its max eigenvalue == 1.\n\n    Args:\n        kernel (tf.Tensor): the convolution kernel to normalize\n        u (tf.Tensor): initialization for the max eigen vector (as a 4d tensor)\n        stride (int): stride parameter of convolutions\n        conv_first (bool): RO or CO case , should be True in CO case (stride^2*C&lt;M)\n        pad_func (Callable): function for applying padding (None is padding same)\n        eps (float): epsilon stopping criterion: norm(ut - ut-1) must be less than eps\n        maxiter (int): maximum number of iterations for the power iteration algorithm.\n\n    Returns:\n        the normalized kernel w_bar, the maximum eigen vector, and the maximum eigen\n            value\n    \"\"\"\n\n    if eps &lt; 0:\n        return kernel, u, 1.0\n\n    _u, _v, _ = _power_iteration_conv(\n        kernel, u, stride, conv_first, pad_func, eps, maxiter\n    )\n\n    # Calculate Sigma\n    sigma = tf.norm(_v)\n    W_bar = kernel / (sigma + eps)\n    return W_bar, _u, sigma\n</code></pre>"},{"location":"api/utils/","title":"deel.lip.utils","text":"<p>Contains utility functions.</p>"},{"location":"api/utils/#deel.lip.utils.evaluate_lip_const","title":"<code>evaluate_lip_const(model, x, eps=0.0001, seed=None)</code>","text":"<p>Evaluate the Lipschitz constant of a model, with the naive method. Please note that the estimation of the lipschitz constant is done locally around input sample. This may not correctly estimate the behaviour in the whole domain.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>built keras model used to make predictions</p> required <code>x</code> <p>inputs used to compute the lipschitz constant</p> required <code>eps</code> <code>float</code> <p>magnitude of noise to add to input in order to compute the constant</p> <code>0.0001</code> <code>seed</code> <code>int</code> <p>seed used when generating the noise ( can be set to None )</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <p>the empirically evaluated lipschitz constant. The computation might also be inaccurate in high dimensional space.</p> Source code in <code>deel/lip/utils.py</code> <pre><code>def evaluate_lip_const(model: Model, x, eps=1e-4, seed=None):\n\"\"\"\n    Evaluate the Lipschitz constant of a model, with the naive method.\n    Please note that the estimation of the lipschitz constant is done locally around\n    input sample. This may not correctly estimate the behaviour in the whole domain.\n\n    Args:\n        model: built keras model used to make predictions\n        x: inputs used to compute the lipschitz constant\n        eps (float): magnitude of noise to add to input in order to compute the constant\n        seed (int): seed used when generating the noise ( can be set to None )\n\n    Returns:\n        float: the empirically evaluated lipschitz constant. The computation might also\n            be inaccurate in high dimensional space.\n\n    \"\"\"\n    y_pred = model.predict(x)\n    # x = np.repeat(x, 100, 0)\n    # y_pred = np.repeat(y_pred, 100, 0)\n    x_var = x + K.random_uniform(\n        shape=x.shape, minval=eps * 0.25, maxval=eps, seed=seed\n    )\n    y_pred_var = model.predict(x_var)\n    dx = x - x_var\n    dfx = y_pred - y_pred_var\n    ndx = K.sqrt(K.sum(K.square(dx), axis=range(1, len(x.shape))))\n    ndfx = K.sqrt(K.sum(K.square(dfx), axis=range(1, len(y_pred.shape))))\n    lip_cst = K.max(ndfx / ndx)\n    print(\"lip cst: %.3f\" % lip_cst)\n    return lip_cst\n</code></pre>"},{"location":"api/utils/#deel.lip.utils.evaluate_lip_const_gen","title":"<code>evaluate_lip_const_gen(model, generator, eps=0.0001, seed=None)</code>","text":"<p>Evaluate the Lipschitz constant of a model, with the naive method. Please note that the estimation of the lipschitz constant is done locally around input sample. This may not correctly estimate the behaviour in the whole domain. The computation might also be inaccurate in high dimensional space.</p> <p>This is the generator version of evaluate_lip_const.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>built keras model used to make predictions</p> required <code>generator</code> <code>Generator[Tuple[np.ndarray, np.ndarray], Any, None]</code> <p>used to select datapoints where to compute the lipschitz constant</p> required <code>eps</code> <code>float</code> <p>magnitude of noise to add to input in order to compute the constant</p> <code>0.0001</code> <code>seed</code> <code>int</code> <p>seed used when generating the noise ( can be set to None )</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <p>the empirically evaluated lipschitz constant.</p> Source code in <code>deel/lip/utils.py</code> <pre><code>def evaluate_lip_const_gen(\n    model: Model,\n    generator: Generator[Tuple[np.ndarray, np.ndarray], Any, None],\n    eps=1e-4,\n    seed=None,\n):\n\"\"\"\n    Evaluate the Lipschitz constant of a model, with the naive method.\n    Please note that the estimation of the lipschitz constant is done locally around\n    input sample. This may not correctly estimate the behaviour in the whole domain.\n    The computation might also be inaccurate in high dimensional space.\n\n    This is the generator version of evaluate_lip_const.\n\n    Args:\n        model: built keras model used to make predictions\n        generator: used to select datapoints where to compute the lipschitz constant\n        eps (float): magnitude of noise to add to input in order to compute the constant\n        seed (int): seed used when generating the noise ( can be set to None )\n\n    Returns:\n        float: the empirically evaluated lipschitz constant.\n\n    \"\"\"\n    x, y = generator.send(None)\n    return evaluate_lip_const(model, x, eps, seed=seed)\n</code></pre>"},{"location":"api/utils/#deel.lip.utils.process_labels_for_multi_gpu","title":"<code>process_labels_for_multi_gpu(labels)</code>","text":"<p>Process labels to be fed to any loss based on KR estimation with a multi-GPU/TPU strategy.</p> <p>When using a multi-GPU/TPU strategy, the flag <code>multi_gpu</code> in KR-based losses must be set to True and the labels have to be pre-processed with this function.</p> <p>For binary classification, the labels should be of shape [batch_size, 1]. For multiclass problems, the labels must be one-hot encoded (1 or 0) with shape [batch_size, number of classes].</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>tf.Tensor</code> <p>tensor containing the labels</p> required <p>Returns:</p> Type Description <p>tf.Tensor: labels processed for KR-based losses with multi-GPU/TPU strategy.</p> Source code in <code>deel/lip/utils.py</code> <pre><code>@tf.function\ndef process_labels_for_multi_gpu(labels):\n\"\"\"Process labels to be fed to any loss based on KR estimation with a multi-GPU/TPU\n    strategy.\n\n    When using a multi-GPU/TPU strategy, the flag `multi_gpu` in KR-based losses must be\n    set to True and the labels have to be pre-processed with this function.\n\n    For binary classification, the labels should be of shape [batch_size, 1].\n    For multiclass problems, the labels must be one-hot encoded (1 or 0) with shape\n    [batch_size, number of classes].\n\n    Args:\n        labels (tf.Tensor): tensor containing the labels\n\n    Returns:\n        tf.Tensor: labels processed for KR-based losses with multi-GPU/TPU strategy.\n    \"\"\"\n    eps = 1e-7\n    labels = tf.cast(tf.where(labels &gt; 0, 1, 0), labels.dtype)\n    batch_size = tf.cast(tf.shape(labels)[0], labels.dtype)\n    counts = tf.reduce_sum(labels, axis=0)\n\n    pos = labels / (counts + eps)\n    neg = (1 - labels) / (batch_size - counts + eps)\n    # Since element-wise KR terms are averaged by loss reduction later on, it is needed\n    # to multiply by batch_size here.\n    return batch_size * (pos - neg)\n</code></pre>"},{"location":"notebooks/demo0/","title":"Demo 0: Example & Usage","text":"(function() {   function addWidgetsRenderer() {     var requireJsScript = document.createElement('script');     requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';      var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]');     var jupyterWidgetsScript = document.createElement('script');     var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';     var widgetState;      // Fallback for older version:     try {       widgetState = mimeElement &amp;&amp; JSON.parse(mimeElement.innerHTML);        if (widgetState &amp;&amp; (widgetState.version_major &lt; 2 || !widgetState.version_major)) {         widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';       }     } catch(e) {}      jupyterWidgetsScript.src = widgetRendererSrc;      document.body.appendChild(requireJsScript);     document.body.appendChild(jupyterWidgetsScript);   }    document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }());  <pre><code>from deel.lip.layers import (\n    SpectralDense,\n    SpectralConv2D,\n    ScaledL2NormPooling2D,\n    FrobeniusDense,\n)\nfrom deel.lip.model import Sequential\nfrom deel.lip.activations import GroupSort\nfrom deel.lip.losses import MulticlassHKR, MulticlassKR\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\n\n# Sequential (resp Model) from deel.model has the same properties as any lipschitz model.\n# It act only as a container, with features specific to lipschitz\n# functions (condensation, vanilla_exportation...) but The layers are fully compatible\n# with the tf.keras.model.Sequential/Model\nmodel = Sequential(\n    [\n        Input(shape=(28, 28, 1)),\n        # Lipschitz layers preserve the API of their superclass ( here Conv2D )\n        # an optional param is available: k_coef_lip which control the lipschitz\n        # constant of the layer\n        SpectralConv2D(\n            filters=16,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        # usual pooling layer are implemented (avg, max...), but new layers are also available\n        ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        SpectralConv2D(\n            filters=16,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        # our layers are fully interoperable with existing keras layers\n        Flatten(),\n        SpectralDense(\n            32,\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        FrobeniusDense(\n            10, activation=None, use_bias=False, kernel_initializer=\"orthogonal\"\n        ),\n    ],\n    # similary model has a parameter to set the lipschitz constant\n    # to set automatically the constant of each layer\n    k_coef_lip=1.0,\n    name=\"hkr_model\",\n)\n\n# HKR (Hinge-Krantorovich-Rubinstein) optimize robustness along with accuracy\nmodel.compile(\n    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n    # note also in the case of lipschitz networks, more robustness require more parameters.\n    loss=MulticlassHKR(alpha=50, min_margin=0.05),\n    optimizer=Adam(1e-3),\n    metrics=[\"accuracy\", MulticlassKR()],\n)\n\nmodel.summary()\n\n# load data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n# standardize and reshape the data\nx_train = np.expand_dims(x_train, -1)\nmean = x_train.mean()\nstd = x_train.std()\nx_train = (x_train - mean) / std\nx_test = np.expand_dims(x_test, -1)\nx_test = (x_test - mean) / std\n# one hot encode the labels\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# fit the model\nmodel.fit(\n    x_train,\n    y_train,\n    batch_size=2048,\n    epochs=30,\n    validation_data=(x_test, y_test),\n    shuffle=True,\n)\n\n# once training is finished you can convert\n# SpectralDense layers into Dense layers and SpectralConv2D into Conv2D\n# which optimize performance for inference\nvanilla_model = model.vanilla_export()\n</code></pre> <pre>\n<code>/home/thibaut.boissin/projects/deel-lip/deel/lip/model.py:56: UserWarning: Sequential model contains a layer wich is not a Lipschitz layer: flatten_2\n  layer.name\n</code>\n</pre> <pre>\n<code>Model: \"hkr_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nspectral_conv2d_4 (SpectralC (None, 28, 28, 16)        321       \n_________________________________________________________________\nscaled_l2norm_pooling2d_4 (S (None, 14, 14, 16)        0         \n_________________________________________________________________\nspectral_conv2d_5 (SpectralC (None, 14, 14, 16)        4641      \n_________________________________________________________________\nscaled_l2norm_pooling2d_5 (S (None, 7, 7, 16)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 784)               0         \n_________________________________________________________________\nspectral_dense_2 (SpectralDe (None, 32)                50241     \n_________________________________________________________________\nfrobenius_dense_2 (Frobenius (None, 10)                640       \n=================================================================\nTotal params: 55,843\nTrainable params: 27,920\nNon-trainable params: 27,923\n_________________________________________________________________\nEpoch 1/30\n30/30 [==============================] - 3s 43ms/step - loss: 6.5323 - accuracy: 0.1522 - MulticlassKR: 0.0183 - val_loss: 2.3933 - val_accuracy: 0.4873 - val_MulticlassKR: 0.0942\nEpoch 2/30\n30/30 [==============================] - 1s 39ms/step - loss: 2.0856 - accuracy: 0.5528 - MulticlassKR: 0.1149 - val_loss: 1.3480 - val_accuracy: 0.7091 - val_MulticlassKR: 0.1653\nEpoch 3/30\n30/30 [==============================] - 1s 35ms/step - loss: 1.2743 - accuracy: 0.7298 - MulticlassKR: 0.1743 - val_loss: 0.9228 - val_accuracy: 0.7942 - val_MulticlassKR: 0.2097\nEpoch 4/30\n30/30 [==============================] - 1s 36ms/step - loss: 0.9001 - accuracy: 0.7975 - MulticlassKR: 0.2168 - val_loss: 0.6864 - val_accuracy: 0.8368 - val_MulticlassKR: 0.2486\nEpoch 5/30\n30/30 [==============================] - 1s 35ms/step - loss: 0.6889 - accuracy: 0.8338 - MulticlassKR: 0.2546 - val_loss: 0.5352 - val_accuracy: 0.8650 - val_MulticlassKR: 0.2835\nEpoch 6/30\n30/30 [==============================] - 1s 37ms/step - loss: 0.5256 - accuracy: 0.8609 - MulticlassKR: 0.2879 - val_loss: 0.4442 - val_accuracy: 0.8805 - val_MulticlassKR: 0.3166\nEpoch 7/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.4469 - accuracy: 0.8735 - MulticlassKR: 0.3186 - val_loss: 0.3349 - val_accuracy: 0.8911 - val_MulticlassKR: 0.3470\nEpoch 8/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.3493 - accuracy: 0.8835 - MulticlassKR: 0.3480 - val_loss: 0.2641 - val_accuracy: 0.8961 - val_MulticlassKR: 0.3787\nEpoch 9/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.2722 - accuracy: 0.8938 - MulticlassKR: 0.3818 - val_loss: 0.2122 - val_accuracy: 0.8993 - val_MulticlassKR: 0.4127\nEpoch 10/30\n30/30 [==============================] - 1s 34ms/step - loss: 0.2036 - accuracy: 0.9013 - MulticlassKR: 0.4153 - val_loss: 0.1330 - val_accuracy: 0.9079 - val_MulticlassKR: 0.4487\nEpoch 11/30\n30/30 [==============================] - 1s 35ms/step - loss: 0.1472 - accuracy: 0.9059 - MulticlassKR: 0.4505 - val_loss: 0.0799 - val_accuracy: 0.9126 - val_MulticlassKR: 0.4861\nEpoch 12/30\n30/30 [==============================] - 1s 35ms/step - loss: 0.0939 - accuracy: 0.9103 - MulticlassKR: 0.4915 - val_loss: 0.0371 - val_accuracy: 0.9142 - val_MulticlassKR: 0.5313\nEpoch 13/30\n30/30 [==============================] - 1s 40ms/step - loss: 0.0499 - accuracy: 0.9100 - MulticlassKR: 0.5346 - val_loss: -0.0211 - val_accuracy: 0.9206 - val_MulticlassKR: 0.5729\nEpoch 14/30\n30/30 [==============================] - 1s 39ms/step - loss: -0.0216 - accuracy: 0.9162 - MulticlassKR: 0.5760 - val_loss: -0.0682 - val_accuracy: 0.9200 - val_MulticlassKR: 0.6219\nEpoch 15/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.0666 - accuracy: 0.9168 - MulticlassKR: 0.6248 - val_loss: -0.1301 - val_accuracy: 0.9236 - val_MulticlassKR: 0.6742\nEpoch 16/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.1223 - accuracy: 0.9197 - MulticlassKR: 0.6778 - val_loss: -0.1777 - val_accuracy: 0.9270 - val_MulticlassKR: 0.7275\nEpoch 17/30\n30/30 [==============================] - 1s 36ms/step - loss: -0.1605 - accuracy: 0.9199 - MulticlassKR: 0.7291 - val_loss: -0.2426 - val_accuracy: 0.9272 - val_MulticlassKR: 0.7900\nEpoch 18/30\n30/30 [==============================] - 1s 36ms/step - loss: -0.2278 - accuracy: 0.9218 - MulticlassKR: 0.7886 - val_loss: -0.2883 - val_accuracy: 0.9305 - val_MulticlassKR: 0.8471\nEpoch 19/30\n30/30 [==============================] - 1s 40ms/step - loss: -0.2246 - accuracy: 0.9170 - MulticlassKR: 0.8478 - val_loss: -0.3104 - val_accuracy: 0.9183 - val_MulticlassKR: 0.9070\nEpoch 20/30\n30/30 [==============================] - 1s 34ms/step - loss: -0.3066 - accuracy: 0.9213 - MulticlassKR: 0.9085 - val_loss: -0.3778 - val_accuracy: 0.9284 - val_MulticlassKR: 0.9754\nEpoch 21/30\n30/30 [==============================] - 1s 39ms/step - loss: -0.3736 - accuracy: 0.9241 - MulticlassKR: 0.9739 - val_loss: -0.4258 - val_accuracy: 0.9280 - val_MulticlassKR: 1.0388\nEpoch 22/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.4180 - accuracy: 0.9229 - MulticlassKR: 1.0337 - val_loss: -0.4805 - val_accuracy: 0.9302 - val_MulticlassKR: 1.1069\nEpoch 23/30\n30/30 [==============================] - 1s 38ms/step - loss: -0.4624 - accuracy: 0.9234 - MulticlassKR: 1.1055 - val_loss: -0.5607 - val_accuracy: 0.9312 - val_MulticlassKR: 1.1803\nEpoch 24/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.5279 - accuracy: 0.9257 - MulticlassKR: 1.1797 - val_loss: -0.5866 - val_accuracy: 0.9275 - val_MulticlassKR: 1.2456\nEpoch 25/30\n30/30 [==============================] - 1s 38ms/step - loss: -0.5482 - accuracy: 0.9218 - MulticlassKR: 1.2388 - val_loss: -0.6441 - val_accuracy: 0.9310 - val_MulticlassKR: 1.3125\nEpoch 26/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.6375 - accuracy: 0.9263 - MulticlassKR: 1.3103 - val_loss: -0.6890 - val_accuracy: 0.9295 - val_MulticlassKR: 1.3795\nEpoch 27/30\n30/30 [==============================] - 1s 42ms/step - loss: -0.6668 - accuracy: 0.9230 - MulticlassKR: 1.3719 - val_loss: -0.7413 - val_accuracy: 0.9271 - val_MulticlassKR: 1.4496\nEpoch 28/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.7483 - accuracy: 0.9264 - MulticlassKR: 1.4371 - val_loss: -0.7748 - val_accuracy: 0.9296 - val_MulticlassKR: 1.5096\nEpoch 29/30\n30/30 [==============================] - 1s 49ms/step - loss: -0.7495 - accuracy: 0.9229 - MulticlassKR: 1.4900 - val_loss: -0.8622 - val_accuracy: 0.9332 - val_MulticlassKR: 1.5644\nEpoch 30/30\n30/30 [==============================] - 1s 35ms/step - loss: -0.8047 - accuracy: 0.9246 - MulticlassKR: 1.5530 - val_loss: -0.8732 - val_accuracy: 0.9297 - val_MulticlassKR: 1.6220\n</code>\n</pre>"},{"location":"notebooks/demo0/#demo-0-example-and-usage","title":"Demo 0: Example and usage","text":"<p>In order to make things simple the following rules have been followed during development:</p> <ul> <li><code>deel-lip</code> follows the <code>keras</code> package structure.</li> <li>All elements (layers, activations, initializers, ...) are compatible     with standard the <code>keras</code> elements.</li> <li>When a k-Lipschitz layer overrides a standard keras layer, it uses     the same interface and the same parameters. The only difference is a     new parameter to control the Lipschitz constant of a layer.</li> </ul>"},{"location":"notebooks/demo0/#which-layers-are-safe-to-use","title":"Which layers are safe to use?","text":"<p>The following table indicates which layers are safe to use in a Lipshitz network, and which are not.</p> layer 1-lip? deel-lip equivalent comments <code>Dense</code> no <code>SpectralDense</code><code>FrobeniusDense</code> <code>SpectralDense</code> and <code>FrobeniusDense</code> are similar when there is a single output. <code>Conv2D</code> no <code>SpectralConv2D</code><code>FrobeniusConv2D</code> <code>SpectralConv2D</code> also implements Bj\u00f6rck normalization. <code>MaxPooling</code><code>GlobalMaxPooling</code> yes n/a <code>AveragePooling2D</code><code>GlobalAveragePooling2D</code> no <code>ScaledAveragePooling2D</code><code>ScaledGlobalAveragePooling2D</code> The lipschitz constant is bounded by <code>sqrt(pool_h * pool_h)</code>. <code>Flatten</code> yes n/a <code>Dropout</code> no None The lipschitz constant is bounded by the dropout factor. <code>BatchNormalization</code> no None We suspect that layer normalization already limits internal covariate shift."},{"location":"notebooks/demo0/#design-tips","title":"Design tips","text":"<p>Designing lipschitz networks requires a careful design in order to avoid vanishing/exploding gradient problems.</p> <p>Choosing pooling layers:</p> layer advantages disadvantages <code>ScaledAveragePooling2D</code> and <code>MaxPooling2D</code> very similar to original implementation (just add a scaling factor for avg). not norm preserving nor gradient norm preserving. <code>InvertibleDownSampling</code> norm preserving and gradient norm preserving. increases the number of channels (and the number of parameters of the next layer). <code>ScaledL2NormPooling2D</code> (sqrt(avgpool(x**2))) norm preserving. lower numerical stability of the gradient when inputs are close to zero. <p>Choosing activations:</p> layer advantages disadvantages <code>ReLU</code> create a strong vanishing gradient effect. If you manage to learn with it, please call 911. <code>MaxMin</code> (stack([ReLU(x), ReLU(-x)])) have similar properties to ReLU, but is norm and gradient norm preserving double the number of outputs <code>GroupSort</code> Input and GradientNorm preserving. Also limit the need of biases (as it is shift invariant). more computationally expensive, (when its parameter n is large) <p>Please note that when learning with the <code>HKR_loss</code> and <code>HKR_multiclass_loss</code>, no activation is required on the last layer.</p>"},{"location":"notebooks/demo0/#how-to-use-it","title":"How to use it ?","text":"<p>Here is an example of 1-lipschitz network trained on MNIST:</p>"},{"location":"notebooks/demo1/","title":"Demo 1: Wasserstein distance estimation on toy example","text":"(function() {   function addWidgetsRenderer() {     var requireJsScript = document.createElement('script');     requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';      var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]');     var jupyterWidgetsScript = document.createElement('script');     var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';     var widgetState;      // Fallback for older version:     try {       widgetState = mimeElement &amp;&amp; JSON.parse(mimeElement.innerHTML);        if (widgetState &amp;&amp; (widgetState.version_major &lt; 2 || !widgetState.version_major)) {         widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';       }     } catch(e) {}      jupyterWidgetsScript.src = widgetRendererSrc;      document.body.appendChild(requireJsScript);     document.body.appendChild(jupyterWidgetsScript);   }    document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }());  <pre><code># pip install deel-lip -qqq\n</code></pre> <pre><code>from datetime import datetime\nimport os\nimport numpy as np\nimport math\n\nimport matplotlib.pyplot as plt \n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Flatten, ReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\nfrom deel.lip.layers import SpectralConv2D, SpectralDense, FrobeniusDense\nfrom deel.lip.activations import MaxMin, GroupSort, FullSort\nfrom deel.lip.losses import KR, HKR\nfrom deel.lip.model import Model\n</code></pre> <pre>\n<code>Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_d1mx9in because the default path (/home/thibaut.boissin/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n2021-09-08 18:20:20.330918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <pre><code>img_size = 64 \nfrac_value = 0.3  # proportion of the center square\n</code></pre> <pre><code>def generate_toy_images(shape,frac=0,v=1):\n\"\"\"\n    function that generate a single image.\n\n    Args:\n        shape: shape of the output image\n        frac: proportion of the center square\n        value: value assigned to the center square\n    \"\"\"\n    img = np.zeros(shape)\n    if frac==0:\n        return img\n    frac=frac**0.5\n    #print(frac)\n    l=int(shape[0]*frac)\n    ldec=(shape[0]-l)//2\n    #print(l)\n    w=int(shape[1]*frac)\n    wdec=(shape[1]-w)//2\n    img[ldec:ldec+l,wdec:wdec+w,:]=v\n    return img\n\n\ndef binary_generator(batch_size,shape,frac=0):\n\"\"\"\n    generate a batch with half of black images, hald of images with a white square.\n    \"\"\"\n    batch_x = np.zeros(((batch_size,)+(shape)), dtype=np.float16)\n    batch_y=np.zeros((batch_size,1), dtype=np.float16)\n    batch_x[batch_size//2:,]=generate_toy_images(shape,frac=frac,v=1)\n    batch_y[batch_size//2:]=1\n    while True:\n        yield  batch_x, batch_y\n\n\ndef ternary_generator(batch_size,shape,frac=0):\n\"\"\"\n    Same as binary generator, but images can have a white square of value 1, or value -1\n    \"\"\"\n    batch_x = np.zeros(((batch_size,)+(shape)), dtype=np.float16)\n    batch_y=np.zeros((batch_size,1), dtype=np.float16)\n    batch_x[3*batch_size//4:,]=generate_toy_images(shape,frac=frac,v=1)\n    batch_x[batch_size//2:3*batch_size//4,]=generate_toy_images(shape,frac=frac,v=-1)\n    batch_y[batch_size//2:]=1\n    #indexes_shuffle = np.arange(batch_size)\n    while True:\n        #np.random.shuffle(indexes_shuffle)\n        #yield  batch_x[indexes_shuffle,], batch_y[indexes_shuffle,]\n        yield  batch_x, batch_y\n</code></pre> <pre><code>def display_img(img):\n\"\"\"\n    Display an image\n    \"\"\"\n    if img.shape[-1] == 1:\n        img = np.tile(img,(3,))\n    fig, ax = plt.subplots()\n\n    imgplot = ax.imshow((img*255).astype(np.uint))\n</code></pre> <p>Now let's take a look at the generated batches</p> <pre><code>test=binary_generator(2,(img_size,img_size,1),frac=frac_value)\nimgs, y=next(test)\n\ndisplay_img(imgs[0])\ndisplay_img(imgs[1])\nprint(\"Norm L2 \"+str(np.linalg.norm(imgs[1])))\nprint(\"Norm L2(count pixels) \"+str(math.sqrt(np.size(imgs[1][imgs[1]==1]))))\n</code></pre> <pre>\n<code>Norm L2 35.0\nNorm L2(count pixels) 35.0\n</code>\n</pre> <pre><code>test=ternary_generator(4,(img_size,img_size,1),frac=frac_value)\nimgs, y=next(test)\n\nfor i in range(4):\n    display_img(0.5*(imgs[i]+1.0)) # we ensure that there is no negative value wehn displaying images\n\nprint(\"Norm L2(imgs[2]-imgs[0])\"+str(np.linalg.norm(imgs[2]-imgs[0])))\nprint(\"Norm L2(imgs[2]) \"+str(np.linalg.norm(imgs[2])))\nprint(\"Norm L2(count pixels) \"+str(math.sqrt(np.size(imgs[2][imgs[2]==-1]))))\n</code></pre> <pre>\n<code>Norm L2(imgs[2]-imgs[0])35.0\nNorm L2(imgs[2]) 35.0\nNorm L2(count pixels) 35.0\n</code>\n</pre> <pre><code>batch_size=64\nepochs=5\nsteps_per_epoch=6400\n</code></pre> <pre><code>generator = ternary_generator   #binary_generator, ternary_generator\nactivation = FullSort #ReLU, MaxMin, GroupSort\n</code></pre> <pre><code>K.clear_session()\n## please note that the previous helper function has the same behavior as the following code:\ninputs = Input((img_size, img_size, 1))\nx = Flatten()(inputs)\nx = SpectralDense(128, activation=FullSort())(x)\nx = SpectralDense(64, activation=FullSort())(x)\nx = SpectralDense(32, activation=FullSort())(x)\ny = FrobeniusDense(1, activation=None)(x)\nwass = Model(inputs=inputs, outputs=y)\nwass.summary()\n</code></pre> <pre>\n<code>2021-09-08 18:20:38.075170: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:20:38.076265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-08 18:20:38.116402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.116842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:20:38.116868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:20:38.119558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:20:38.119602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:20:38.120389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:20:38.120583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:20:38.122025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:20:38.122661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:20:38.122768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:20:38.122832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.123234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.123588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:20:38.124825: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:20:38.124895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.125224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:20:38.125241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:20:38.125254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:20:38.125266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:20:38.125278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:20:38.125289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:20:38.125300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:20:38.125311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:20:38.125323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:20:38.125366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.125711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.126022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:20:38.126048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:20:38.409201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-08 18:20:38.409221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-08 18:20:38.409225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-08 18:20:38.409352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.409615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.409848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:20:38.410069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9056 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n2021-09-08 18:20:38.493063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:20:38.861293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:20:38.861380: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n</code>\n</pre> <pre>\n<code>Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 4096)              0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 128)               1048833   \n_________________________________________________________________\nspectral_dense_1 (SpectralDe (None, 64)                16513     \n_________________________________________________________________\nspectral_dense_2 (SpectralDe (None, 32)                4161      \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 1)                 65        \n=================================================================\nTotal params: 1,069,572\nTrainable params: 534,785\nNon-trainable params: 534,787\n_________________________________________________________________\n</code>\n</pre> <pre><code>optimizer = Adam(lr=0.01)\n</code></pre> <pre><code>wass.compile(loss=HKR(alpha=0), optimizer=optimizer, metrics=[KR])\n</code></pre> <pre><code>wass.fit_generator( generator(batch_size,(img_size,img_size,1),frac=frac_value),\n                steps_per_epoch=steps_per_epoch// batch_size,\n                epochs=epochs,verbose=1)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n2021-09-08 18:20:39.823710: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-08 18:20:39.842379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n</code>\n</pre> <pre>\n<code>Epoch 1/5\n100/100 [==============================] - 6s 50ms/step - loss: -24.9882 - KR: 24.9882\nEpoch 2/5\n100/100 [==============================] - 5s 49ms/step - loss: -34.9959 - KR: 34.9959\nEpoch 3/5\n100/100 [==============================] - 5s 49ms/step - loss: -34.9964 - KR: 34.9964\nEpoch 4/5\n100/100 [==============================] - 5s 50ms/step - loss: -34.9961 - KR: 34.9961\nEpoch 5/5\n100/100 [==============================] - 5s 50ms/step - loss: -34.9957 - KR: 34.9957\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7f6a6b73cfd0&gt;</code>\n</pre> <p>As we can see the loss converge to the value 35 which is the wasserstein distance between the two distributions (square and non-square).</p>"},{"location":"notebooks/demo1/#demo-1-wasserstein-distance-estimation-on-toy-example","title":"Demo 1: Wasserstein distance estimation on toy example","text":"<p>In this notebook we will see how to estimate the wasserstein distance with a Neural net by using the Kantorovich-Rubinestein dual representation.</p>"},{"location":"notebooks/demo1/#wasserstein-distance","title":"Wasserstein distance","text":"<p>The wasserstein distance measure the distance between two probability distribution. Wikipedia article gives a more intuitive definition of it:</p> <p>Intuitively, if each distribution is viewed as a unit amount of \"dirt\" piled on M, the metric is the minimum \"cost\" of turning one pile into the other, which is assumed to be the amount of dirt that needs to be moved times the mean distance it has to be moved. Because of this analogy, the metric is known in computer science as the earth mover's distance.</p> <p>Mathematically it is defined as:</p> \\[ W_1(\\mu,\\nu) = \\inf_{\\pi \\in \\Pi(\\mu,\\nu)}\\underset{x,z \\sim \\pi}{\\mathbb{E}}\\parallel \\textbf{x}-\\textbf{z} \\parallel \\] <p>where \\(\\Pi(\\mu,\\nu)\\) is the set of all probability measures on \\(\\Omega\\times \\Omega\\) with marginals \\(\\mu\\) and \\(\\nu\\). In most case this equation is not tractable.</p>"},{"location":"notebooks/demo1/#kr-dual-formulation","title":"KR dual formulation","text":"<p>In our setup, the KR dual formulation is stated as following: $$ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] -\\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] $$</p> <p>This state the problem as an optimization problem over the 1-lipschitz functions. Therefore k-Lipschitz networks allows us to solve this maximization problem.</p> <p>[1] C. Anil, J. Lucas, et R. Grosse, \u00ab\u00a0Sorting out Lipschitz function approximation\u00a0\u00bb, arXiv:1811.05381 [cs, stat], nov. 2018.</p> <p>We will illustrate this on a synthetic image dataset where \\(W_1\\) is known.</p>"},{"location":"notebooks/demo1/#parameters-input-images","title":"Parameters input images","text":"<p>The synthetic dataset will be composed image with black or white squares allowing us to check if the computed wasserstein distance is correct. One distribution will be the set of black images, while the other will be the set of images with a square on it. these two distribution are diracs, and the wasserstein distance can be analyticaly computed:</p> <p>In the case to the two diracs the wasserstein distance is then the L1 distance between the two images.</p>"},{"location":"notebooks/demo1/#generate-images","title":"Generate images","text":""},{"location":"notebooks/demo1/#for-binary-generator","title":"for binary generator","text":""},{"location":"notebooks/demo1/#for-ternary-generator","title":"for ternary generator","text":""},{"location":"notebooks/demo1/#expe-parameters","title":"Expe parameters","text":"<p>Now we know the wasserstein distance between the black image and the images with a square on it. For both binary generator and ternary generator this distance is 35.</p> <p>We will then compute this distance using a neural network.</p>"},{"location":"notebooks/demo1/#build-lipschitz-model","title":"Build lipschitz Model","text":""},{"location":"notebooks/demo1/#learn-on-toy-dataset","title":"Learn on toy dataset","text":""},{"location":"notebooks/demo2/","title":"Demo 2: HKR Classifier on toy dataset","text":"(function() {   function addWidgetsRenderer() {     var requireJsScript = document.createElement('script');     requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';      var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]');     var jupyterWidgetsScript = document.createElement('script');     var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';     var widgetState;      // Fallback for older version:     try {       widgetState = mimeElement &amp;&amp; JSON.parse(mimeElement.innerHTML);        if (widgetState &amp;&amp; (widgetState.version_major &lt; 2 || !widgetState.version_major)) {         widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';       }     } catch(e) {}      jupyterWidgetsScript.src = widgetRendererSrc;      document.body.appendChild(requireJsScript);     document.body.appendChild(jupyterWidgetsScript);   }    document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }());  <pre><code># pip install deel-lip -qqq\n</code></pre> <pre><code>import numpy as np\nfrom sklearn.datasets import make_moons, make_circles  # the synthetic dataset\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n\n# in order to build our classifier we will use element from tensorflow along with\n# layers from deel-lip\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import ReLU, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import binary_accuracy\n\nfrom deel.lip.model import Model  # use of deel.lip is not mandatory but offers the vanilla_export feature\nfrom deel.lip.layers import SpectralConv2D, SpectralDense, FrobeniusDense\nfrom deel.lip.activations import MaxMin, GroupSort, FullSort, GroupSort2\nfrom deel.lip.losses import HKR, KR, HingeMargin  # custom losses for HKR robust classif\n</code></pre> <pre>\n<code>Matplotlib created a temporary config/cache directory at /tmp/matplotlib-lzatifz2 because the default path (/home/thibaut.boissin/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n2021-09-08 18:23:52.158609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <pre><code>circle_or_moons = 1  # 0 for circle , 1 for moons\nn_samples=5000  # number of sample in the dataset\nnoise=0.05  # amount of noise to add in the data. Tested with 0.14 for circles 0.05 for two moons\nfactor=0.4  # scale factor between the inner and the outer circle\n</code></pre> <pre><code>if circle_or_moons == 0:\n    X,Y=make_circles(n_samples=n_samples,noise=noise,factor=factor)\nelse:\n    X,Y=make_moons(n_samples=n_samples,noise=noise)\n\n# When working with the HKR-classifier, using labels {-1, 1} instead of {0, 1} is advised.\n# This will be explained further on \nY[Y==1]=-1\nY[Y==0]=1\n</code></pre> <pre><code>X1=X[Y==1]\nX2=X[Y==-1]\nsns.scatterplot(X1[:1000,0],X1[:1000,1])\nsns.scatterplot(X2[:1000,0],X2[:1000,1])\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n</code>\n</pre> <pre>\n<code>&lt;AxesSubplot:&gt;</code>\n</pre> <pre><code>batch_size=256\nsteps_per_epoch=40480\nepoch=10\nhidden_layers_size = [256,128,64]  # stucture of the network\nactivation = FullSort  # other lipschitz activation are ReLU, MaxMin, GroupSort2, GroupSort\nmin_margin= 0.29  # minimum margin to enforce between the values of f for each class\n</code></pre> <pre><code># build data generator\ndef otp_generator(batch_size, X, Y):\n    Y_ix = np.array([i for i in range(Y.shape[0])])\n    Y0_ix = Y_ix[Y == 1]\n    Y1_ix = Y_ix[Y == -1]\n    half = Y.shape[0] // 2\n    while True:\n        batch_x = np.zeros(((batch_size,) + (X[0].shape)), dtype=np.float32)\n        batch_y = np.zeros((batch_size, 1), dtype=np.float32)\n        ind = np.random.choice(Y0_ix, size=batch_size // 2, replace=False)\n        batch_x[:batch_size // 2, ] = X[ind]\n        batch_y[:batch_size // 2, 0] = Y[ind]\n        ind = np.random.choice(Y1_ix, size=batch_size // 2, replace=False)\n        batch_x[batch_size // 2:, ] = X[ind]\n        batch_y[batch_size // 2:, 0] = Y[ind]\n\n        yield batch_x, batch_y\ngen=otp_generator(batch_size,X,Y)\n</code></pre> <pre><code>K.clear_session()\n# please note that calling the previous helper function has the exact\n# same effect as the following code:\ninputs = Input((2,))\nx = SpectralDense(256, activation=activation())(inputs)\nx = SpectralDense(128, activation=activation())(x)\nx = SpectralDense(64, activation=activation())(x)\ny = FrobeniusDense(1, activation=None)(x)\nwass = Model(inputs=inputs, outputs=y)\nwass.summary()\n</code></pre> <pre>\n<code>2021-09-08 18:23:54.376987: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:23:54.377747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-08 18:23:54.415033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.415345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:23:54.415372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:23:54.417208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:23:54.417243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:23:54.417819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:23:54.417963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:23:54.419000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:23:54.419454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:23:54.419534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:23:54.419584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.419873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.420126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:23:54.421463: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-08 18:23:54.421518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.421774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.83GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n2021-09-08 18:23:54.421789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:23:54.421800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:23:54.421811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:23:54.421820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-08 18:23:54.421830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-08 18:23:54.421840: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-08 18:23:54.421850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-08 18:23:54.421860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-08 18:23:54.421899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.422177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.422438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-08 18:23:54.422462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-08 18:23:54.700971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-08 18:23:54.700991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-08 18:23:54.700995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-08 18:23:54.701140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.701410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.701645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-08 18:23:54.701868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9056 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n2021-09-08 18:23:54.766864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-08 18:23:55.126952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-08 18:23:55.127037: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n</code>\n</pre> <pre>\n<code>Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 2)]               0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 256)               1537      \n_________________________________________________________________\nspectral_dense_1 (SpectralDe (None, 128)               65793     \n_________________________________________________________________\nspectral_dense_2 (SpectralDe (None, 64)                16513     \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 1)                 129       \n=================================================================\nTotal params: 83,972\nTrainable params: 41,985\nNon-trainable params: 41,987\n_________________________________________________________________\n</code>\n</pre> <p>As we can see the network has a gradient equal to 1 almost everywhere as all the layers respect this property.</p> <p>It is good to note that the last layer is a <code>FrobeniusDense</code> this is because, when we have a single output, it become equivalent to normalize the frobenius norm and the spectral norm (as we only have a single singular value)</p> <pre><code>optimizer = Adam(lr=0.01)\n</code></pre> <pre><code># as the output of our classifier is in the real range [-1, 1], binary accuracy must be redefined\ndef HKR_binary_accuracy(y_true, y_pred):\n    S_true= tf.dtypes.cast(tf.greater_equal(y_true[:,0], 0),dtype=tf.float32)\n    S_pred= tf.dtypes.cast(tf.greater_equal(y_pred[:,0], 0),dtype=tf.float32)\n    return binary_accuracy(S_true,S_pred)\n</code></pre> <pre><code>wass.compile(\n    loss=HKR(alpha=10,min_margin=min_margin),  # HKR stands for the hinge regularized KR loss\n    metrics=[\n        KR,  # shows the KR term of the loss\n        HingeMargin(min_margin=min_margin),  # shows the hinge term of the loss\n        HKR_binary_accuracy  # shows the classification accuracy\n    ],\n    optimizer=optimizer\n)\n</code></pre> <pre><code>wass.fit_generator(\n    gen,\n    steps_per_epoch=steps_per_epoch // batch_size, \n    epochs=epoch,\n    verbose=1\n)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n2021-09-08 18:23:56.416569: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-08 18:23:56.434380: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n</code>\n</pre> <pre>\n<code>Epoch 1/10\n158/158 [==============================] - 4s 13ms/step - loss: 0.6832 - KR: 0.5668 - HingeMargin: 0.1250 - HKR_binary_accuracy: 0.7808\nEpoch 2/10\n158/158 [==============================] - 2s 13ms/step - loss: -0.7488 - KR: 0.9578 - HingeMargin: 0.0209 - HKR_binary_accuracy: 0.9795\nEpoch 3/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.7921 - KR: 0.9734 - HingeMargin: 0.0181 - HKR_binary_accuracy: 0.9865\nEpoch 4/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8035 - KR: 0.9783 - HingeMargin: 0.0175 - HKR_binary_accuracy: 0.9875\nEpoch 5/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8232 - KR: 0.9749 - HingeMargin: 0.0152 - HKR_binary_accuracy: 0.9913\nEpoch 6/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8207 - KR: 0.9690 - HingeMargin: 0.0148 - HKR_binary_accuracy: 0.9920\nEpoch 7/10\n158/158 [==============================] - 2s 12ms/step - loss: -0.8376 - KR: 0.9940 - HingeMargin: 0.0156 - HKR_binary_accuracy: 0.9911\nEpoch 8/10\n158/158 [==============================] - 2s 13ms/step - loss: -0.8252 - KR: 0.9878 - HingeMargin: 0.0163 - HKR_binary_accuracy: 0.9888\nEpoch 9/10\n158/158 [==============================] - 2s 14ms/step - loss: -0.8320 - KR: 0.9810 - HingeMargin: 0.0149 - HKR_binary_accuracy: 0.9926\nEpoch 10/10\n158/158 [==============================] - 2s 13ms/step - loss: -0.8296 - KR: 0.9783 - HingeMargin: 0.0149 - HKR_binary_accuracy: 0.9924\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7eff68093750&gt;</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\nbatch_size=1024\n\nx = np.linspace(X[:,0].min()-0.2, X[:,0].max()+0.2, 120)\ny = np.linspace(X[:,1].min()-0.2, X[:,1].max()+0.2,120)\nxx, yy = np.meshgrid(x, y, sparse=False)\nX_pred=np.stack((xx.ravel(),yy.ravel()),axis=1)\n</code></pre> <pre><code># make predictions of f\npred=wass.predict(X_pred)\n\nY_pred=pred\nY_pred=Y_pred.reshape(x.shape[0],y.shape[0])\n</code></pre> <pre><code>#plot the results\nfig = plt.figure(figsize=(10,7))\nax1 = fig.add_subplot(111)\n\nsns.scatterplot(X[Y==1,0],X[Y==1,1],alpha=0.1,ax=ax1)\nsns.scatterplot(X[Y==-1,0],X[Y==-1,1],alpha=0.1,ax=ax1)\ncset =ax1.contour(xx,yy,Y_pred,cmap='twilight')\nax1.clabel(cset, inline=1, fontsize=10)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n</code>\n</pre> <pre>\n<code>&lt;a list of 7 text.Text objects&gt;</code>\n</pre> <pre><code>from deel.lip.model import vanillaModel\n## this is equivalent to test2 = wass.vanilla_export()\ntest2 = vanillaModel(wass)\ntest2.summary()\n</code></pre> <pre>\n<code>Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 2)]               0         \n_________________________________________________________________\nspectral_dense (Dense)       (None, 256)               768       \n_________________________________________________________________\nspectral_dense_1 (Dense)     (None, 128)               32896     \n_________________________________________________________________\nspectral_dense_2 (Dense)     (None, 64)                8256      \n_________________________________________________________________\nfrobenius_dense (Dense)      (None, 1)                 65        \n=================================================================\nTotal params: 41,985\nTrainable params: 41,985\nNon-trainable params: 0\n_________________________________________________________________\n</code>\n</pre> <pre><code>pred_test=test2.predict(X_pred)\nY_pred=pred_test\nY_pred=Y_pred.reshape(x.shape[0],y.shape[0])\n</code></pre> <pre><code>fig = plt.figure(figsize=(10,7))\nax1 = fig.add_subplot(111)\n#ax2 = fig.add_subplot(312)\n#ax3 = fig.add_subplot(313)\nsns.scatterplot(X[Y==1,0],X[Y==1,1],alpha=0.1,ax=ax1)\nsns.scatterplot(X[Y==-1,0],X[Y==-1,1],alpha=0.1,ax=ax1)\ncset =ax1.contour(xx,yy,Y_pred,cmap='twilight')\nax1.clabel(cset, inline=1, fontsize=10)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n/home/thibaut.boissin/envs/tf24/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n</code>\n</pre> <pre>\n<code>&lt;a list of 7 text.Text objects&gt;</code>\n</pre>"},{"location":"notebooks/demo2/#demo-2-hkr-classifier-on-toy-dataset","title":"Demo 2: HKR Classifier on toy dataset","text":"<p>In this demo notebook we will show how to build a robust classifier based on the regularized version of the Kantorovitch-Rubinstein duality. We will perform this on the <code>two moons</code> synthetic dataset.</p>"},{"location":"notebooks/demo2/#parameters","title":"Parameters","text":"<p>Let's first construct our two moons dataset</p>"},{"location":"notebooks/demo2/#relation-with-optimal-transport","title":"Relation with optimal transport","text":"<p>In this setup we can solve the optimal transport problem between the distribution of <code>X[Y==1]</code> and <code>X[Y==-1]</code>. This usually require to match each element of the first distribution with an element of the second distribution such that this minimize a global cost. In our setup this cost is the $ l_1 $ distance, which will allow us to make use of the KR dual formulation. The overall cost  is then the \\(W_1\\) distance.</p>"},{"location":"notebooks/demo2/#wasserstein-distance","title":"Wasserstein distance","text":"<p>The wasserstein distance measure the distance between two probability distribution. Wikipedia article gives a more intuitive definition of it:</p> <p>Intuitively, if each distribution is viewed as a unit amount of \"dirt\" piled on {\\displaystyle M}M, the metric is the minimum \"cost\" of turning one pile into the other, which is assumed to be the amount of dirt that needs to be moved times the mean distance it has to be moved. Because of this analogy, the metric is known in computer science as the earth mover's distance.</p> <p>Mathematically it is defined as:</p> \\[ W_1(\\mu,\\nu) = \\inf_{\\pi \\in \\Pi(\\mu,\\nu)}\\underset{x,z \\sim \\pi}{\\mathbb{E}}\\parallel \\textbf{x}-\\textbf{z} \\parallel \\] <p>where \\(\\Pi(\\mu,\\nu)\\) is the set of all probability measures on \\(\\Omega\\times \\Omega\\) with marginals \\(\\mu\\) and \\(\\nu\\). In most case this equation is not tractable.</p> <p>However the \\(W_1\\) distance is known to be untractable in general.</p>"},{"location":"notebooks/demo2/#kr-dual-formulation","title":"KR dual formulation","text":"<p>In our setup, the KR dual formulation is stated as following: $$ W_1(\\mu, \\nu) = \\sup_{f \\in Lip_1(\\Omega)} \\underset{\\textbf{x} \\sim \\mu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] -\\underset{\\textbf{x}  \\sim \\nu}{\\mathbb{E}} \\left[f(\\textbf{x} )\\right] $$</p> <p>This state the problem as an optimization problem over the 1-lipschitz functions. Therefore k-Lipschitz networks allows us to solve this maximization problem.</p>"},{"location":"notebooks/demo2/#hinge-kr-classification","title":"Hinge-KR classification","text":"<p>When dealing with \\(W_1\\) one may note that many functions maximize the maximization problem described above. Also we want this function to be meaningfull in terms of classification. To do so, we want f to be centered in 0, which can be done without altering the inital problem. By doing so we can use the obtained function for binary classification, by looking at the sign of \\(f\\).</p> <p>In order to enforce this, we will add a Hinge term to the loss. It has been shown that this new problem is still a optimal transport problem and that this problem admit a meaningfull optimal solution.</p>"},{"location":"notebooks/demo2/#hkr-classifier","title":"HKR-Classifier","text":"<p>Now we will show how to build a binary classifier based on the regularized version of the KR dual problem.</p> <p>In order to ensure the 1-Lipschitz constraint <code>deel-lip</code> uses spectral normalization. These layers also can also use Bjork orthonormalization to ensure that the gradient of the layer is 1 almost everywhere. Experiment shows that the optimal solution lie in this sub-class of functions.</p>"},{"location":"notebooks/demo2/#build-lipschitz-model","title":"Build lipschitz Model","text":"<p>Let's build our model now.</p>"},{"location":"notebooks/demo2/#learn-classification-on-toy-dataset","title":"Learn classification on toy dataset","text":"<p>Now we are ready to learn the classification task on the two moons dataset.</p>"},{"location":"notebooks/demo2/#plot-output-countour-line","title":"Plot output countour line","text":"<p>As we can see the classifier get a pretty good accuracy. Let's now take a look at the learnt function.  As we are in the 2D space, we can draw a countour plot to visualize f.</p>"},{"location":"notebooks/demo2/#transfer-network-to-a-classical-mlp-and-compare-outputs","title":"Transfer network to a classical MLP and compare outputs","text":"<p>As we saw, our networks use custom layers in order to constrain training. However during inference layers behave exactly as regular <code>Dense</code> or <code>Conv2d</code> layers. Deel-lip has a functionnality to export a model to it's vanilla keras equivalent. Making it more  convenient for inference.</p>"},{"location":"notebooks/demo3/","title":"Demo 3: HKR Classifier on MNIST dataset","text":"(function() {   function addWidgetsRenderer() {     var requireJsScript = document.createElement('script');     requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';      var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]');     var jupyterWidgetsScript = document.createElement('script');     var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';     var widgetState;      // Fallback for older version:     try {       widgetState = mimeElement &amp;&amp; JSON.parse(mimeElement.innerHTML);        if (widgetState &amp;&amp; (widgetState.version_major &lt; 2 || !widgetState.version_major)) {         widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';       }     } catch(e) {}      jupyterWidgetsScript.src = widgetRendererSrc;      document.body.appendChild(requireJsScript);     document.body.appendChild(jupyterWidgetsScript);   }    document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }());  <pre><code># pip install deel-lip -qqq\n</code></pre> <pre><code>import tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.python.keras.layers import Input, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import binary_accuracy\nfrom tensorflow.keras.models import Sequential\n\nfrom deel.lip.layers import (\n    SpectralConv2D,\n    SpectralDense,\n    FrobeniusDense,\n    ScaledL2NormPooling2D,\n)\nfrom deel.lip.activations import MaxMin, GroupSort, GroupSort2, FullSort\nfrom deel.lip.losses import HKR, KR, HingeMargin\n</code></pre> <pre>\n<code>2021-09-08 18:34:34.803681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <pre><code>from tensorflow.keras.datasets import mnist\n\n# first we select the two classes\nselected_classes = [0, 8]  # must be two classes as we perform binary classification\n\n\ndef prepare_data(x, y, class_a=0, class_b=8):\n\"\"\"\n    This function convert the MNIST data to make it suitable for our binary classification\n    setup.\n    \"\"\"\n    # select items from the two selected classes\n    mask = (y == class_a) + (\n        y == class_b\n    )  # mask to select only items from class_a or class_b\n    x = x[mask]\n    y = y[mask]\n    x = x.astype(\"float32\")\n    y = y.astype(\"float32\")\n    # convert from range int[0,255] to float32[-1,1]\n    x /= 255\n    x = x.reshape((-1, 28, 28, 1))\n    # change label to binary classification {-1,1}\n    y[y == class_a] = 1.0\n    y[y == class_b] = -1.0\n    return x, y\n\n\n# now we load the dataset\n(x_train, y_train_ord), (x_test, y_test_ord) = mnist.load_data()\n\n# prepare the data\nx_train, y_train = prepare_data(\n    x_train, y_train_ord, selected_classes[0], selected_classes[1]\n)\nx_test, y_test = prepare_data(\n    x_test, y_test_ord, selected_classes[0], selected_classes[1]\n)\n\n# display infos about dataset\nprint(\n    \"train set size: %i samples, classes proportions: %.3f percent\"\n    % (y_train.shape[0], 100 * y_train[y_train == 1].sum() / y_train.shape[0])\n)\nprint(\n    \"test set size: %i samples, classes proportions: %.3f percent\"\n    % (y_test.shape[0], 100 * y_test[y_test == 1].sum() / y_test.shape[0])\n)\n</code></pre> <pre>\n<code>train set size: 11774 samples, classes proportions: 50.306 percent\ntest set size: 1954 samples, classes proportions: 50.154 percent\n</code>\n</pre> <pre><code># training parameters\nepochs = 10\nbatch_size = 128\n\n# network parameters\nactivation = GroupSort  # ReLU, MaxMin, GroupSort2\n\n# loss parameters\nmin_margin = 1.0\nalpha = 10.0\n</code></pre> <p>Now we can build the network. Here the experiment is done with a MLP. But <code>Deel-lip</code> also provide state of the art 1-Lipschitz convolutions.</p> <pre><code>K.clear_session()\n# helper function to build the 1-lipschitz MLP\nwass = Sequential(\n    layers=[\n        Input((28, 28, 1)),\n        Flatten(),\n        SpectralDense(32, GroupSort2(), use_bias=True),\n        SpectralDense(16, GroupSort2(), use_bias=True),\n        FrobeniusDense(1, activation=None, use_bias=False),\n    ],\n    name=\"lipModel\",\n)\nwass.summary()\n</code></pre> <pre>\n<code>Model: \"lipModel\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 32)                50241     \n_________________________________________________________________\nspectral_dense_1 (SpectralDe (None, 16)                1057      \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 1)                 32        \n=================================================================\nTotal params: 51,330\nTrainable params: 25,664\nNon-trainable params: 25,666\n_________________________________________________________________\n</code>\n</pre> <pre><code>optimizer = Adam(lr=0.001)\n</code></pre> <pre><code># as the output of our classifier is in the real range [-1, 1], binary accuracy must be redefined\ndef HKR_binary_accuracy(y_true, y_pred):\n    S_true = tf.dtypes.cast(tf.greater_equal(y_true[:, 0], 0), dtype=tf.float32)\n    S_pred = tf.dtypes.cast(tf.greater_equal(y_pred[:, 0], 0), dtype=tf.float32)\n    return binary_accuracy(S_true, S_pred)\n</code></pre> <pre><code>wass.compile(\n    loss=HKR(\n        alpha=alpha, min_margin=min_margin\n    ),  # HKR stands for the hinge regularized KR loss\n    metrics=[\n        KR,  # shows the KR term of the loss\n        HingeMargin(min_margin=min_margin),  # shows the hinge term of the loss\n        HKR_binary_accuracy,  # shows the classification accuracy\n    ],\n    optimizer=optimizer,\n)\n</code></pre> <pre><code>wass.fit(\n    x=x_train,\n    y=y_train,\n    validation_data=(x_test, y_test),\n    batch_size=batch_size,\n    shuffle=True,\n    epochs=epochs,\n    verbose=1,\n)\n</code></pre> <pre>\n<code>Epoch 1/10\n92/92 [==============================] - 2s 10ms/step - loss: -1.6675 - KR: 3.7144 - HingeMargin: 0.2047 - HKR_binary_accuracy: 0.9382 - val_loss: -5.0961 - val_KR: 5.5990 - val_HingeMargin: 0.0519 - val_HKR_binary_accuracy: 0.9786\nEpoch 2/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.0297 - KR: 5.5716 - HingeMargin: 0.0542 - HKR_binary_accuracy: 0.9793 - val_loss: -5.4469 - val_KR: 5.7710 - val_HingeMargin: 0.0354 - val_HKR_binary_accuracy: 0.9879\nEpoch 3/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.3788 - KR: 5.7838 - HingeMargin: 0.0405 - HKR_binary_accuracy: 0.9858 - val_loss: -5.6435 - val_KR: 5.9555 - val_HingeMargin: 0.0334 - val_HKR_binary_accuracy: 0.9860\nEpoch 4/10\n92/92 [==============================] - 1s 8ms/step - loss: -5.6172 - KR: 5.9671 - HingeMargin: 0.0350 - HKR_binary_accuracy: 0.9874 - val_loss: -5.7918 - val_KR: 6.0764 - val_HingeMargin: 0.0308 - val_HKR_binary_accuracy: 0.9879\nEpoch 5/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.7598 - KR: 6.0676 - HingeMargin: 0.0308 - HKR_binary_accuracy: 0.9891 - val_loss: -5.8711 - val_KR: 6.1062 - val_HingeMargin: 0.0264 - val_HKR_binary_accuracy: 0.9899\nEpoch 6/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.7647 - KR: 6.0829 - HingeMargin: 0.0318 - HKR_binary_accuracy: 0.9879 - val_loss: -5.8503 - val_KR: 6.1463 - val_HingeMargin: 0.0315 - val_HKR_binary_accuracy: 0.9879\nEpoch 7/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8007 - KR: 6.1082 - HingeMargin: 0.0307 - HKR_binary_accuracy: 0.9884 - val_loss: -5.8470 - val_KR: 6.1179 - val_HingeMargin: 0.0296 - val_HKR_binary_accuracy: 0.9879\nEpoch 8/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8268 - KR: 6.1185 - HingeMargin: 0.0292 - HKR_binary_accuracy: 0.9897 - val_loss: -5.8439 - val_KR: 6.1153 - val_HingeMargin: 0.0294 - val_HKR_binary_accuracy: 0.9889\nEpoch 9/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8865 - KR: 6.1548 - HingeMargin: 0.0268 - HKR_binary_accuracy: 0.9910 - val_loss: -5.8800 - val_KR: 6.1668 - val_HingeMargin: 0.0312 - val_HKR_binary_accuracy: 0.9874\nEpoch 10/10\n92/92 [==============================] - 1s 7ms/step - loss: -5.8578 - KR: 6.1453 - HingeMargin: 0.0288 - HKR_binary_accuracy: 0.9892 - val_loss: -5.9233 - val_KR: 6.1783 - val_HingeMargin: 0.0282 - val_HKR_binary_accuracy: 0.9889\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7fce2c6635d0&gt;</code>\n</pre> <p>As we can see the model reach a very decent accuracy on this task.</p>"},{"location":"notebooks/demo3/#demo-3-hkr-classifier-on-mnist-dataset","title":"Demo 3: HKR classifier on MNIST dataset","text":"<p>This notebook will demonstrate learning a binary task on the MNIST0-8 dataset.</p>"},{"location":"notebooks/demo3/#data-preparation","title":"data preparation","text":"<p>For this task we will select two classes: 0 and 8. Labels are changed to {-1,1}, wich is compatible with the Hinge term used in the loss.</p>"},{"location":"notebooks/demo3/#build-lipschitz-model","title":"Build lipschitz Model","text":"<p>Let's first explicit the paremeters of this experiment</p>"},{"location":"notebooks/demo3/#learn-classification-on-mnist","title":"Learn classification on MNIST","text":"<p>Now the model is build, we can learn the task.</p>"},{"location":"notebooks/demo4/","title":"Demo 4: HKR Multiclass and fooling","text":"(function() {   function addWidgetsRenderer() {     var requireJsScript = document.createElement('script');     requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';      var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]');     var jupyterWidgetsScript = document.createElement('script');     var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';     var widgetState;      // Fallback for older version:     try {       widgetState = mimeElement &amp;&amp; JSON.parse(mimeElement.innerHTML);        if (widgetState &amp;&amp; (widgetState.version_major &lt; 2 || !widgetState.version_major)) {         widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';       }     } catch(e) {}      jupyterWidgetsScript.src = widgetRendererSrc;      document.body.appendChild(requireJsScript);     document.body.appendChild(jupyterWidgetsScript);   }    document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }());  <pre><code># pip install deel-lip foolbox -qqq\n</code></pre> <pre><code>from deel.lip.layers import (\n    SpectralDense,\n    SpectralConv2D,\n    ScaledL2NormPooling2D,\n    ScaledAveragePooling2D,\n    FrobeniusDense,\n)\nfrom deel.lip.model import Sequential\nfrom deel.lip.activations import GroupSort, FullSort\nfrom deel.lip.losses import MulticlassHKR, MulticlassKR\nfrom deel.lip.callbacks import CondenseCallback\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n</code></pre> <pre>\n<code>2021-09-09 14:03:36.448213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n</code>\n</pre> <p>For this example, the dataset <code>fashion_mnist</code> will be used. In order to keep things simple, no data augmentation will be performed.</p> <pre><code># load data\n(x_train, y_train_ord), (x_test, y_test_ord) = fashion_mnist.load_data()\n# standardize and reshape the data\nx_train = np.expand_dims(x_train, -1) / 255\nx_test = np.expand_dims(x_test, -1) / 255\n# one hot encode the labels\ny_train = to_categorical(y_train_ord)\ny_test = to_categorical(y_test_ord)\n</code></pre> <p>Let's build the network. </p> <pre><code># Sequential (resp Model) from deel.model has the same properties as any lipschitz model.\n# It act only as a container, with features specific to lipschitz\n# functions (condensation, vanilla_exportation...)\nmodel = Sequential(\n    [\n        Input(shape=x_train.shape[1:]),\n        # Lipschitz layers preserve the API of their superclass ( here Conv2D )\n        # an optional param is available: k_coef_lip which control the lipschitz\n        # constant of the layer\n        SpectralConv2D(\n            filters=16,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        # usual pooling layer are implemented (avg, max...), but new layers are also available\n      ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        SpectralConv2D(\n            filters=32,\n            kernel_size=(3, 3),\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n      ScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n        # our layers are fully interoperable with existing keras layers\n        Flatten(),\n        SpectralDense(\n            64,\n            activation=GroupSort(2),\n            use_bias=True,\n            kernel_initializer=\"orthogonal\",\n        ),\n        FrobeniusDense(\n            y_train.shape[-1], activation=None, use_bias=False, kernel_initializer=\"orthogonal\"\n        ),\n    ],\n    # similary model has a parameter to set the lipschitz constant\n    # to set automatically the constant of each layer\n    k_coef_lip=1.0,\n    name=\"hkr_model\",\n)\n\n# HKR (Hinge-Krantorovich-Rubinstein) optimize robustness along with accuracy\nmodel.compile(\n    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n    # note also in the case of lipschitz networks, more robustness require more parameters.\n    loss=MulticlassHKR(alpha=100, min_margin=.25),\n    optimizer=Adam(1e-4),\n    metrics=[\"accuracy\", MulticlassKR()],\n)\n\nmodel.summary()\n</code></pre> <pre>\n<code>2021-09-09 14:03:38.719310: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-09 14:03:38.719800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-09 14:03:38.750242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.750491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\ncoreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n2021-09-09 14:03:38.750504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-09 14:03:38.751559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-09 14:03:38.751584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-09 14:03:38.752047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-09 14:03:38.752161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-09 14:03:38.753239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-09 14:03:38.753476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-09 14:03:38.753540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-09 14:03:38.753583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.753826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.754040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-09 14:03:38.754479: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-09 14:03:38.754559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.754781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\ncoreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n2021-09-09 14:03:38.754792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-09 14:03:38.754799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-09 14:03:38.754806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-09 14:03:38.754812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-09 14:03:38.754818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-09 14:03:38.754824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-09 14:03:38.754831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-09 14:03:38.754837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-09 14:03:38.754865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.755095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:38.755303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-09 14:03:38.755319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-09 14:03:39.211037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-09 14:03:39.211059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-09 14:03:39.211064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-09 14:03:39.211182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:39.211426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:39.211643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-09 14:03:39.211849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7250 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\n</code>\n</pre> <pre>\n<code>Model: \"hkr_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nspectral_conv2d (SpectralCon (None, 28, 28, 16)        321       \n_________________________________________________________________\nscaled_l2norm_pooling2d (Sca (None, 14, 14, 16)        0         \n_________________________________________________________________\nspectral_conv2d_1 (SpectralC (None, 14, 14, 32)        9281      \n_________________________________________________________________\nscaled_l2norm_pooling2d_1 (S (None, 7, 7, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1568)              0         \n_________________________________________________________________\nspectral_dense (SpectralDens (None, 64)                200833    \n_________________________________________________________________\nfrobenius_dense (FrobeniusDe (None, 10)                1280      \n=================================================================\nTotal params: 211,715\nTrainable params: 105,856\nNon-trainable params: 105,859\n_________________________________________________________________\n</code>\n</pre> <pre>\n<code>/home/thibaut.boissin/projects/repo_github/deel-lip/deel/lip/model.py:56: UserWarning: Sequential model contains a layer wich is not a Lipschitz layer: flatten\n  layer.name\n</code>\n</pre> <pre><code># fit the model\nmodel.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=100,\n    validation_data=(x_test, y_test),\n    shuffle=True,\n    verbose=1,\n)\n</code></pre> <pre>\n<code>2021-09-09 14:03:40.083840: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-09 14:03:40.100871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n</code>\n</pre> <pre>\n<code>Epoch 1/100\n</code>\n</pre> <pre>\n<code>2021-09-09 14:03:42.102055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-09 14:03:42.320388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-09 14:03:42.331382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n</code>\n</pre> <pre>\n<code>15/15 [==============================] - 5s 117ms/step - loss: 41.2174 - accuracy: 0.1382 - MulticlassKR: 0.0467 - val_loss: 29.5743 - val_accuracy: 0.2798 - val_MulticlassKR: 0.1810\nEpoch 2/100\n15/15 [==============================] - 1s 81ms/step - loss: 25.3826 - accuracy: 0.4441 - MulticlassKR: 0.2389 - val_loss: 19.8280 - val_accuracy: 0.5547 - val_MulticlassKR: 0.3549\nEpoch 3/100\n15/15 [==============================] - 1s 81ms/step - loss: 18.3231 - accuracy: 0.5899 - MulticlassKR: 0.4017 - val_loss: 16.0346 - val_accuracy: 0.6183 - val_MulticlassKR: 0.4835\nEpoch 4/100\n15/15 [==============================] - 1s 81ms/step - loss: 15.0896 - accuracy: 0.6402 - MulticlassKR: 0.5135 - val_loss: 13.9297 - val_accuracy: 0.6470 - val_MulticlassKR: 0.5607\nEpoch 5/100\n15/15 [==============================] - 1s 81ms/step - loss: 13.2237 - accuracy: 0.6814 - MulticlassKR: 0.5821 - val_loss: 12.5531 - val_accuracy: 0.6814 - val_MulticlassKR: 0.6186\nEpoch 6/100\n15/15 [==============================] - 1s 81ms/step - loss: 12.0225 - accuracy: 0.7057 - MulticlassKR: 0.6364 - val_loss: 11.6916 - val_accuracy: 0.6964 - val_MulticlassKR: 0.6655\nEpoch 7/100\n15/15 [==============================] - 1s 81ms/step - loss: 11.2456 - accuracy: 0.7178 - MulticlassKR: 0.6803 - val_loss: 11.0661 - val_accuracy: 0.7131 - val_MulticlassKR: 0.7020\nEpoch 8/100\n15/15 [==============================] - 1s 81ms/step - loss: 10.7023 - accuracy: 0.7343 - MulticlassKR: 0.7144 - val_loss: 10.6094 - val_accuracy: 0.7190 - val_MulticlassKR: 0.7339\nEpoch 9/100\n15/15 [==============================] - 1s 81ms/step - loss: 10.2158 - accuracy: 0.7353 - MulticlassKR: 0.7471 - val_loss: 10.2140 - val_accuracy: 0.7255 - val_MulticlassKR: 0.7639\nEpoch 10/100\n15/15 [==============================] - 1s 80ms/step - loss: 9.9306 - accuracy: 0.7444 - MulticlassKR: 0.7743 - val_loss: 9.8911 - val_accuracy: 0.7341 - val_MulticlassKR: 0.7875\nEpoch 11/100\n15/15 [==============================] - 1s 80ms/step - loss: 9.4766 - accuracy: 0.7500 - MulticlassKR: 0.8008 - val_loss: 9.5676 - val_accuracy: 0.7397 - val_MulticlassKR: 0.8139\nEpoch 12/100\n15/15 [==============================] - 1s 80ms/step - loss: 9.2583 - accuracy: 0.7547 - MulticlassKR: 0.8227 - val_loss: 9.3108 - val_accuracy: 0.7445 - val_MulticlassKR: 0.8375\nEpoch 13/100\n15/15 [==============================] - 1s 81ms/step - loss: 9.0268 - accuracy: 0.7571 - MulticlassKR: 0.8463 - val_loss: 9.0594 - val_accuracy: 0.7461 - val_MulticlassKR: 0.8565\nEpoch 14/100\n15/15 [==============================] - 1s 80ms/step - loss: 8.7289 - accuracy: 0.7631 - MulticlassKR: 0.8653 - val_loss: 8.8221 - val_accuracy: 0.7563 - val_MulticlassKR: 0.8798\nEpoch 15/100\n15/15 [==============================] - 1s 81ms/step - loss: 8.5468 - accuracy: 0.7660 - MulticlassKR: 0.8856 - val_loss: 8.6213 - val_accuracy: 0.7566 - val_MulticlassKR: 0.8976\nEpoch 16/100\n15/15 [==============================] - 1s 80ms/step - loss: 8.3208 - accuracy: 0.7699 - MulticlassKR: 0.9078 - val_loss: 8.4393 - val_accuracy: 0.7672 - val_MulticlassKR: 0.9187\nEpoch 17/100\n15/15 [==============================] - 1s 80ms/step - loss: 8.1348 - accuracy: 0.7747 - MulticlassKR: 0.9288 - val_loss: 8.2421 - val_accuracy: 0.7644 - val_MulticlassKR: 0.9369\nEpoch 18/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.8150 - accuracy: 0.7807 - MulticlassKR: 0.9479 - val_loss: 8.0528 - val_accuracy: 0.7741 - val_MulticlassKR: 0.9598\nEpoch 19/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.7277 - accuracy: 0.7813 - MulticlassKR: 0.9697 - val_loss: 7.8976 - val_accuracy: 0.7749 - val_MulticlassKR: 0.9754\nEpoch 20/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.5802 - accuracy: 0.7822 - MulticlassKR: 0.9866 - val_loss: 7.7375 - val_accuracy: 0.7784 - val_MulticlassKR: 0.9936\nEpoch 21/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.3151 - accuracy: 0.7893 - MulticlassKR: 1.0068 - val_loss: 7.5871 - val_accuracy: 0.7818 - val_MulticlassKR: 1.0131\nEpoch 22/100\n15/15 [==============================] - 1s 81ms/step - loss: 7.2699 - accuracy: 0.7901 - MulticlassKR: 1.0211 - val_loss: 7.4710 - val_accuracy: 0.7807 - val_MulticlassKR: 1.0305\nEpoch 23/100\n15/15 [==============================] - 1s 83ms/step - loss: 7.1052 - accuracy: 0.7939 - MulticlassKR: 1.0391 - val_loss: 7.3397 - val_accuracy: 0.7854 - val_MulticlassKR: 1.0450\nEpoch 24/100\n15/15 [==============================] - 1s 80ms/step - loss: 7.0167 - accuracy: 0.7962 - MulticlassKR: 1.0562 - val_loss: 7.2212 - val_accuracy: 0.7870 - val_MulticlassKR: 1.0637\nEpoch 25/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.8205 - accuracy: 0.8002 - MulticlassKR: 1.0749 - val_loss: 7.1256 - val_accuracy: 0.7895 - val_MulticlassKR: 1.0808\nEpoch 26/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.7542 - accuracy: 0.8013 - MulticlassKR: 1.0923 - val_loss: 7.0068 - val_accuracy: 0.7897 - val_MulticlassKR: 1.0966\nEpoch 27/100\n15/15 [==============================] - 1s 81ms/step - loss: 6.6025 - accuracy: 0.8022 - MulticlassKR: 1.1069 - val_loss: 6.8967 - val_accuracy: 0.7924 - val_MulticlassKR: 1.1105\nEpoch 28/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.5729 - accuracy: 0.8033 - MulticlassKR: 1.1220 - val_loss: 6.8168 - val_accuracy: 0.7951 - val_MulticlassKR: 1.1275\nEpoch 29/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.5147 - accuracy: 0.8074 - MulticlassKR: 1.1347 - val_loss: 6.7141 - val_accuracy: 0.7971 - val_MulticlassKR: 1.1425\nEpoch 30/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.4094 - accuracy: 0.8059 - MulticlassKR: 1.1528 - val_loss: 6.6193 - val_accuracy: 0.7998 - val_MulticlassKR: 1.1605\nEpoch 31/100\n15/15 [==============================] - 1s 82ms/step - loss: 6.3102 - accuracy: 0.8090 - MulticlassKR: 1.1664 - val_loss: 6.5371 - val_accuracy: 0.8005 - val_MulticlassKR: 1.1746\nEpoch 32/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.1902 - accuracy: 0.8078 - MulticlassKR: 1.1889 - val_loss: 6.4705 - val_accuracy: 0.8004 - val_MulticlassKR: 1.1924\nEpoch 33/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.1780 - accuracy: 0.8127 - MulticlassKR: 1.1991 - val_loss: 6.3850 - val_accuracy: 0.8033 - val_MulticlassKR: 1.2076\nEpoch 34/100\n15/15 [==============================] - 1s 80ms/step - loss: 6.1156 - accuracy: 0.8123 - MulticlassKR: 1.2147 - val_loss: 6.3106 - val_accuracy: 0.8091 - val_MulticlassKR: 1.2191\nEpoch 35/100\n15/15 [==============================] - 1s 81ms/step - loss: 6.0083 - accuracy: 0.8143 - MulticlassKR: 1.2322 - val_loss: 6.2621 - val_accuracy: 0.8086 - val_MulticlassKR: 1.2360\nEpoch 36/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.9177 - accuracy: 0.8158 - MulticlassKR: 1.2462 - val_loss: 6.1842 - val_accuracy: 0.8101 - val_MulticlassKR: 1.2483\nEpoch 37/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7953 - accuracy: 0.8186 - MulticlassKR: 1.2662 - val_loss: 6.1092 - val_accuracy: 0.8119 - val_MulticlassKR: 1.2654\nEpoch 38/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7620 - accuracy: 0.8179 - MulticlassKR: 1.2781 - val_loss: 6.0499 - val_accuracy: 0.8126 - val_MulticlassKR: 1.2815\nEpoch 39/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7588 - accuracy: 0.8187 - MulticlassKR: 1.2897 - val_loss: 5.9959 - val_accuracy: 0.8131 - val_MulticlassKR: 1.2936\nEpoch 40/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.7005 - accuracy: 0.8208 - MulticlassKR: 1.3042 - val_loss: 5.9460 - val_accuracy: 0.8152 - val_MulticlassKR: 1.3039\nEpoch 41/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.6319 - accuracy: 0.8232 - MulticlassKR: 1.3146 - val_loss: 5.8816 - val_accuracy: 0.8148 - val_MulticlassKR: 1.3217\nEpoch 42/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.6429 - accuracy: 0.8232 - MulticlassKR: 1.3291 - val_loss: 5.8772 - val_accuracy: 0.8151 - val_MulticlassKR: 1.3317\nEpoch 43/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.5395 - accuracy: 0.8245 - MulticlassKR: 1.3460 - val_loss: 5.8039 - val_accuracy: 0.8189 - val_MulticlassKR: 1.3538\nEpoch 44/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.4303 - accuracy: 0.8249 - MulticlassKR: 1.3593 - val_loss: 5.7421 - val_accuracy: 0.8189 - val_MulticlassKR: 1.3669\nEpoch 45/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.3844 - accuracy: 0.8268 - MulticlassKR: 1.3762 - val_loss: 5.6846 - val_accuracy: 0.8217 - val_MulticlassKR: 1.3765\nEpoch 46/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.3307 - accuracy: 0.8281 - MulticlassKR: 1.3873 - val_loss: 5.6413 - val_accuracy: 0.8234 - val_MulticlassKR: 1.3881\nEpoch 47/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.3788 - accuracy: 0.8258 - MulticlassKR: 1.3938 - val_loss: 5.6087 - val_accuracy: 0.8214 - val_MulticlassKR: 1.3971\nEpoch 48/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.2561 - accuracy: 0.8314 - MulticlassKR: 1.4119 - val_loss: 5.5684 - val_accuracy: 0.8215 - val_MulticlassKR: 1.4106\nEpoch 49/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.2374 - accuracy: 0.8276 - MulticlassKR: 1.4266 - val_loss: 5.5116 - val_accuracy: 0.8255 - val_MulticlassKR: 1.4254\nEpoch 50/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.2404 - accuracy: 0.8299 - MulticlassKR: 1.4328 - val_loss: 5.4923 - val_accuracy: 0.8248 - val_MulticlassKR: 1.4351\nEpoch 51/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.2273 - accuracy: 0.8302 - MulticlassKR: 1.4446 - val_loss: 5.4473 - val_accuracy: 0.8252 - val_MulticlassKR: 1.4494\nEpoch 52/100\n15/15 [==============================] - 1s 80ms/step - loss: 5.1193 - accuracy: 0.8302 - MulticlassKR: 1.4615 - val_loss: 5.4205 - val_accuracy: 0.8219 - val_MulticlassKR: 1.4643\nEpoch 53/100\n15/15 [==============================] - 1s 81ms/step - loss: 5.1053 - accuracy: 0.8338 - MulticlassKR: 1.4739 - val_loss: 5.3770 - val_accuracy: 0.8238 - val_MulticlassKR: 1.4766\nEpoch 54/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.9836 - accuracy: 0.8338 - MulticlassKR: 1.4889 - val_loss: 5.3285 - val_accuracy: 0.8259 - val_MulticlassKR: 1.4896\nEpoch 55/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.9996 - accuracy: 0.8337 - MulticlassKR: 1.4994 - val_loss: 5.3168 - val_accuracy: 0.8272 - val_MulticlassKR: 1.4970\nEpoch 56/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.9064 - accuracy: 0.8372 - MulticlassKR: 1.5095 - val_loss: 5.2652 - val_accuracy: 0.8284 - val_MulticlassKR: 1.5102\nEpoch 57/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.9659 - accuracy: 0.8335 - MulticlassKR: 1.5204 - val_loss: 5.2111 - val_accuracy: 0.8284 - val_MulticlassKR: 1.5191\nEpoch 58/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.9272 - accuracy: 0.8351 - MulticlassKR: 1.5316 - val_loss: 5.1873 - val_accuracy: 0.8310 - val_MulticlassKR: 1.5290\nEpoch 59/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.8504 - accuracy: 0.8367 - MulticlassKR: 1.5386 - val_loss: 5.1892 - val_accuracy: 0.8263 - val_MulticlassKR: 1.5440\nEpoch 60/100\n15/15 [==============================] - 1s 82ms/step - loss: 4.7810 - accuracy: 0.8399 - MulticlassKR: 1.5500 - val_loss: 5.1203 - val_accuracy: 0.8298 - val_MulticlassKR: 1.5517\nEpoch 61/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.7313 - accuracy: 0.8394 - MulticlassKR: 1.5630 - val_loss: 5.1206 - val_accuracy: 0.8292 - val_MulticlassKR: 1.5662\nEpoch 62/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.7666 - accuracy: 0.8406 - MulticlassKR: 1.5742 - val_loss: 5.0925 - val_accuracy: 0.8295 - val_MulticlassKR: 1.5692\nEpoch 63/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.6527 - accuracy: 0.8418 - MulticlassKR: 1.5808 - val_loss: 5.0593 - val_accuracy: 0.8302 - val_MulticlassKR: 1.5836\nEpoch 64/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.7434 - accuracy: 0.8410 - MulticlassKR: 1.5952 - val_loss: 5.0201 - val_accuracy: 0.8329 - val_MulticlassKR: 1.5966\nEpoch 65/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.7347 - accuracy: 0.8386 - MulticlassKR: 1.6056 - val_loss: 5.0073 - val_accuracy: 0.8337 - val_MulticlassKR: 1.6002\nEpoch 66/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.6701 - accuracy: 0.8414 - MulticlassKR: 1.6104 - val_loss: 4.9744 - val_accuracy: 0.8345 - val_MulticlassKR: 1.6125\nEpoch 67/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.5813 - accuracy: 0.8430 - MulticlassKR: 1.6230 - val_loss: 4.9599 - val_accuracy: 0.8336 - val_MulticlassKR: 1.6252\nEpoch 68/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.6265 - accuracy: 0.8420 - MulticlassKR: 1.6316 - val_loss: 4.9260 - val_accuracy: 0.8310 - val_MulticlassKR: 1.6337\nEpoch 69/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.6232 - accuracy: 0.8426 - MulticlassKR: 1.6420 - val_loss: 4.8940 - val_accuracy: 0.8365 - val_MulticlassKR: 1.6376\nEpoch 70/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.5432 - accuracy: 0.8430 - MulticlassKR: 1.6507 - val_loss: 4.8714 - val_accuracy: 0.8355 - val_MulticlassKR: 1.6471\nEpoch 71/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.4822 - accuracy: 0.8438 - MulticlassKR: 1.6584 - val_loss: 4.8362 - val_accuracy: 0.8358 - val_MulticlassKR: 1.6575\nEpoch 72/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.4781 - accuracy: 0.8444 - MulticlassKR: 1.6695 - val_loss: 4.8306 - val_accuracy: 0.8372 - val_MulticlassKR: 1.6670\nEpoch 73/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.5386 - accuracy: 0.8424 - MulticlassKR: 1.6777 - val_loss: 4.8021 - val_accuracy: 0.8364 - val_MulticlassKR: 1.6715\nEpoch 74/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.4138 - accuracy: 0.8447 - MulticlassKR: 1.6880 - val_loss: 4.7918 - val_accuracy: 0.8377 - val_MulticlassKR: 1.6845\nEpoch 75/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.4090 - accuracy: 0.8476 - MulticlassKR: 1.6962 - val_loss: 4.7612 - val_accuracy: 0.8368 - val_MulticlassKR: 1.6925\nEpoch 76/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.4482 - accuracy: 0.8459 - MulticlassKR: 1.6987 - val_loss: 4.7491 - val_accuracy: 0.8363 - val_MulticlassKR: 1.7041\nEpoch 77/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.3394 - accuracy: 0.8462 - MulticlassKR: 1.7108 - val_loss: 4.7155 - val_accuracy: 0.8387 - val_MulticlassKR: 1.7075\nEpoch 78/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.3768 - accuracy: 0.8482 - MulticlassKR: 1.7117 - val_loss: 4.6795 - val_accuracy: 0.8396 - val_MulticlassKR: 1.7135\nEpoch 79/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.3540 - accuracy: 0.8476 - MulticlassKR: 1.7259 - val_loss: 4.6666 - val_accuracy: 0.8388 - val_MulticlassKR: 1.7266\nEpoch 80/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.2509 - accuracy: 0.8469 - MulticlassKR: 1.7359 - val_loss: 4.6558 - val_accuracy: 0.8357 - val_MulticlassKR: 1.7321\nEpoch 81/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.2792 - accuracy: 0.8461 - MulticlassKR: 1.7397 - val_loss: 4.6639 - val_accuracy: 0.8364 - val_MulticlassKR: 1.7419\nEpoch 82/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.2849 - accuracy: 0.8465 - MulticlassKR: 1.7502 - val_loss: 4.6150 - val_accuracy: 0.8389 - val_MulticlassKR: 1.7488\nEpoch 83/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.2858 - accuracy: 0.8466 - MulticlassKR: 1.7563 - val_loss: 4.6256 - val_accuracy: 0.8382 - val_MulticlassKR: 1.7551\nEpoch 84/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.1836 - accuracy: 0.8491 - MulticlassKR: 1.7594 - val_loss: 4.5682 - val_accuracy: 0.8401 - val_MulticlassKR: 1.7607\nEpoch 85/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1970 - accuracy: 0.8497 - MulticlassKR: 1.7701 - val_loss: 4.5760 - val_accuracy: 0.8405 - val_MulticlassKR: 1.7660\nEpoch 86/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1455 - accuracy: 0.8507 - MulticlassKR: 1.7759 - val_loss: 4.5417 - val_accuracy: 0.8425 - val_MulticlassKR: 1.7734\nEpoch 87/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1810 - accuracy: 0.8506 - MulticlassKR: 1.7823 - val_loss: 4.5125 - val_accuracy: 0.8417 - val_MulticlassKR: 1.7786\nEpoch 88/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1159 - accuracy: 0.8518 - MulticlassKR: 1.7922 - val_loss: 4.5125 - val_accuracy: 0.8391 - val_MulticlassKR: 1.7913\nEpoch 89/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.1807 - accuracy: 0.8500 - MulticlassKR: 1.7990 - val_loss: 4.4882 - val_accuracy: 0.8402 - val_MulticlassKR: 1.7938\nEpoch 90/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1548 - accuracy: 0.8504 - MulticlassKR: 1.8031 - val_loss: 4.5046 - val_accuracy: 0.8421 - val_MulticlassKR: 1.8073\nEpoch 91/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.1227 - accuracy: 0.8501 - MulticlassKR: 1.8102 - val_loss: 4.4483 - val_accuracy: 0.8408 - val_MulticlassKR: 1.8036\nEpoch 92/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.1302 - accuracy: 0.8512 - MulticlassKR: 1.8124 - val_loss: 4.4501 - val_accuracy: 0.8435 - val_MulticlassKR: 1.8101\nEpoch 93/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.0846 - accuracy: 0.8502 - MulticlassKR: 1.8184 - val_loss: 4.4205 - val_accuracy: 0.8425 - val_MulticlassKR: 1.8175\nEpoch 94/100\n15/15 [==============================] - 1s 80ms/step - loss: 3.9720 - accuracy: 0.8539 - MulticlassKR: 1.8275 - val_loss: 4.4813 - val_accuracy: 0.8381 - val_MulticlassKR: 1.8186\nEpoch 95/100\n15/15 [==============================] - 1s 81ms/step - loss: 3.9978 - accuracy: 0.8542 - MulticlassKR: 1.8309 - val_loss: 4.3855 - val_accuracy: 0.8440 - val_MulticlassKR: 1.8287\nEpoch 96/100\n15/15 [==============================] - 1s 80ms/step - loss: 4.0764 - accuracy: 0.8506 - MulticlassKR: 1.8369 - val_loss: 4.3828 - val_accuracy: 0.8443 - val_MulticlassKR: 1.8371\nEpoch 97/100\n15/15 [==============================] - 1s 81ms/step - loss: 4.0436 - accuracy: 0.8517 - MulticlassKR: 1.8470 - val_loss: 4.3730 - val_accuracy: 0.8457 - val_MulticlassKR: 1.8344\nEpoch 98/100\n15/15 [==============================] - 1s 81ms/step - loss: 3.9989 - accuracy: 0.8532 - MulticlassKR: 1.8491 - val_loss: 4.3596 - val_accuracy: 0.8445 - val_MulticlassKR: 1.8446\nEpoch 99/100\n15/15 [==============================] - 1s 80ms/step - loss: 3.9820 - accuracy: 0.8541 - MulticlassKR: 1.8539 - val_loss: 4.3444 - val_accuracy: 0.8442 - val_MulticlassKR: 1.8477\nEpoch 100/100\n15/15 [==============================] - 1s 80ms/step - loss: 3.9592 - accuracy: 0.8523 - MulticlassKR: 1.8626 - val_loss: 4.3177 - val_accuracy: 0.8448 - val_MulticlassKR: 1.8529\n</code>\n</pre> <pre>\n<code>&lt;tensorflow.python.keras.callbacks.History at 0x7f9e52213c10&gt;</code>\n</pre> <pre><code># once training is finished you can convert\n# SpectralDense layers into Dense layers and SpectralConv2D into Conv2D\n# which optimize performance for inference\nvanilla_model = model.vanilla_export()\n</code></pre> <pre><code>import foolbox as fb\nfrom tensorflow import convert_to_tensor\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n</code></pre> <pre>\n<code>Matplotlib created a temporary config/cache directory at /tmp/matplotlib-an1t4aqt because the default path (/home/thibaut.boissin/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n</code>\n</pre> <pre><code># we will test it on 10 samples one of each class\nnb_adv = 10\n\nhkr_fmodel = fb.TensorFlowModel(vanilla_model, bounds=(0., 1.), device=\"/GPU:0\")\n</code></pre> <p>In order to test the robustness of the model, the first correctly classified element of each class are selected.</p> <pre><code># strategy: first\n# we select a sample from each class.\nimages_list = []\nlabels_list = []\n# select only a few element from the test set\nselected=np.random.choice(len(y_test_ord), 500)\nsub_y_test_ord = y_test_ord[:300]\nsub_x_test = x_test[:300]\n# drop misclassified elements\nmisclassified_mask = tf.equal(tf.argmax(vanilla_model.predict(sub_x_test), axis=-1), sub_y_test_ord)\nsub_x_test = sub_x_test[misclassified_mask]\nsub_y_test_ord = sub_y_test_ord[misclassified_mask]\n# now we will build a list with input image for each element of the matrix\nfor i in range(10):\n  # select the first element of the ith label\n  label_mask = [sub_y_test_ord==i]\n  x = sub_x_test[label_mask][0]\n  y = sub_y_test_ord[label_mask][0]\n  # convert it to tensor for use with foolbox\n  images = convert_to_tensor(x.astype(\"float32\"), dtype=\"float32\")\n  labels = convert_to_tensor(y, dtype=\"int64\")\n  # repeat the input 10 times, one per misclassification target\n  images_list.append(images)\n  labels_list.append(labels)\nimages = convert_to_tensor(images_list)\nlabels = convert_to_tensor(labels_list)\n</code></pre> <pre>\n<code>/home/thibaut.boissin/envs/deel-lip_github/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n/home/thibaut.boissin/envs/deel-lip_github/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n</code>\n</pre> <p>In order to build a certficate, we take for each sample the top 2 output and apply this formula: $$ \\epsilon \\geq \\frac{\\text{top}_1 - \\text{top}_2}{2} $$ Where epsilon is the robustness radius for the considered sample.</p> <pre><code>values, classes = tf.math.top_k(hkr_fmodel(images), k=2)\ncertificates = (values[:, 0] - values[:, 1]) / 2\ncertificates\n</code></pre> <pre>\n<code>&lt;tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.25511226, 1.0321686 , 0.34624586, 0.5743104 , 0.12979731,\n       0.19581676, 0.08184442, 0.34386343, 0.68743587, 0.12055641],\n      dtype=float32)&gt;</code>\n</pre> <p>now we will attack the model to check if the certificates are respected. In this setup <code>L2CarliniWagnerAttack</code> is used but in practice as these kind of networks are gradient norm preserving, other attacks gives very similar results.</p> <pre><code>attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=6, steps=8000)\nimgs, advs, success = attack(hkr_fmodel, images, labels, epsilons=None)\ndist_to_adv = np.sqrt(np.sum(np.square(images - advs), axis=(1,2,3)))\ndist_to_adv\n</code></pre> <pre>\n<code>array([1.3944995 , 3.5208094 , 1.6824133 , 1.9192038 , 0.5746496 ,\n       0.7780392 , 0.39687884, 1.1619285 , 2.367604  , 0.48984095],\n      dtype=float32)</code>\n</pre> <p>As we can see the certificate are respected.</p> <pre><code>tf.assert_less(certificates, dist_to_adv)\n</code></pre> <p>Finally we can take a visual look at the obtained examples. We first start with utility functions for display.</p> <pre><code>class_mapping = {\n  0: \"T-shirt/top\",\n  1: \"Trouser\",\n  2: \"Pullover\",\n  3: \"Dress\",\n  4: \"Coat\",\n  5: \"Sandal\",\n  6: \"Shirt\",\n  7: \"Sneaker\",\n  8: \"Bag\",\n  9: \"Ankle boot\",\n}\n</code></pre> <pre><code>def adversarial_viz(model, images, advs, class_mapping):\n\"\"\"\n  This functions shows for each sample: \n  - the original image\n  - the adversarial image\n  - the difference map\n  - the certificate and the observed distance to adversarial \n  \"\"\"\n  scale = 1.5\n  kwargs={}\n  nb_imgs = images.shape[0]\n  # compute certificates\n  values, classes = tf.math.top_k(model(images), k=2)\n  certificates = (values[:, 0] - values[:, 1]) / 2\n  # compute difference distance to adversarial\n  dist_to_adv = np.sqrt(np.sum(np.square(images - advs), axis=(1,2,3)))\n  # find classes labels for imgs and advs\n  orig_classes = [class_mapping[i] for i in tf.argmax(model(images), axis=-1).numpy()]\n  advs_classes = [class_mapping[i] for i in tf.argmax(model(advs), axis=-1).numpy()]\n  # compute differences maps\n  if images.shape[-1] != 3:\n    diff_pos = np.clip(advs - images, 0, 1.)\n    diff_neg = np.clip(images - advs, 0, 1.)\n    diff_map = np.concatenate([diff_neg, diff_pos, np.zeros_like(diff_neg)], axis=-1)\n  else:\n    diff_map = np.abs(advs - images)\n  # expands image to be displayed\n  if images.shape[-1] != 3:\n    images = np.repeat(images, 3, -1)\n  if advs.shape[-1] != 3:\n    advs = np.repeat(advs, 3, -1)\n  # create plot\n  figsize = (3 * scale, nb_imgs * scale)\n  fig, axes = plt.subplots(\n    ncols=3,\n    nrows=nb_imgs,\n    figsize=figsize,\n    squeeze=False,\n    constrained_layout=True,\n    **kwargs,\n  )\n  for i in range(nb_imgs):\n    ax = axes[i][0]\n    ax.set_title(orig_classes[i])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.axis(\"off\")\n    ax.imshow(images[i])\n    ax = axes[i][1]\n    ax.set_title(advs_classes[i])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.axis(\"off\")\n    ax.imshow(advs[i])\n    ax = axes[i][2]\n    ax.set_title(f\"certif: {certificates[i]:.2f}, obs: {dist_to_adv[i]:.2f}\")\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.axis(\"off\")\n    ax.imshow(diff_map[i]/diff_map[i].max())\n</code></pre> <p>When looking at the adversarial examples we can see that the network has interresting properties:</p> <pre><code>adversarial_viz(hkr_fmodel, images, advs, class_mapping)\n</code></pre>"},{"location":"notebooks/demo4/#demo-4-hkr-multiclass-and-fooling","title":"Demo 4: HKR multiclass and fooling","text":"<p>This notebook will show how to train a lispchitz network in a multiclass setup. The HKR is extended to multiclass using a one-vs all setup. It will go through the process of designing and training the network. It will also show how to create robustness certificates from the output of the network. Finally these certificates will be checked by attacking the network. </p>"},{"location":"notebooks/demo4/#installation","title":"installation","text":"<p>First, we install the required libraries. <code>Foolbox</code> will allow to perform adversarial attacks on the trained network.</p>"},{"location":"notebooks/demo4/#the-architecture","title":"the architecture","text":"<p>The original one vs all setup would require 10 different networks ( 1 per class ), however, in practice we use a network with a common body and 10 1-lipschitz heads. Experiments have shown that this setup don't affect the network performance. In order to ease the creation of such network, <code>FrobeniusDense</code> layer has a parameter for this:  whenr <code>disjoint_neurons=True</code> it act as the stacking of 10 single neurons head. Note that, altough each head is a 1-lipschitz function the overall network is not 1-lipschitz (Concatenation is not 1-lipschitz). We will see later how this affects the certficate creation.</p>"},{"location":"notebooks/demo4/#the-loss","title":"the loss","text":"<p>The multiclass loss can be found in <code>HKR_multiclass_loss</code>. The loss has two params: <code>alpha</code> and <code>min_margin</code>. Decreasing <code>alpha</code> and increasing <code>min_margin</code> improve robustness (at the cost of accuracy). note also in the case of lipschitz networks, more robustness require more parameters. For more information see our paper.</p> <p>In this setup choosing <code>alpha=100</code>, <code>min_margin=.25</code> provide a good robustness without hurting the accuracy too much.</p> <p>Finally the <code>KR_multiclass_loss()</code> indicate the robustness of the network ( proxy of the average certificate )</p>"},{"location":"notebooks/demo4/#notes-about-constraint-enforcement","title":"notes about constraint enforcement","text":"<p>There are currently 3 way to enforce a constraint in a network: 1. regularization 2. weight reparametrization 3. weight projection</p> <p>The first one don't provide the required garanties, this is why <code>deel-lip</code> focuses on the later two. Weight reparametrization is done directly in the layers (parameter <code>niter_bjorck</code>) this trick allow to perform arbitrary gradient updates without breaking the constraint. However this is done in the graph, increasing ressources consumption. The last method project the weights between each batch, ensuring the constraint at an more affordable computational cost. It can be done in <code>deel-lip</code> using the <code>CondenseCallback</code>. The main problem with this method is a reduced efficiency of each update.</p> <p>As a rule of thumb, when reparametrization is used alone, setting <code>niter_bjorck</code> to at least 15 is advised. However when combined with weight projection, this setting can be lowered greatly.</p>"},{"location":"notebooks/demo4/#model-exportation","title":"model exportation","text":"<p>Once training is finished, the model can be optimized for inference by using the <code>vanilla_export()</code> method.</p>"},{"location":"notebooks/demo4/#certificates-generation-and-adversarial-attacks","title":"certificates generation and adversarial attacks","text":""},{"location":"notebooks/demo4/#predictability","title":"predictability","text":"<p>by looking at the certificates, we can predict if the adversarial example will be close of not</p>"},{"location":"notebooks/demo4/#disparity-among-classes","title":"disparity among classes","text":"<p>As we can see, the attacks are very efficent on similar classes (eg. T-shirt/top, and Shirt ). This denote that all classes are not made equal regarding robustness.</p>"},{"location":"notebooks/demo4/#explainability","title":"explainability","text":"<p>The network is more explainable: attacks can be used as counterfactuals. We can tell that removing the inscription on a T-shirt turns it into a shirt makes sense. Non robust examples reveals that the network rely on textures rather on shapes to make it's decision.</p>"}]}